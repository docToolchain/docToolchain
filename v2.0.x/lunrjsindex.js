var documents = [

{
    "id": 0,
    "uri": "030_news/2024/3.4.1-release.html",
    "menu": "news",
    "title": "Release v3.4.1",
    "text": " Table of Contents docToolchain release v3.4.1 (Bugfix-Release) About This Release Notes fixed added changed docToolchain release v3.4.1 (Bugfix-Release) About This Release This release fixes some bugs and introduces some minor changes. This version contains a fix for the publishToConfluence task which failed due to a bug introduced in v3.4.0 . One of the change highlights is the switch to the latest version of the HTML Sanity Checker (HSC) . After some refactoring, HSC is now also available as batch- and command line tool. This allows to use HSC in CI/CD pipelines or as a standalone tool without the prior requirement to use Gradle. Furthermore, we did some housekeeping and removed some legacy code and unused configuration properties. Notes fixed Missing alt attributes in site templates (found by HTML Sanity Checker 2.0.0-rc0, see below). Jira links substitution is not working publishToConfluence fails with \"No such property: attachmentPrefix for class: org.docToolchain.tasks.Asciidoc2ConfluenceTask\" DTCW should preferably use DTC from the local installation and only rely on ${PATH} otherwise Task :exportEA FAILED because of unknown property 'imageFormat' added Add an environment variable DTC_SHELL_DEBUG (which could be set to -x or -xv ) to let dtcw run the DTC script in a more verbose way. changed Use Release 2.0.0-rc0 of HTML Sanity Checker removed legacy jiraRoot config property You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 1,
    "uri": "030_news/2024/3.4.0-release.html",
    "menu": "news",
    "title": "Release v3.4",
    "text": " Table of Contents docToolchain release v3.4 (Bugfix-Release) About This Release Notes fixed added changed docToolchain release v3.4 (Bugfix-Release) About This Release JCenter is going into sunset again ( https://jfrog.com/blog/jcenter-sunset/ ). Since quite some time, docToolchain does not reference JCenter anymore. But it seems that deep down in the Gradle code, there where still some mechanisms which resolved dependencies via JCenter. Now that JCenter redirects to Maven Central, we noticed that there where some dependencies which are not available in Maven Central. For grolifant and okhttp-digest , we could modify the version used: https://github.com/docToolchain/docToolchain/pull/1416/files#diff-3433324f9a2bbfe886e6234c6f7e08522a1a63d4cb55e50555310dbc87a26d6eR15 For markdown_to_asciidoc , the coordinates changed and with them the minimal Java Version: https://github.com/docToolchain/docToolchain/pull/1416/files#diff-0849704cf63a51fc06de310463839c4dd6e238297c41f8431abb1d019c94ac7eL48 Since docToolchain consists of scripts, we could add some logik that if you are below JDK 17, docToolchain still runs but exportMarkdown will be disabled. To make docToolchain more stable, we added a new tutorial with some thoughts about how to use docToolchain in an Enterprise environment: Enterprise docToolchain . In this special case, a corporate proxy for the dependencies would have safed you from a disruption. Why are those old dependencies in docToolchain? Well, docToolchain relies on many great libraries which already run in a stable way for quite some time. There was no need to update them in the past. But to be honest, some are also hard to upgrade. This is why there is a replacement for jBake in the pipeline. A lightweight version with only the feature set which docToolchain uses with less dependencies. Notes fixed Build suddenly fails (since changes to Gradle plugin portal) added Collapsible left menu (see https://doctoolchain.org/docToolchain/v2.0.x/030_news/index.html for an example) exportEA: Add additional option to set the image format #1391: Update collectIncludes.gradle changed removed link to plausible.io on docs site You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 2,
    "uri": "030_news/2024/3.3-release.html",
    "menu": "news",
    "title": "Release v3.3",
    "text": " Table of Contents docToolchain release v3.3 (Bugfix-Release) About This Release Notes fixes changed docToolchain release v3.3 (Bugfix-Release) About This Release This release fixes a problem with the docker image and dependencies in a restricted environment. The docker image should already contain all required dependencies and thus should be able to run in an enviroment without internet connection (build pipeline). With the latest im provements, a change was introduced which broke this feature. This resulted in timeouts for the dependency resolution. We now managed to fix this again. We also introduced an enviroment variable DTC_DOCKER_PREFIX to specify an internal docker hub for the docker image. This should also help to run docToolchain in restricted environments. Other changes fix problems with custom ruby extensiosn for PDF generation and features for publishToConfluence Notes fixes [Noticket] Enforce x86 Java on macOS as long as jbake does not support arm64 processors [Noticket] Avoid usage of an arbitrary arch binary/script on ${PATH} instead of the desired /usr/bin/arch on macOS. #1353: docker: Problem with 3.x images and dependencies? #1239: Execute a custom asciidoctor converter for generateHTML #1290: Custom ruby extension for PDF generation #1355: publishToConfluence - some code blocks are generated as txt instead of requested language and loose linebreaks #1349: publishToConfluence - a source code block containing template parameters has formatting problems changed you can now specify another dockerhub via DTC_DOCKER_PREFIX You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 3,
    "uri": "030_news/2024/3.2.2-release.html",
    "menu": "news",
    "title": "Release v3.2.2",
    "text": " Table of Contents docToolchain release v3.2.2 (Bugfix-Release) About This Release Notes 3.2.2 - 2024-01-18 fixes added changed docToolchain release v3.2.2 (Bugfix-Release) This is the Bugfix-Release v3.2.2 About This Release The v3.2.1 Release changed the behaviour of the REST client used in publishToConfluence and failed on attachments uploads in some cases. please also check the release notes for v3.2.0 and release notes for v3.2.1 Notes 3.2.2 - 2024-01-18 fixes #1335 publishToConfluence throws exception when uploading attachments in v3.2.0 #1343: Build and publish docs after PR get into ng added #1338: extend the options for the docker environment by additional environment variables and additional parameter sets. changed [Core] Http calls from docToolchain are now identified by a user agent string of format docToolchain_v&lt;DTCW_VERSION&gt; . a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 4,
    "uri": "030_news/2024/3.2.1-release.html",
    "menu": "news",
    "title": "Release v3.2.1",
    "text": " Table of Contents docToolchain release v3.2.1 (Bugfix-Release) About This Release Notes 3.2.1 - 2024-01-10 fixes added changed docToolchain release v3.2.1 (Bugfix-Release) This is the Bugfix-Release v3.2.1 About This Release The v3.2.0 Release could not handle certain HTML files in publishToConfluence and failed on attachments uploads. please also check the release notes for v3.2.0 Notes 3.2.1 - 2024-01-10 fixes #1330: Publish to confluence gives response 400 on version 3.2.0 added #1327: Allow use of enhanced docker image new task wipeConfluenceSpace to delete all pages of a space changed a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 5,
    "uri": "030_news/2023/3.2.0-release.html",
    "menu": "news",
    "title": "Release v3.2.0",
    "text": " Table of Contents docToolchain release v3.2.0 About This Release Notes 3.2.0 - 2023-12-20 fixes added changed docToolchain release v3.2.0 About This Release Here it is: docToolchain v3.2.0! We could reduce the size of the release by ~70MB compared to v3.1.2 and ~120MB compared to v2.2.1. Additionally we successfully closed a plenty vulnerabilities in the dependencies (11 Critical, 76 High, 129 Medium). It contains two major changes: Clean up dependency tree Removed build-in server for previewSite task. the task is now a no-op. There is no replacement for the build-in server. Simply open the generated .html in your browser. previewSite may be removed in a future release. Removed unused dependencies Refactored exportJiraIssues and exportJiraSprintChangelog tasks. Improved error handling for all Atlassian API calls Introduced new configuration option jira.exports as a replacement for jira.requests . The change is backwards compatible, but the new configuration option is recommended and the deprecated jira.requests will be removed soon. Introduce configuration option to limit the number of API calls per second to avoid 429 errors Notes 3.2.0 - 2023-12-20 fixes #1307: powershell: problem to find local installed jdk #1300: publishToConfluence:Cannot handle embedded SVG images #1253: publishToConfluence removes all linebreaks from code added changed #1231: docker: port mapping only needed for previewSite #1309: deprecate previewSite task #1292: remove http builder and httpmime a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 6,
    "uri": "030_news/2023/3.1.2-release.html",
    "menu": "news",
    "title": "Release v3.1.2",
    "text": " Table of Contents docToolchain release v3.1.2 (Bugfix-Release) About This Release Notes 3.1.2 - 2023-11-16 fixes added changed docToolchain release v3.1.2 (Bugfix-Release) This is the Bugfix-Release v3.1.2 About This Release The v3.1.1 Release could not handle certain Confluence URLs and was missing a task dependency. please also check the release notes for v3.1.0 Notes 3.1.2 - 2023-11-16 fixes #1291: publishToConfluence - Images not found #1293: Explicit dependency required between generateHTML and htmlSanityCheck added changed The Confluence API configuration is now aware of contexts and hides the API version specific settings. a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 7,
    "uri": "030_news/2023/3.1.1-release.html",
    "menu": "news",
    "title": "Release v3.1.1",
    "text": " Table of Contents docToolchain release v3.1.1 (Bugfix-Release) About This Release Notes 3.1.1 - 2023-11-07 fixes changed docToolchain release v3.1.1 (Bugfix-Release) We just had to create Bugfix-Release v3.1.1 About This Release The v3.1.0 Release could not handle Confluence attachments. This release fixes this blocker. please also check the release notes for v3.1.0 Notes 3.1.1 - 2023-11-07 fixes #1281: publishToConfluence throws exception when uploading attachments in v3.1.0 #1283: \"tasks\" target causes Exception changed Improve docs for publishToConfluence task a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 8,
    "uri": "030_news/2023/3.1.0-release.html",
    "menu": "news",
    "title": "Release v3.1.0",
    "text": " Table of Contents docToolchain release v3.1.0! About This Release Notes 3.1.0 - 2023-11-03 fixes added changed docToolchain release v3.1.0! About This Release Here it is: docToolchain v3.1.0! It contains two major changes: docToolchain starts to become more modularized. This enables us to provide a core component which can be used by other projects as well, without the use of Gradle. Though, Gradle will still get the full support. Atlassian is currently deprecating the Confluence API v1. This release candidate contains the first steps to support the new API v2. From January 2024 on, the old API will be shut down for all Cloud Instances ( see ). While the script logic was mostly unaffected, the RestClient had to be rewritten. Although we tested everything, we need your help to test the new API to verify we didn&#8217;t miss anything. Notes to switch to the new API, you have to set the confluence.useV1Api property to false in your docToolchainConfig.groovy file. This is recommended for all users using Confluence Cloud. 3.1.0 - 2023-11-03 fixes #1262: downloadTemplate skips creating a folder, causes generateSite to fail #1269 Fix wrong bash usage on Darwin with Homebrew #1269 Ensure DTC_JAVA_HOME is preferred over JAVA_HOME #1069 publishToConfluence 'ancestorName' query does not support proxy #1272: publishToConfluence broken when document contains internal links added configure Confluence API parameters via Gradle parameters introduce verifyConfluenceApiAccess task - check if your API settings are correct changed introduce docToolchain core component to modularize the project implement Confluence API v2 support You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 9,
    "uri": "030_news/2023/3.0.2-release.html",
    "menu": "news",
    "title": "Release v3.0.2",
    "text": " Table of Contents docToolchain release v3.0.2 (Bugfix-Release) About This Release Notes 3.0.2 - 2023-09-12 fixes changed Discussion docToolchain release v3.0.2 (Bugfix-Release) We just had to create Bugfix-Release v3.0.2 About This Release The v3.0.1 Release created a non-working default config. This release fixes this blocker. please also check the release notes for v3.0.1 Notes 3.0.2 - 2023-09-12 fixes #1246: publishToConfluence: Fix comparision error for titles with leading/trailing white spaces #1248: broken default config changed Discussion To discuss the new features, a new discussion thread has been created. a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 10,
    "uri": "030_news/2023/3.0.1-release.html",
    "menu": "news",
    "title": "Release v3.0.1",
    "text": " Table of Contents docToolchain release v3.0.1! About This Release Notes 3.0.1 - 2023-09-11 fixes changed Discussion docToolchain release v3.0.1! We just turned the release-candidate into release v3.0.1 About This Release Wow! The docToolchain community managed to prepare the biggest release in the history of docToolchain! :-) This release was made possible through the hard work of the following wonderful contributors (in no special order): @camminati @RoettingerJ @PacoVK @bit-jkraushaar @Frank-dev20 @windows97 @mh182 @rdmueller @dependabot @sparsick @johthor @srotman @PeterStange @klatka (list was automatically generated by github) 14 Contributors 23+ fixes several additions lots of dependency updates Notes to use the new wrapper, you currently have to fetch it from https://raw.githubusercontent.com/docToolchain/docToolchain/ng/dtcw or https://raw.githubusercontent.com/docToolchain/docToolchain/ng/dtcw.ps1 instead of the location mentioned in the tutorial ./dtcw local install doctoolchain and ./dtcw local install java are now the commands to do an initial local setup generatePDF now needs additional styles, details will follow to test the Antora template install antora: https://docs.antora.org/antora/latest/install/install-antora/ download the arc42 template as antora style ./dtcw downloadTemplate create a playbook.yaml within the root of your project make sure that your project is a valid git repository and contains at least one commit execute antora playbook.yml playbook.yml site: title: Antora ARC42 Template start_page: arc42-template::index.adoc content: sources: - url: ./ start_path: src/docs branches: [HEAD] ui: bundle: url: https://gitlab.com/antora/antora-ui-default/-/jobs/artifacts/HEAD/raw/build/ui-bundle.zip?job=bundle-stable snapshot: true asciidoc: attributes: sectanchors: true output: dir: build/antora 3.0.1 - 2023-09-11 fixes #1209: generateSite: Problem with meta data parsing #1217, #1214, #1216: dtcw.ps1 fix handling of java version #1215: dtcw.ps1 says dtc not installed after exceuting an install #1192: exportExcel: unnecessary Rowspans break rendering of table #1221: generateSite: beforeToc functionality broken #1218: plantuml encoding issues fixed curl command in manual #402: publishToConfluence: Error rendering macro 'code' #1200: JCenter kills doctoolchain, as Grolifant is not available on Maven Central #1198: gravatar eleminates leading 0 from md5 hash #1193: exportEA fails since v2.0.5 with an exception #395 asciidoctor-diagram: ERROR: Failed to generate image: PlantUML image generation failed #455 Force execution to stop with failure on missing image reference #621: dtcw - sdkman installation check returns wrong result #829: Multiple run of dtcw with docker is failing because of a container name conflict #831: fix for generateSite: images-hrefs not correct #973: dtcw getJava doesn&#8217;t work without local #1109: docToolchain release notes contain releases twice #1031: dtcw ignores installed Java RE when docker is installed - your java version 17 is too new #1163: upload to confluence breaks with embedded images #1161: publishToConfluence looses the id when generating level 2 page anchors various fixes in dtcw , dtcw.ps1 : pick the right environment if none provided by the user support of JAVA_HOME which was silently ignored. #220 convertToDocx and convertToEpub not working Workaround for Confluence new Editor rollout #1184: PublishToConfluence new editor issues and page size #880: publishToConfluence FAILED: Content body cannot be converted to new editor format #1053: publishToConfluence: hash is displayed at end of some pages configure if build should fail on missing images introduces configuration property failOnMissingImages introduce generateContent task - AI for docToolchain added req42 framework to downloadTemplate task added 'FR' as language for arc42 Antora support (beta), setup a docToolchain project and integrate it as module seamlessly into your existing Antora playbook. See downloadTemplate task for more details. added short tutorial about changing the theme of a microsite changed add support for Java 17, drop support for Java 8 upgrade Gradle to 8.1.1 upgrade dependencies 'com.athaydes:spock-reports:2.3.2-groovy-3.0' 'com.github.ben-manes.versions:0.46.0' 'com.structurizr:structurizr-dsl:1.30.1' 'com.structurizr:structurizr-export:1.14.0' 'com.structurizr:structurizr-graphviz:2.0.0' 'de.undercouch.download:5.4.0' 'io.pebbletemplates:pebble:3.2.0' 'net.bytebuddy:byte-buddy:1.14.4' 'org.asciidoctor:asciidoctor-gradle-jvm:4.0.0-alpha.1' (remove obsolete cloning of reveal.js ) 'org.asciidoctor:asciidoctorj-diagram:2.2.7' 'org.apache.httpcomponents:httpmime:4.5.14' 'org.apache.poi:poi-ooxml:5.2.3' 'org.codehaus.groovy:groovy-xml:3.0.13' 'org.jsoup:jsoup:1.16.1' 'org.junit.jupiter:junit-jupiter-api:5.9.3' 'org.openapitools:openapi-generator-gradle-plugin:6.6.0' 'org.openapi.generator:6.6.0' 'org.spockframework:spock-core:2.3-groovy-3.0' dtcw and dtcw.ps1 : improve output with hints to guide the user add --version option deprecate getJava with install java add environment variable DTC_CONFIG_FILE to specify a configuration file other than than docToolchainConfig.groovy in the project root folder collectIncludes changed regexp to start with ^[A-Za-z] as file name to allow lowercase filenames as well. certain directories are excluded from traversal. Define excludeDirectories in order to skip additional directories. doc: replace old URL doctoolchain.github.io occurrences with the new doctoolchain.org publishToConfluence support embedded images Discussion To discuss the new features, a new discussion thread has been created. a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 11,
    "uri": "030_news/2023/Babylon.html",
    "menu": "news",
    "title": "Multilingual Documentation",
    "text": " Table of Contents Multilingual Documentation: A Guide Multilingual Documentation: A Guide Working in diverse teams is great! But creating documentation in multiple languages can be a real challenge when English is not the primary language. Dr. Gernot Starke and Benjamin Wolf have tackled this very issue in their article Babylon as a Feature . Providing unique insights as well as practical solutions, they offer a deep-dive into the many facets of multilingual documentation and offer useful strategies to improve your own. "
},

{
    "id": 12,
    "uri": "030_news/2023/3.0.0-rc1.html",
    "menu": "news",
    "title": "Release Candidate v3.0.0",
    "text": " Table of Contents docToolchain release candidate v3.0.0! About This Release Notes 3.0.0-rc1 - 2023-07-13 fixes added changed Discussion docToolchain release candidate v3.0.0! About This Release Wow! The docToolchain community managed to prepare the biggest release in the history of docToolchain! :-) This release was made possible through the hard work of the following wonderful contributors (in no special order): @camminati @RoettingerJ @PacoVK @bit-jkraushaar @Frank-dev20 @windows97 @mh182 @rdmueller @dependabot @sparsick @johthor @srotman @PeterStange (list was automatically generated by github) 13 Contributors 18+ fixes several additions lots of dependency updates Since this is currently only a pre-release / release candidate, please play around with it, test it and report all your findings. Notes to use the new wrapper, you currently have to fetch it from https://raw.githubusercontent.com/docToolchain/docToolchain/ng/dtcw or https://raw.githubusercontent.com/docToolchain/docToolchain/ng/dtcw.ps1 instead of the location mentioned in the tutorial ./dtcw local install doctoolchain and ./dtcw local install java are now the commands to do an initial local setup generatePDF now needs additional styles, details will follow to test the Antora template install antora: https://docs.antora.org/antora/latest/install/install-antora/ download the arc42 template as antora style ./dtcw downloadTemplate create a playbook.yaml within the root of your project make sure that your project is a valid git repository and contains at least one commit execute antora playbook.yml playbook.yml site: title: Antora ARC42 Template start_page: arc42-template::index.adoc content: sources: - url: ./ start_path: src/docs/arc42 branches: [HEAD] ui: bundle: url: https://gitlab.com/antora/antora-ui-default/-/jobs/artifacts/HEAD/raw/build/ui-bundle.zip?job=bundle-stable snapshot: true asciidoc: attributes: sectanchors: true output: dir: build/antora 3.0.0-rc1 - 2023-07-13 fixes #1200: JCenter kills doctoolchain, as Grolifant is not available on Maven Central #1198: gravatar eleminates leading 0 from md5 hash #1193: exportEA fails since v2.0.5 with an exception #395 asciidoctor-diagram: ERROR: Failed to generate image: PlantUML image generation failed #455 Force execution to stop with failure on missing image reference #621: dtcw - sdkman installation check returns wrong result #829: Multiple run of dtcw with docker is failing because of a container name conflict #831: fix for generateSite: images-hrefs not correct #973: dtcw getJava doesn&#8217;t work without local #1109: docToolchain release notes contain releases twice #1031: dtcw ignores installed Java RE when docker is installed - your java version 17 is too new #1163: upload to confluence breaks with embedded images #1161: publishToConfluence looses the id when generating level 2 page anchors various fixes in dtcw , dtcw.ps1 : pick the right environment if none provided by the user support of JAVA_HOME which was silently ignored. #220 convertToDocx and convertToEpub not working Workaround for Confluence new Editor rollout #1184: PublishToConfluence new editor issues and page size #880: publishToConfluence FAILED: Content body cannot be converted to new editor format #1053: publishToConfluence: hash is displayed at end of some pages added configure if build should fail on missing images introduces configuration property failOnMissingImages introduce generateContent task - AI for docToolchain added req42 framework to downloadTemplate task added 'FR' as language for arc42 Antora support (beta), setup a docToolchain project and integrate it as module seamlessly into your existing Antora playbook. See downloadTemplate task for more details. added short tutorial about changing the theme of a microsite changed add support for Java 17, drop support for Java 8 upgrade Gradle to 8.1.1 upgrade dependencies 'com.athaydes:spock-reports:2.3.2-groovy-3.0' 'com.github.ben-manes.versions:0.46.0' 'com.structurizr:structurizr-dsl:1.30.1' 'com.structurizr:structurizr-export:1.14.0' 'com.structurizr:structurizr-graphviz:2.0.0' 'de.undercouch.download:5.4.0' 'io.pebbletemplates:pebble:3.2.0' 'net.bytebuddy:byte-buddy:1.14.4' 'org.asciidoctor:asciidoctor-gradle-jvm:4.0.0-alpha.1' (remove obsolete cloning of reveal.js ) 'org.asciidoctor:asciidoctorj-diagram:2.2.7' 'org.apache.httpcomponents:httpmime:4.5.14' 'org.apache.poi:poi-ooxml:5.2.3' 'org.codehaus.groovy:groovy-xml:3.0.13' 'org.jsoup:jsoup:1.16.1' 'org.junit.jupiter:junit-jupiter-api:5.9.3' 'org.openapitools:openapi-generator-gradle-plugin:6.6.0' 'org.openapi.generator:6.6.0' 'org.spockframework:spock-core:2.3-groovy-3.0' dtcw and dtcw.ps1 : improve output with hints to guide the user add --version option deprecate getJava with install java add environment variable DTC_CONFIG_FILE to specify a configuration file other than than docToolchainConfig.groovy in the project root folder collectIncludes changed regexp to start with ^[A-Za-z] as file name to allow lowercase filenames as well. certain directories are excluded from traversal. Define excludeDirectories in order to skip additional directories. doc: replace old URL doctoolchain.github.io occurrences with the new doctoolchain.org publishToConfluence support embedded images Discussion To discuss the new features, a new discussion thread has been created. a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). "
},

{
    "id": 13,
    "uri": "030_news/2023/2.2.1-release.html",
    "menu": "news",
    "title": "Release v2.2.1",
    "text": " Table of Contents docToolchain v2.2.1 has Been Released! About This Release 2.2.1 - 2023-03-05 fixes added changed docToolchain v2.2.1 has Been Released! About This Release Great News! docToolchain now comes with structurizr , a library which let&#8217;s you model your diagrams-as-code views and we have better automated tests for the doctoolchain wrapper dtc ! To discuss the new features, a new discussion thread has been created. a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). 2.2.1 - 2023-03-05 fixes use the configured proxy when publishing labels to confluence pages #1054 : fix for publishToConfluence was broken in v2.2.0 #1063 : fix for exportConfluence broken path for partial exports added exportStructurizr Task automated tests for dtcw changed automate the use of x86 emulator on apple silicon in dtcw updated jBake Markdown extensions and added FENCED_CODE_BLOCKS "
},

{
    "id": 14,
    "uri": "030_news/2023/2.2.0-release.html",
    "menu": "news",
    "title": "Release v2.2.0",
    "text": " Table of Contents docToolchain v2.2.0 has Been Released! About This Release Changes which need migration 2.2.0 - 2023-02-16 fixes added changed docToolchain v2.2.0 has Been Released! About This Release This is a fresh release of many nice features. The best probably is the exportConfluence Task which lets you export a whole confluence space to AsciiDoc! To test the new release, the docToolchain wrapper dtcw will not be updated until the end of the week. To discuss the new features, a new discussion thread has been created. please take a close look at the changelog, because there are some breaking changes Changes which need migration #937 Confluence publish nested pages by heading This replaces the settings allInOnePage and createSubPages . Migrate as follows: allInOnePage = true is the same as subpagesForSections = 0 allInOnePage = false &amp;&amp; createSubpages = false is the same as subpagesForSections = 1 allInOnePage = false &amp;&amp; createSubpages = true is the same as subpagesForSections = 2 #940 simplify configuration to use preamble heading from h1 instead of configuration Migrate by removing the setting preambleTitle and set the correct first level heading in the document. Make dtcw (and some other shell executables) shellcheck proof the docker image has been moved to doctoolchain /doctoolchain:v2.2.0 a big \"THANK YOU\" to all Sponsors and Contributors who helped to support docToolchain! You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). 2.2.0 - 2023-02-16 fixes fixed whitespace in GH issue template (which leads to errors in htmlSanityCheck ) fixed ExportMarkdownSpec fixed GenerateDeckSpec fixed GenerateDeck / Reveal.js fixed exportEA hangs by EA v16.1 fixed exportEA write model notes into models subfolder allow numeric ancestorIds for confluence export #951 Improve DTC_PROJECT_BRANCH management #976 dtcw shows a fatal error when not in git repository #978 dtcw.ps1 does not correctly check for java version #890 updated documentation on \"Self-Contained docToolchain\" Remove never used analytics.js file from docsy theme added new Task exportConfluence Add confluenceBearerToken property rubyExtensions configuration CZ as language for downloadTemplate Enable to use a particular version of DTC from the wrapper by setting the environment variable 'DTC_VERSION' accordingly. publishToConfluence: Add possibility to set the page version comment exportEAP.vbs: trim notes filename exportEAP.vbs: creates for each model a combined notes exportEAP.vbs: msg \"looking for&#8230;&#8203;\" extended for EA 16.1 changed switch docker base image from deprecated openJDK 14 to temurin 11 The publishToConfluence guide now contains 3 modes for authentication (username &amp; password, username &amp; API key, personal access token) Improve confluence export performance when only ancestorIds are given #937 Confluence publish nested pages by heading This replaces the settings allInOnePage and createSubPages . Migrate as follows: allInOnePage = true is the same as subpagesForSections = 0 allInOnePage = false &amp;&amp; createSubpages = false is the same as subpagesForSections = 1 allInOnePage = false &amp;&amp; createSubpages = true is the same as subpagesForSections = 2 #683 publishToConfluence with unknown source language #940 simplify configuration to use preamble heading from h1 instead of configuration Migrate by removing the setting preambleTitle and set the correct first level heading in the document. Make dtcw (and some other shell executables) shellcheck proof "
},

{
    "id": 15,
    "uri": "030_news/2022/2.1.0-release.html",
    "menu": "news",
    "title": "Release v2.1.0",
    "text": " Table of Contents docToolchain v2.1.0 has Been Released! About This Release Changelog v2.1.0 fixes added changed docToolchain v2.1.0 has Been Released! About This Release This is the long due announcement of the 2.1.0 release. It has been already released 2022-08-15, but it took me (Ralf) until now (2023-02-15) to create this new post. You like docToolchain? What about helping to make it even better? docToolchain is a community project, so be part of the community which drives the project. You don&#8217;t have to code for doing so. It would even help to brush up the docs, write tutorials or groom the backlog (I guess many of the open issues are already fixed). the docker image has been moved to doctoolchain /doctoolchain:v2.1.0 Changelog v2.1.0 fixes #938 asciidoc2confluence.groovy retrieveAllPages is returning allPages eventhough different spacekey is passed to it. This is happening when i try to publish documents to confluence #720 Fix gradlew.bat Fixes typo in dtcw.bat for finding the correct local cli command. #847 generateHTML &amp; generatePDF documentation improvements #851 fix duplicate TOC marker #853 Hide site links when not configured #873 generateSite: Fix index page location #899 dtcw local &lt;any-task&gt; (bash) executes :help instead of &lt;any-task&gt; added #692 generateSite: navigation tree instead of a list on the left #886 Add the possibility to set maven credentials #848 generateSite: add customisation possibilities for the jbake gradle plugin #894 custom, project specific Tasks #897 collectIncludes: Add options to configure search #911 Add confluence page limit changed updated available languages for arc42 template updated asciidoctorj-diagram to 2.2.3 added latest version to dtcw the docker image has been moved to doctoolchain /doctoolchain:v2.1.0 "
},

{
    "id": 16,
    "uri": "030_news/2022/2.0.5-release.html",
    "menu": "news",
    "title": "Release v2.0.5",
    "text": " Table of Contents docToolchain v2.0.5 has Been Released! About This Release Changelog v2.0.5 fixes added changed docToolchain v2.0.5 has Been Released! About This Release This is a bug-fix release. Thanks to everyone who contributed! the docker image is a bit bigger now. If everything works out, this is because it now contains hopefully all dependencies. Changelog v2.0.5 fixes 2022-03-08 downloadTemplate: fix encoding for working with powershell #821 exportPPT is broken since 2.x 2022-02-25 #764 order :jbake-order: numerical 2021-12-20 brushed up docs 2021-12-06 #712 - publishToConfluence fails when no hash is available for an uploaded image 2022-01-23 #757 - CI: Fix problem in ci-scrip 2021-12-06 #20 some wget versions throw errors #19 the wrapper stops if no java installed but you want to use docker 2021-11-26 #18 gradle daemon has memory problems 2021-11-15 #696 - exportContributors - not everybody is rendered #697 - exportToMarkdown docs are not referenced correctly added 2021-12-09 #714 - Update exportExcel.gradle 2021-11-30 #706 - exportEA: Add check if diagrams shall be overwritten 2021-11-13 #686 - Add resourceDirs option changed 2022-03-09 upgraded underlying gradle from 6.7.1 to 6.9.2 2022-03-08 downloadTemplate: upgraded download plugin #817 htmlSanityCheck remove dependency to generateHTML 2022-02-09 #795 publishToConfluence: added hint for wrong configuration 2022-01-23 #756 exportEA: Add two more items for export 2021-12-23 #730 \"improve this doc\" and \"create and issue\" links 2021-12-09 make build output less noisy - use logger instead of println 2021-12-08 changed wording of landing page (thanx to Jody Winter) 2021-12-04 changed java download hint from oracle to https://adoptium.net/ 2021-11-30 refactored config file 2021-11-14 refactored jbake template \"menu.gsp\" "
},

{
    "id": 17,
    "uri": "030_news/2022/2.0.4-release.html",
    "menu": "news",
    "title": "(Release v2.0.4)",
    "text": " Table of Contents docToolchain v2.0.4 About This Release docToolchain v2.0.4 About This Release there was a major bug in this release, so please ignore "
},

{
    "id": 18,
    "uri": "030_news/2021/2021-11-23-Open-Source-Camp.html",
    "menu": "news",
    "title": "Open Source Camp",
    "text": " Table of Contents Open Source Camp Open Source Camp .center { text-align: center; } The next Cyberland Open Source Camp is just around the corner. This time, docToolchain will be one of the featured open source projects! Calling all contributors and supporters of the project to think about the tasks we could realistically solve in those few hours. Here are some ideas from our list of open issues to get your brains into gear: Autocompletion for the CLI . generateSite – additional navigation level on the left . Create multi-branch GitHub pages example . Investigations with Gitpod . A new InitRepo task . If you have another idea, please let me know . To vote for a task, go to GitHub and ❤️ the issue. "
},

{
    "id": 19,
    "uri": "030_news/2021/2.0.3-release.html",
    "menu": "news",
    "title": "Release v2.0.3",
    "text": " Table of Contents docToolchain v2.0.3 Has Been Released! About This Release Changelog v2.0.3 docToolchain v2.0.3 Has Been Released! About This Release This is a bug-fix release. Thanks to everyone who contributed! Changelog v2.0.3 Added #681 - Please reactivate single page manual on v2.0.x site Fixed 2021-11-10 fix #693 - on windows powershell, targetDir is set wrong fix #695 - generateSite: toc attributes 2021-11-09 fix #690 - previewSite: exception if folder does not exist 2021-11-08 fix #687 - wrong encoding of emojis fix #688 - htmlSanityCheck: config of sourceDir is wrong fix #689 - code highlight: css clash with blog post tags fix #682 - generateSite: copyImages uses the wrong target "
},

{
    "id": 20,
    "uri": "030_news/2021/2.0.2-release.html",
    "menu": "news",
    "title": "Release v2.0.2",
    "text": " Table of Contents docToolchain v2.0.2 has been released! About This Release Changelog v2.0.2 docToolchain v2.0.2 has been released! About This Release This is a bug-fix release. Thanks to everyone who contributed! Changelog v2.0.2 Added 2021-10-19 use :jbake-rightcolumnhtml: to add some html to the right column Changed 2021-10-19 Add #667 - GH Actions Default Build 2021-10-18 Fix #664 - doctoolchain.org link and typos Fixed 2021-10-19 fix example for gitRepoUrl in config fix projectRootDir fix status.png and siteTitle 2021-10-17 fix #660 - generateSite: projectRootDir wrong 2021-10-11 fix #651 - powershell: broken install when space in user path 2021-10-15 fix #658 - generateSite - subsequent runs won&#8217;t fail with an invalid or missing site theme "
},

{
    "id": 21,
    "uri": "030_news/2021/2.0.1-release.html",
    "menu": "news",
    "title": "Release v2.0.1",
    "text": " Table of Contents docToolchain v2.0.1 has been released! About This Release Changelog v2.0.1 docToolchain v2.0.1 has been released! About This Release This is our first bug-fix release. Thanks to everyone who contributed! Changelog v2.0.1 Added 2021-10-06 experimental: globalReferences Changed 2021-10-04 fix #616 - exportOpenAPI: Enhance the Confluence Open-API Documentation API to refer to URLs Fixed 2021-10-06 fix #636 - theme: larger admonition icons fix #649 - generateSite on powershell wrong file-separator 2021-10-04 fix #645 - exportJiraIssues: Could not get unknown property 'configFile' for task ':exportJiraIssues' of type org.gradle.api.DefaultTask 2021-09-30 fix #632 - generateHTML: broken images with generateHTML "
},

{
    "id": 22,
    "uri": "030_news/2021/2.0.0-release.html",
    "menu": "news",
    "title": "Release v2.0.0",
    "text": " Table of Contents docToolchain v2.0.0 has been released! Changes and New Features Coming Soon A Personal Thank You from Ralf Changelog v2.0.0 docToolchain v2.0.0 has been released! Today marks an important milestone for docToolchain: the release of v2.0.0, aka ‘ng’ or next generation! The focus of this huge release is simplified setup, better usability and distraction-free writing. Changes and New Features The most important change is the switch-to-a-command-line based approach . You can now fully focus on your documentation without crowding your repo with lots of other files like scripts and themes. This is made possible by the new docToolchain wrapper (or dtcw for short). dtcw is a little script that resides together with a config file in your repository. It ensures that the right docToolchain version is in use, ensures that all prerequisites are met, and it even checks whether Docker or a local installation should be used to execute docToolchain. And, if docToolchain is not currently installed, dtcw will install it for you. In this release, we have tried very hard to avoid error messages . Where we can’t avoid them, we’ve tried to make them as meaningful as possible. Another huge feature is the generateSite -Task which includes jBake as static site generator to help you to create awesome docs. You can now create a full documentation website with a few commands. We chose the beautiful docsy theme from hugo, and it even contains a local search implemented with lunr. To get you started with your solution architecture docs, we’ve added the downloadTemplate -task which delivers the famous arc42 template in four languages. And last but not least, we have used the new generateSite -Feature to restructure docToolchain’s very own documentation! Coming Soon Our goal for the coming weeks is to provide tutorials that demonstrate all of the new features. A Personal Thank You from Ralf Thank you to all docToolchain contributors, sponsors and users for your efforts in getting this major release out the door. I wouldn’t have made it this far without you. Happy writing! Ralf Changelog v2.0.0 Added 2021-09-21 added lunrjs as local search engine 2021-09-06 added warning when running on WSL added dtcw.bat to avoid execution restrictions updated developer docs added docsy as theme 2021-05-21 if the outputPath from the config starts with a '/', it will be considered as absolute path. This way, you can move the build folder outside of your repository. outputPath = System.getenv('HOME')+'/.doctoolchain/build/'+(new File('.')).canonicalPath.md5() repository theme gets only copied to build if it is defined in siteFolder generateSite will now add meta-data to all asciidoc files which have no meta-data defined. The menu name and order will be created corresponding to the folder and file name. The title will be extracted as first headline from the file itself. 2021-05-18 Headless mode for themes fix landing page (only gets copied once when microsite config isn&#8217;t set yet.) 2021-04-07 generateSite can now handle themes 2021-04-09 downloadTemplate can now handle further templates 2021-02-26 copyThemes task generateSite task 2021-02-23 first version of powershell wrapper 2021-02-22 manual test script 2021-01-05 dtc wrapper 2021-01-08 first definition of a static site taken from arc42-template-project updated gradle wrapper (6.6.1) added downloadTemplates task added feature to automatically create a Config file if it doesn&#8217;t exist configured gradle to run without daemon Changed 2021-09-22 streamingExecute (exportPPT, exportEA) now emits a note instead ot an error when running on linux brushed up powershell wrapper Fixed 2021-09-21 updated exportContributors to follow moved files fixed downloadTemplate 2021-09-18 fixed favicons fixed blog 2021-05-22 fix copyThemes to also copy the external theme 2021-05-06 fix #574: publishToConfluence: Problem with wrong ancestorId 2021-04-28 fix copyImages for generateSite 2021-03-02 removed default imagesdir for generateSite 2021-03-01 fixed imagesdir typo 2021-03-01 updated docs for generateSite fixed menu for generateSite 2021-02-27 fixed createDist task fixed plantUML for generatePDF fixed plantUML for generateSite 2021-02-24 [543] dtcw: added pre-requisites check and alternative curl instead of wget 2021-02-22 handling of images for generateHTML "
},

{
    "id": 23,
    "uri": "030_news/2021/last-release-candidate.html",
    "menu": "news",
    "title": "Last Release Candidate",
    "text": " Table of Contents Last Release Candidate Last Release Candidate Good news! We’ve just (we hope!) released the final last release candidate. All known major issues have been fixed and lots of cool features have been added. All remaining and unknown issues will be fixed in 2.0.x versions. "
},

{
    "id": 24,
    "uri": "030_news/index.html",
    "menu": "news",
    "title": "Overview",
    "text": " Table of Contents Overview Overview Find all published news on this page. "
},

{
    "id": 25,
    "uri": "ea/Use_Cases_links.html",
    "menu": "ea",
    "title": "Use_Cases_links.ad",
    "text": " . and this is just a test for issue #2 https://github.com/rdmueller/docToolchain/issues/2 "
},

{
    "id": 26,
    "uri": "ea/Use_Cases_links_issue2.html",
    "menu": "ea",
    "title": "Use_Cases_links_issue2.ad",
    "text": " . and this is just a test for issue #2 https://github.com/rdmueller/docToolchain/issues/2 "
},

{
    "id": 27,
    "uri": "ea/Use_Cases_notes.html",
    "menu": "ea",
    "title": "Use_Cases_notes.ad",
    "text": " docToolchain is a gradle/maven build which turns asciidoc documentation into HTML5 rendered files. create stunning docs invoked by gradle or maven command "
},

{
    "id": 28,
    "uri": "ea/UseCases.html",
    "menu": "ea",
    "title": "UseCases.ad",
    "text": " docToolchain is a gradle/maven build which turns asciidoc documentation into HTML5 rendered files. create stunning docs invoked by gradle or maven command "
},

{
    "id": 29,
    "uri": "ea/Use_Cases_notes_UseCases.html",
    "menu": "ea",
    "title": "Use_Cases_notes_UseCases.ad",
    "text": " docToolchain is a gradle/maven build which turns asciidoc documentation into HTML5 rendered files. create stunning docs invoked by gradle or maven command "
},

{
    "id": 30,
    "uri": "ea/Activity_notes_issue1.html",
    "menu": "ea",
    "title": "Activity_notes_issue1.ad",
    "text": " Activity1 Just a test for issue #1 https://github.com/rdmueller/docToolchain/issues/1 "
},

{
    "id": 31,
    "uri": "ea/issue1.html",
    "menu": "ea",
    "title": "issue1.ad",
    "text": " Activity1 Just a test for issue #1 https://github.com/rdmueller/docToolchain/issues/1 "
},

{
    "id": 32,
    "uri": "ea/Architect_notes.html",
    "menu": "ea",
    "title": "Architect_notes.ad",
    "text": " "
},

{
    "id": 33,
    "uri": "ea/issue2.html",
    "menu": "ea",
    "title": "issue2.ad",
    "text": " . and this is just a test for issue #2 https://github.com/rdmueller/docToolchain/issues/2 "
},

{
    "id": 34,
    "uri": "ea/Architect_notes_issue2.html",
    "menu": "ea",
    "title": "Architect_notes_issue2.ad",
    "text": " "
},

{
    "id": 35,
    "uri": "ea/readme.html",
    "menu": "ea",
    "title": "readme.ad",
    "text": " Table of Contents Warning! This folder contains exported diagrams or notes from Enterprise Architect. Please note that these are generated files but reside in the src -folder in order to be versioned. This is to make sure that they can be used from environments other than windows. Warning! The contents of this folder will be overwritten with each re-export! use gradle exportEA to re-export files "
},

{
    "id": 36,
    "uri": "015_tasks/03_tasks.html",
    "menu": "tasks",
    "title": "What Is a Task?",
    "text": " Table of Contents What Is a Task? How Tasks Are Named .gravatar img { margin-left: 3px; border-radius: 4px; } What Is a Task? 2 minutes to read A task is another name for a script which triggers the build actions that compile and publish your docs. This diagram gives you an overview of the entire build process: Figure 1. docToolchain How Tasks Are Named Tasks are given a naming prefix which indicates their role in the build process. There are currently 4 groups. generateX These tasks use plain old Asciidoctor functionality to render the source to a given format. exportX These tasks export images and AsciiDoc snippets from other systems or file formats. The resulting artifacts can then be included from your main sources. export tasks differ from generate tasks because with export tasks, you don&#8217;t have to export with each build. Also, with export tasks, it&#8217;s likely that you will already store the resulting artifacts under version control because the tools needed for the export (such as Sparx Enterprise Architect or MS PowerPoint) are typically not available on your build server or another contributor&#8217;s machine. convertToX These tasks take the output from Asciidoctor and convert it (through other tools) to the target format. This results in a dependency on a generateX task and another external tool (currently pandoc ). publishToX These tasks not only convert your documents but also deploy, publish and move them to a remote system (currently Confluence), meaning the result is immediately visible to others. "
},

{
    "id": 37,
    "uri": "015_tasks/03_task_previewSite.html",
    "menu": "tasks",
    "title": "previewSite",
    "text": " Table of Contents previewSite About This Task .gravatar img { margin-left: 3px; border-radius: 4px; } previewSite 1 minute to read About This Task Note This task has now been deprecated. When you use a build in a static site generator through generateSite , most site themes don&#8217;t need the static site server for general content. You can just preview the site by opening from the file system in your browser. However, some JavaScript features will not work because of CORS restrictions. In that case you need a server. You can start one by running e.g. python -m http.server or in case you have Python 3 python3 -m http.server . "
},

{
    "id": 38,
    "uri": "015_tasks/03_task_generateHTML.html",
    "menu": "tasks",
    "title": "generateHTML",
    "text": " Table of Contents generateHTML About This Task Generating Single-File HTML Output Creating Text-Based Diagrams Controlling Diagram Size Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } generateHTML 3 minutes to read About This Task This is the standard Asciidoctor generator which is supported out of the box. The result is written to build/html5 (the HTML files need the images folder to be in the same directory to display correctly). Generating Single-File HTML Output If you would like the generator to produce a single-file HTML, you can configure Asciidoctor to store the images inline as data-uri by setting :data-uri: in the config of your AsciiDoc file. But be warned. The file can quickly become very large and some browsers might struggle to render it. Creating Text-Based Diagrams docToolchain is configured to use the asciidoctor-diagram plugin to create PlantUML diagrams. The plugin also supports many other text-based diagrams, but PlantUML is the most common. To use the plugin, specify your PlantUML code like this: .example diagram [plantuml, \"{plantUMLDir}demoPlantUML\", png] # (1) ---- class BlockProcessor class DiagramBlock class DitaaBlock class PlantUmlBlock BlockProcessor &lt;|-- DiagramBlock DiagramBlock &lt;|-- DitaaBlock DiagramBlock &lt;|-- PlantUmlBlock ---- The element of this list specifies the diagram tool plantuml to be used. The second element is the name of the image to be created, and the third specifies the image type. Note {plantUMLDir} ensures that PlantUML also works for the generatePDF task. Without it, generateHTML works fine, but the PDF will not contain the generated images. Important Be sure to specify a unique image name for each diagram, otherwise they will overwrite each other. The above example renders as: Figure 1. example diagram Controlling Diagram Size If you want to control the size of the diagram in the output, configure the \"width\" attribute (in pixels) or the \"scale\" attribute (floating point ratio) passed to asciidoctor-diagram . The following example updates the diagram above by changing the declaration to one of the versions below: [plantuml, target=\"{plantUMLDir}demoPlantUMLWidth\", format=png, width=250] # rest of the diagram definition [plantuml, target=\"{plantUMLDir}demoPlantUMLScale\", format=png, scale=0.75] # rest of the diagram definition The output will render like this: Figure 2. example diagram (with specified width) Figure 3. example diagram (with specified scale) Note To work correctly, PlantUML needs Graphviz dot installed. If you can&#8217;t install it, use the Java-based version of the dot library instead. Just add !pragma layout smetana as the first line of your diagram definition. Further Reading and Resources This blog post explains more about single-file HTML. Read this blog post to understand how to use PlantUML without Graphviz dot. Other helpful posts related to the generateHTML task: PlantUML with Gradle PlantUML with Asciidoctor-pdf PlantUML Revisited Source Show source code of scripts/AsciiDocBasics.gradle or go directly to GitHub · docToolchain/scripts/AsciiDocBasics.gradle . scripts/AsciiDocBasics.gradle task generateHTML ( type: AsciidoctorTask, group: 'docToolchain', description: 'use html5 as asciidoc backend') { attributes ( 'plantUMLDir' : file(\"${docDir}/${config.outputPath}/html5\").toURI().relativize(new File(\"${docDir}/${config.outputPath}/html5/plantUML/\").toURI()).getPath(), ) // specify output folder explicitly to avoid cleaning targetDir from other generated content outputDir = file(targetDir + '/html5/') outputOptions { separateOutputDirs = false backends = ['html5'] } def sourceFilesHTML = findSourceFilesByType(['html']) // onlyIf { // sourceFilesHTML // } sources { sourceFilesHTML.each { include it.file File useFile = new File(srcDir, it.file) if (!useFile.exists()) { throw new Exception (\"\"\" The file $useFile in HTML config does not exist! Please check the configuration 'inputFiles' in $mainConfigFile.\"\"\") } } } resources { config.imageDirs.each { imageDir -&gt; from(new File(file(srcDir),imageDir)) logger.info ('imageDir: '+imageDir) into './images' } config.resourceDirs.each { resource -&gt; from(new File(file(srcDir),resource.source)) logger.info ('resource: '+resource.source) into resource.target } } doFirst { if (sourceFilesHTML.size()==0) { throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'html'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } } } "
},

{
    "id": 39,
    "uri": "015_tasks/03_task_exportStructurizr.html",
    "menu": "tasks",
    "title": "exportStructurizr",
    "text": " Table of Contents exportStructurizr About This Task Configuration Example Configuration Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportStructurizr 3 minutes to read About This Task Structurizr builds upon \"diagrams as code\", allowing you to create multiple diagrams from a single model, using a number of tools and programming languages. Structurizr is specifically designed to support the C4 model for visualising software architecture . This task exports PlantUML (respective C4-PlantUML ) diagrams from a software architecture model described with the Structurizr DSL . The generated diagrams can be integrated into the AsciiDoc documentation. The software architecture model is integral part of the software architecture documentation. As such we strongly suggest to put the Structurizr workspace file under revision control integrating it in the src/docs directory. The user would edit the software architecture model by this file. This Structurizr DSL example below creates two diagrams, based upon a single set of elements and relationships. workspace { model { user = person \"User\" softwareSystem = softwareSystem \"Software System\" { webapp = container \"Web Application\" { user -&gt; this \"Uses\" } container \"Database\" { webapp -&gt; this \"Reads from and writes to\" } } } views { systemContext softwareSystem { include * autolayout lr } container softwareSystem { include * autolayout lr } theme default } } And here the diagrams defined by the views in the example above rendered by the Structurizr web renderer. Configuration Config.groovy // Configuration for Structurizr related tasks structurizr = [:] structurizr.with { // Configure where `exportStructurizr` looks for the Structurizr model. workspace = { // The directory in which the Structurizr workspace file is located. // path = 'src/docs/structurizr' // By default `exportStructurizr` looks for a file '${structurizr.workspace.path}/workspace.dsl' // You can customize this behavior with 'filename'. Note that the workspace filename is provided without '.dsl' extension. // filename = 'workspace' } export = { // Directory for the exported diagrams. // // WARNING: Do not put manually created/changed files into this directory. // If a valid Structurizr workspace file is found the directory is deleted before the diagram files are generated. // outputPath = 'src/docs/structurizr/diagrams' // Format of the exported diagrams. Defaults to 'plantuml' if the parameter is not provided. // // Following formats are supported: // - 'plantuml': the same as 'plantuml/structurizr' // - 'plantuml/structurizr': exports views to PlantUML // - 'plantuml/c4plantuml': exports views to PlantUML with https://github.com/plantuml-stdlib/C4-PlantUML // format = 'plantuml' } } Example Configuration The example below shows a possible directory layout with a src/docs/structurizr directory containing the workspace.dsl file. . ├── docToolchainConfig.groovy ├── dtcw └── src └── docs ├── example │   └── example.adoc ├── images │   ├── some-pics-1.png │   └── some-pics-2.png └── structurizr └── workspace.dsl The minimal configuration for the exportStructurizr task in your docToolchainConfig.groovy would look like structurizr = [:] structurizr.with { workspace = { path = 'src/docs/structurizr' } export = { outputPath = \"src/docs/structurizr/diagrams\" // The format is optional. // format = 'plantuml' } } You probably want to put the directory configured with structurizr.export.outputPath into your .gitignore file. Warning Do not put manually created/changed files into the directory provided with structurizr.export.outputPath . If a valid Structurizr workspace file is provided the directory is deleted before the diagram files are generated. Calling ./dtcw exportStructurizr generates the diagrams in the structurizr.export.outputPath directory. Directory layout after exporting the diagrams ├── docToolchainConfig.groovy ├── dtcw └── src └── docs ├── example │   └── example.adoc ├── images │   ├── some-pics-1.png │   └── some-pics-2.png └── structurizr ├── diagrams | ├── Container-001-key.puml | ├── Container-001.puml | ├── SystemContext-001-key.puml | └── SystemContext-001.puml └── workspace.dsl Following our example the exported diagrams may be included in the Asciidoc document example.adoc with plantuml::../structurizr/diagrams/SystemContext-001.puml[\"structurizr-SystemContext\",format=svg] plantuml::../structurizr/diagrams/Container-001.puml[\"structurizr-Container\",format=svg] Source Show source code of scripts/exportStructurizr.gradle or go directly to GitHub · docToolchain/scripts/exportStructurizr.gradle . scripts/exportStructurizr.gradle task exportStructurizr ( group: 'docToolchain', description: 'exports the views of a Structurizr DSL file to diagramms' ) { doLast { logger.debug(\"\\n=====================\\nStructurizr Config - before property replacement:\\n=====================\") logger.debug(\"structurizr.workspace.path: ${config.structurizr.workspace.path}\") logger.debug(\"structurizr.workspace.filename: ${config.structurizr.workspace.filename}\") logger.debug(\"structurizr.export.outputPath: ${config.structurizr.export.outputPath}\") logger.debug(\"structurizr.export.format: ${config.structurizr.export.format}\") // First we check the parameters def workspacePath = findProperty(\"structurizr.workspace.path\")?:config.structurizr.workspace.path if (!workspacePath) { throw new GradleException(\"Missing configuration parameter 'structurizr.workspace.path': please provide the path where the Structurizr workspace file is located.\") } // If 'workspace.filename' is not provided, default to 'workspace' (without extension). def filename = (findProperty(\"structurizr.workspace.filename\")?:config.structurizr.workspace.filename)?:'workspace' def outputPath = findProperty(\"structurizr.export.outputPath\")?:config.structurizr.export.outputPath if (!outputPath) { throw new GradleException(\"Missing configuration parameter 'structurizr.export.outputPath': please provide the directory where the diagrams should be exported.\") } // If 'format' parameter is not provided, default to 'plantuml'. def format = (findProperty(\"structurizr.export.format\")?:config.structurizr.export.format)?:'plantuml' // Assure valid 'format' configuration parameter. DiagramExporter exporter switch(format) { case 'plantuml': case 'plantuml/structurizr': exporter = new StructurizrPlantUMLExporter() break case 'plantuml/c4plantuml': exporter = new C4PlantUMLExporter() break default: throw new GradleException(\"unknown structurizr.format '${format}': supported formats are 'plantuml' and 'plantuml/c4plantuml'.\") } logger.info(\"\\n=====================\\nStructurizr Config:\\n=====================\") logger.info(\"structurizr.workspace.path: ${workspacePath}\") logger.info(\"structurizr.workspace.filename: ${filename}\") logger.info(\"structurizr.export.outputPath: ${outputPath}\") logger.info(\"structurizr.export.format: ${format}\") def workspaceFile = new File(docDir, workspacePath+'/'+filename+'.dsl') logger.info(\"Parsing Structurizr workspace file '${workspaceFile}'\") StructurizrDslParser parser = new StructurizrDslParser() // TODO: provide better error output in case parsing fails parser.parse(workspaceFile) Workspace workspace = parser.getWorkspace() ThemeUtils.loadThemes(workspace) // Cleanup existing diagrams and then make sure the directory exists where the diagrams are exported new File(docDir, outputPath).deleteDir() // Create a readme to clarify things def readme = \"\"\"This folder contains exported diagrams from a model described with Structurizr DSL. Please note that these are generated files but reside in the `src`-folder in order to be versioned. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradlew exportStructurizr` to re-export the diagrams \"\"\" new File(docDir, outputPath).mkdirs() new File(docDir, outputPath+'/README.adoc').write(readme) Collection&lt;Diagram&gt; diagrams = exporter.export(workspace); diagrams.each { diagram -&gt; def file = new File(docDir, outputPath+\"/\"+diagram.key+'.'+diagram.getFileExtension()) file.write(diagram.definition) if (diagram.legend) { def legend = new File(docDir, outputPath+\"/\"+diagram.key+\"-key.\"+diagram.getFileExtension()) legend.write(diagram.legend.definition) } } } } "
},

{
    "id": 40,
    "uri": "ea/Activity_notes.html",
    "menu": "ea",
    "title": "Activity_notes.ad",
    "text": " Activity1 Just a test for issue #1 https://github.com/rdmueller/docToolchain/issues/1 "
},

{
    "id": 41,
    "uri": "015_tasks/03_task_exportConfluence.html",
    "menu": "tasks",
    "title": "exportConfluence",
    "text": " Table of Contents exportConfluence About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportConfluence 3 minutes to read About This Task For a long time, docToolchain supports the conversion of AsciiDoc files to confluence spaces. This task now allows you to convert you confluence spaces back to AsciiDoc. A confluence space will be converted to a \"ready to use\" set of AsciiDoc files together with a navigation menu. Note the results of the conversion are quite good. However, don&#8217;t expect the two tasks publishToConfluence and exportConfluence to be able to give you a full round-trip without losing some information about the format of your texts. As an example, numbered headlines will not be automatically converted between both systems. The task exportConfluence parses the entities.xml file of a confluence-space export and creates a hierarchical html export. It then uses pandoc to convert the HTML files to AsciiDoc. Since this conversion isn&#8217;t perfect and pandoc doesn&#8217;t even know about confluence macros, the script also does some pre- and post-processing. prerequisites docToolchain &gt;= v2.2 you need to have pandoc installed. usage Export the confluence space as XML and unzip it in a distinct sample_data folder. To export the confluence space, navigate to the space and then click Space Settings Manage Space &gt; Export Space [x] Export Formats: XLM &#8658; Next [x] Full Export &#8658; Export Configure the right paths in your docToolchainConfig.groovy . export = [ srcDir: 'sample_data', destDir: 'src/docs' ] Then use the following steps to run the script and render the results as a microsite: ./dtcw exportConfluence ./dtcw generateSite You can also specify the needed parameters through the command line: ./dtcw exportConfluence -Pconfluence.export.srcDir=sample_data -Pconfluence.export.destDir=src/docs Supported Features all kinds of text formatting line breaks paragraphs explizit, external links image attachments admonitions .-Titles Anchors numbered Lists bulleted Lists literal blocks code blocks horizontal rules Quotes look good standard tables lucidchart diagrams anchors link-macro unsupported features tables with colspans or rowspans layout-sections inline comments comments expand blocks user-profile macro has only rudimentary support known issues Definitions lists are transformed to tables Quotes are not exactly as expected but look good tables with colspan will have colspan removed include sections are in give sort order Source Show source code of scripts/confluenceToAsciiDoc.groovy or go directly to GitHub · docToolchain/scripts/confluenceToAsciiDoc.groovy . scripts/confluenceToAsciiDoc.groovy import org.jsoup.Jsoup import org.jsoup.parser.Parser import org.jsoup.nodes.Document import groovy.xml.XmlSlurper import groovy.xml.slurpersupport.GPathResult import java.nio.file.Files import java.nio.file.StandardCopyOption // parse command line arguments and display usage info List parseCliArgs(String[] args) { // parse the exportet confluence entities from xml file if (args.size() &lt; 2) { println \"\"\" Usage: groovy exportConfluence.groovy srcDir=[name of source dir] destDir=[name of destination dir] both dirs can be specified as relative path. the script expects the srcDir to contain the unzipped data from a confluence space XML export \"\"\" System.exit(1) } parsedArgs = args.collectEntries { it.split(\"=\").each { it.trim() } } def srcDir = new File(parsedArgs.srcDir) def destDir = new File(parsedArgs.destDir) destDir.mkdirs() return [srcDir, destDir] } lucidChartsIframe = false unknownTagsStats = [:] //takes confluence xHTML storage format and fixes some issues to be better converted by pandoc def fixBody(pageId, String body, users, pages, space) { body = body // it seems to be a bug how CDATA sections are closed in the xHTML .replaceAll(\"]] &gt;&lt;\", \"]]&gt;&lt;\") // remove empty headings .replaceAll(\"&lt;h[1-9]&gt; &lt;/h[1-9]&gt;\",\"\") // remove unecessary colspan attrib .replaceAll('colspan=\"1\"',\"\") // fix colspan=2 for pandoc .replaceAll('colspan=\"2\"(.*?)&lt;/(t[dh])&gt;','$1&lt;/$2&gt;&lt;$2&gt;&lt;/$2&gt;') Document dom = Jsoup.parse(body, 'utf-8', Parser.xmlParser()) dom.outputSettings().prettyPrint(false);//makes html() preserve linebreaks and spacing dom.outputSettings().escapeMode(org.jsoup.nodes.Entities.EscapeMode.xhtml); //This will ensure xhtml validity regarding entities dom.outputSettings().charset(\"UTF-8\"); //does no harm :-) // search for image tags and convert them to HTML // get all ac: tags def acTags = [] dom.select(\"*\").each { element -&gt; if (element.tagName().startsWith(\"ac:\")) { acTags &lt;&lt; element.tagName().replace(\":\", \"|\") } } //fix links which still point to confluence dom.select(\"a\").each { element -&gt; def href = element.attr('href') def regexp = href =~ '/spaces/([^/]+)/pages/([0-9]+)/' if (regexp.size()==1) { // we have a link to confluence. // let's try to redirect it to out static page def targetSpace = regexp[0][1] if (space.key!=targetSpace) { println \"WARNING: can't rewrite links between different spaces (source: $space.key, target: $targetSpace)\" } else { def targetPage = regexp[0][2] def targetFilename = (pages[targetPage]?.filename) ?: '' def folderStructureTarget = getFolderStructure(pages, targetPage).join(\"/\") def folderStructureSource = getFolderStructure(pages, pageId) def targetLink = \"../\" * folderStructureSource.size() + folderStructureTarget + \"/\" + targetFilename + \".html\" element.attr('href', targetLink) } } } dom.select(\"span\").each { element -&gt; if (element.attr(\"class\").startsWith(\"css-\")) { element.unwrap() } if (element.attr(\"class\").startsWith(\"loader-wrapper\")) { element.unwrap() } if (element.attr(\"class\").contains(\"smart-link-title-wrapper\")) { element.unwrap() } } acTags = acTags.unique() def unknownTags = [] if (acTags.size() &gt; 0) { dom.select(acTags.join(\", \")).each { element -&gt; def name = element.tagName() switch (name) { case \"ac:image\": def alignment = element.attr(\"ac:align\") def width = element.attr(\"ac:width\") def filename = element.select([\"ri|attachment\"]).attr(\"ri:filename\") def version = element.select([\"ri|attachment\"]).attr(\"ri:version-at-save\") element.before(\"&lt;img src='{filepath}/${(version?version+\"_\":\"1_\")+(filename.replaceAll(\":\",\"_\"))}' align='${alignment?:''}' width='${width?:''}' /&gt;\") element.remove() break case \"ac:link\": if (element.children().size()&gt;0) { def anchor = element.attr(\"ac:anchor\") def targetPage = element.select(\"ri|page\").attr(\"ri:content-title\") def linkText = element.select(\"ac|plain-text-link-body\").text() if (linkText.trim()==\"\") { linkText = element.select(\"ac|link-body\").text() } targetPage = pages.find { _pageId, pageInfo -&gt; pageInfo.title == targetPage} if (targetPage) { def folderStructureTarget = getFolderStructure(pages, targetPage.key).join(\"/\") def folderStructureSource = getFolderStructure(pages, pageId) def targetLink = \"../\" * folderStructureSource.size() + folderStructureTarget + \"/\" + targetPage.value.filename + \".adoc\" if (anchor) { targetLink += \"#\" + anchor } element.before(\" xref:${targetLink}[${linkText}] \") element.remove() } else { //&lt;ac:link&gt;&lt;ri:attachment ri:filename=\"attachment.png\" ri:version-at-save=\"1\" /&gt;&lt;/ac:link&gt; } } break case \"ac:plain-text-link-body\": // ignore, part of link break case \"ac:inline-comment-marker\": // ignore - not supported break case [ \"ac:layout\", \"ac:layout-section\", \"ac:layout-cell\", \"ac:placeholder\" ]: // these tags are for multi column layouts and can't be easily converted // ignore break case \"ac:structured-macro\": def macroName = element.attr(\"ac:name\") switch (macroName) { case [ \"drawio\", \"excerpt-include\", \"panel\", ]: // ignore - not supported break case [\"expand\", \"expandable-comment\", ]: //println \"&gt;&gt;&gt; $macroName\" //println element break; case [\"view-file\"]: def filename = element.select([\"ri|attachment\"]).attr(\"ri:filename\") def version = element.select([\"ri|attachment\"]).attr(\"ri:version-at-save\") def height = element.select(\"ac|parameter[ac:name=height]\")?:'400' def filepath = \"images/\"+getFolderStructure(pages, pageId).join(\"/\") filepath = \"../\"*getFolderStructure(pages,pageId).size()+filepath if (filename.toLowerCase().endsWith('.pdf')) { element.before(\"\"\" &lt;div&gt; ++++%%CRLF%% &amp;lt;iframe name=\"${filename.replaceAll(\":\", \"_\")}\" allowfullscreen frameborder=\"0\" src='${filepath}/${(version ? version + \"_\" : \"1_\") + (filename.replaceAll(\":\", \"_\"))}' width='100%' height='${height}' &gt;&amp;lt;/iframe&gt;%%CRLF%% ++++%%CRLF%% &lt;/div&gt; \"\"\") } else if (filename[-4..-1].toLowerCase() in ['.jpg', '.png']) { element.before(\"&lt;img src='${filepath}/${(version ? version + \"_\" : \"1_\") + (filename.replaceAll(\":\", \"_\"))}' /&gt;\") } else { element.before(\"&lt;a href='${filepath}/${(version ? version + \"_\" : \"1_\") + (filename.replaceAll(\":\", \"_\"))}' &gt;$filename&lt;/a&gt;\") } element.remove() break; case 'attachments': // get all attachments for the current page and insert them as link // since we don't know about attachments in this method, we delegate it for later element.before(\"%%attachments%%\") element.remove() break case 'profile': def userkey = element.select(\"ri|user\").attr(\"ri:userkey\") if (users[userkey]) { element.before(\"\"\" User:: ${users[userkey].name}%%CRLF%% // ${users[userkey].atlassianAccountId}%%CRLF%% \"\"\") element.remove() } break case 'lucidchart': def documentId = element.select(\"ac|parameter[ac:name=documentId]\").text() def localId = element.attr(\"ac:local-id\") def macroId = element.attr(\"ac:macro-id\") def lucidInfos = \"\"\" // lucidChart // localId: ${element.attr(\"ac:local-id\")} // macroId: ${element.attr(\"ac:macro-id\")} \"\"\" element.select(\"ac|parameter\").each { parameter -&gt; def pname = parameter.attr(\"ac:name\") def pvalue = parameter.text() lucidInfos += \"// ${pname}: ${pvalue}\\n\" } // create AsciiDoc which will be passed through // only \\r\\n have to be encoded def chart = \"\" if (lucidChartsIframe) { chart = \"\"\" ++++%%CRLF%% &amp;lt;iframe allowfullscreen frameborder=\"0\" style=\"width:640px; height:480px\" src=\"https://lucid.app/documents/embedded/${documentId}\" &gt;&amp;lt;/iframe&gt;%%CRLF%% ++++%%CRLF%% \"\"\" } else { def folderStructure = getFolderStructure(pages, pageId) chart = \"\"\" %%CRLF%% image::${folderStructure.join(\"/\")}/${documentId}.png[]%%CRLF%% %%CRLF%% \"\"\" lucidInfoFile.append(\"\"\"\\ images/${folderStructure.join(\"/\")}/${documentId}.png \"\"\".toString()) } element.before(\"\"\" &lt;div class=\"lucidchart-wrapper\"&gt; ${lucidInfos.replaceAll(\"\\n\", \"%%CRLF%%\")} $chart https://lucid.app/lucidchart/${documentId}/edit[edit lucidchart] &lt;/div&gt; \"\"\") element.remove() break case 'toc': //ignore toc, will be generated by asciidoctor element.remove() break case 'children': //ignore, contains no content element.remove() break case [ 'tip', 'info', 'warning', 'note' ] : // admotions body = element.select(\"ac|rich-text-body\").html() def type = [ 'info':'NOTE', 'warning':'WARNING', 'note': 'CAUTION', 'tip':'TIP'][macroName] element.html(\"\"\" &lt;div class=\"admonition-wrapper\"&gt; [${type}]%%CRLF%% ====%%CRLF%% ${body.replaceAll(\"&lt;h([1-9])&gt;\",\"&lt;h\\$1&gt;[discrete]\")}%%CRLF%% ====%%CRLF%% &lt;/div&gt; \"\"\") element.unwrap() break case 'info': body = element.select(\"ac|rich-text-body\").html() def title = element.select(\"ac|parameter[ac:name=title]\").text() element.html(\"\"\" &lt;div class=\"info-wrapper\"&gt; .${title}%%CRLF%% ****%%CRLF%% ${body.replaceAll(\"&lt;h([1-9])&gt;\",\"&lt;h\\$1&gt;[discrete]\")}%%CRLF%% ****%%CRLF%% &lt;/div&gt; \"\"\") element.unwrap() break case 'anchor': def anchor = element.select(\"ac|parameter\").text() element.html(\"\\n&lt;span&gt;[[${anchor}]]&lt;span&gt;\\n\") element.unwrap() break case ['code', 'paste-code-macro']: def language = element.select(\"ac|parameter[ac:name=language]\").text() def code = element.select(\"ac|plain-text-body\").text() element.html(\"\"\" &lt;div class=\"code-wrapper\"&gt; [source, $language]%%CRLF%% ----%%CRLF%% ${code.replaceAll(\"\\n\",\"%%CRLF%%\")}%%CRLF%% ----%%CRLF%% &lt;/div&gt; \"\"\") element.unwrap() break default: unknownTags = (unknownTags &lt;&lt; \"ac:structured-macro $macroName\").unique() if (!unknownTagsStats[\"ac:structured-macro $macroName\"]) { unknownTagsStats[\"ac:structured-macro $macroName\"]=[] } unknownTagsStats[\"ac:structured-macro $macroName\"] &lt;&lt; pageId } break case [ \"ac:parameter\", \"ac:rich-text-body\", \"ac:plain-text-body\" ]: // ignore, part of structured-macro break default: unknownTags = (unknownTags &lt;&lt; name).unique() if (!unknownTagsStats[name]) { unknownTagsStats[name]=[] } unknownTagsStats[name] &lt;&lt; pageId } } } def html = dom.html() // some last dirty hacks // add a space in front of each link .replaceAll(\"&lt;a \", \" &lt;a \") // some links contain /#/ which is a problem for asciidoc .replaceAll(\"[/][#][/]\", '/\\\\\\\\#/') // remove unneeded line breaks in headlines .replaceAll(\"&lt;p&gt;&lt;/p&gt;&lt;strong&gt;&lt;br /&gt;\", \"&lt;strong&gt;\") // remove empty bold tags .replaceAll(\"&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;\", \"&lt;br /&gt;\") // turn html titles to .-titles .replaceAll(\"&lt;div&gt;&lt;div class=\\\"title\\\"&gt;([^&lt;]+)&lt;/div&gt;&lt;/div&gt;\", \".\\$1\") // remove bold formatting and empty breaks from .-titles .replaceAll(\"&lt;strong&gt;&lt;br /&gt;[.]([^&lt;]+)&lt;/strong&gt;\", \".\\$1\") return [html, unknownTags] } // need to parse the entities.xml into meta data about page-structure, attachments and space def parseMetaData( entities) { // first parse all pages, then all contentBodies def pages = [:] def attachments = [:] def space = [:] def users = [:] def unknownTags = [] println \"parsing page meta-data\" println \"\" entities.object.each { object -&gt; switch (object[\"@class\"]) { case 'Page': def pageId = object.id.toString() def contentStatus = object.property.find { it.@name == 'contentStatus' } if (contentStatus == \"current\") { def title = object.property.find { it.@name == 'title' }.text() def parentId = object.property.find { it.@name == 'parent' }.text() def filename = title .replaceAll(\"[Ää]\",\"ae\") .replaceAll(\"[Üü]\",\"ue\") .replaceAll(\"[Öö]\",\"oe\") .replaceAll(\"[^a-zA-Z0-9]\", \"_\") .replaceAll(\"_+\", \"_\") def position = object.property.find { it.@name == 'position' }.text() println \"Page: \" + pageId + \" - \" + title pages[pageId] = [title: title, parentId: parentId ?: -1, filename: filename, position: position] } break case 'Attachment': def id = object.id.toString() def contentStatus = object.property.find { it.@name == 'contentStatus' } if (contentStatus == \"current\") { def title = object.property.find { it.@name == 'title' }.text() def pageId = object.property.find { it.@name == 'containerContent' }.id.text() def version = object.property.find { it.@name == 'version' }.text() def originalId = object.property.find { it.@name == 'originalVersion' }.id.text() attachments[id] = [filename: title, id: id, version: version, pageId: pageId, originalId: originalId] println \"Attachment: \" + id + \" - \" + contentStatus + \" - \" + title } break case 'ConfluenceUserImpl': def id = object.id.toString() def name = object.property.find { it.@name == 'name' }.text() def atlassianAccountId = object.property.find { it.@name == 'atlassianAccountId' }.text() users[id] = [name: name, atlassianAccountId: atlassianAccountId] break case [ 'ContentProperty', 'SpacePermission', 'CustomContentEntityObject', 'Notification', 'Comment', 'OutgoingLink', 'Label', 'Labelling', 'User2ContentRelationEntity', 'Content2ContentRelationEntity', 'SpaceDescription', 'LikeEntity', 'BucketPropertySetItem', 'ContentPermission', 'BlogPost' ]: // ignore break case 'Space': space.name = object.property.find { it.@name == 'name' }.text() space.key = object.property.find { it.@name == 'key' }.text() space.homePage = object.property.find { it.@name == 'homePage' }.id.text() break case 'BodyContent': // will be handled later break default: println object[\"@class\"] break } } if (pages[space.homePage]==null) { pages[space.homePage] = [:] } pages[space.homePage].parentId = 0 return [unknownTags, pages, attachments, space, users] } // confluence exports attachments in a non-human readable format // let's change this def void copyAttachments (attachments, pages, srcDir, destDir) { println \"copying attachments\" attachments.each { attachmentId, attachment -&gt; def attachmentFile = new File(srcDir, 'attachments/' + attachment.pageId + '/' + (attachment.originalId ?: attachment.id) + \"/\" + attachment.version) def folderStructure = getFolderStructure(pages, attachment.pageId) def deepFilename = folderStructure.join(\"/\")+\"/\"+attachment.version + \"_\" + (attachment.filename.replaceAll(\":\", \"_\")) if (folderStructure.size() &gt; 1) { new File(destDir, \"images/\" + folderStructure.join(\"/\")).mkdirs() } def destFile = new File(new File(destDir, 'images'), deepFilename) try { Files.copy(attachmentFile.toPath(), destFile.toPath(), StandardCopyOption.REPLACE_EXISTING) } catch (Exception e) { println e.message } } } // get the folder structure for the current page through the page structure information String[] getFolderStructure ( Map pages, String pageId) { def parentId = pages[pageId]?.parentId if (parentId &amp;&amp; parentId != \"null\" &amp;&amp; parentId != 0) { if (pages[parentId]) { return getFolderStructure(pages, parentId ) + pages[parentId].filename } else { println \"parent page not found: \" + parentId + \" for \" + pages[pageId].filename return [] } } else { return [] } } // extract xHTML bodies from export, convert it to HTML and then to adoc and write it to disk def extractBodies(GPathResult entities, pages, attachments, space, users, File destDir) { println \"extracting contentBodies\" println \"\" def unknownTags = [] entities.object.each { object -&gt; switch (object[\"@class\"]) { case 'Page': def pageId = object.id.toString() def contentStatus = object.property.find { it.@name == 'contentStatus' } pages[pageId]?.status = '' if ( contentStatus == \"current\" &amp;&amp; (pages[pageId].parentId != -1 || pages[pageId].parentId == space.homePage) ) { pages[pageId].status = 'current' metaData = pages[pageId] def body = \"\" object.collection.findAll { it.@name == 'bodyContents' }.each { it -&gt; def id = it.element.id.text() body = entities.object .find { it.@class == 'BodyContent' &amp;&amp; it.id == id } .property.find { it.@name == 'body' }.text() } def children = [] object.collection.findAll { it.@name == 'children' }.each { collection -&gt; collection.element.each { element -&gt; children &lt;&lt; element.id.text() } } def folderStructure = getFolderStructure(pages, pageId) def deepFilename = folderStructure.join(\"/\")+\"/\"+metaData.filename.toString() // ensure that target folder exists if (folderStructure.size() &gt;= 1) { new File(destDir, folderStructure.join(\"/\")).mkdirs() } def outFile = new File(destDir, deepFilename + \".html\") // now, lets fix some body parts def uTags (body, uTags) = fixBody( pageId, body, users, pages, space) unknownTags = (unknownTags + uTags).unique() outFile.write(body, 'utf-8') // convert to AsciiDoc def outFilename = outFile.canonicalPath[0..-6] + \".adoc\" def command = \"pandoc --wrap preserve -f html -t asciidoc -s ${outFile.canonicalPath} -o ${outFilename}\" def process = command.execute() process.waitForProcessOutput(System.out, System.err) if (process.exitValue()&gt;1) { println \"couldn't convert ${outfile.canonicalPath}\" } else { def outFileAdoc = new File(outFilename) def filename = (outFile.toString() - destDir.toString()) def weightedChildren = [] children.each { child -&gt; weightedChildren &lt;&lt; [weight : ((pages[child]?.position?:\"-1\") as Integer), include: \"include::\" + pages[pageId].filename + \"/\" + pages[child].filename + \".adoc[levelOffset=+1]\", menu : \"include::\" + pages[child].filename + \"/_menu.adoc[]\"] } def childIncludes = \"\" if (weightedChildren.size()&gt;0) { childIncludes = \"\"\" ifdef::includeChildren[] ${weightedChildren.sort { it.weight }.collect { it.include }.join(\"\\n\")} endif::includeChildren[] \"\"\" } println deepFilename def fileHeader = \"\"\" :jbake-menu: ${folderStructure.size()&gt;0?folderStructure[0]:'-'} :jbake-deep-menu: ${folderStructure.join(\"/\")} :jbake-status: published :jbake-type: page_custom_menu :jbake-order: ${metaData.position?:'0'} :jbake-root: ${\"../\" * (folderStructure.size() )} :filename: ${metaData.filename.toString()}.adoc :filepath: ${folderStructure.join(\"/\")} include::{jbake-root}_config.adoc[] ifndef::imagesdir[:imagesdir: {jbake-root}images] \"\"\" // apply some last dirty fixes def adoc = outFileAdoc.text // fix \\r\\n for passed through asciidoc .replaceAll(\"%%CRLF%% *\", \"\\n\") // fix descrete headers .replaceAll(\"(=+) \\\\[discrete\\\\]\", \"[discrete]\\n\\$1 \") // nonbreaking space asciidoc style .replaceAll(\" \", \"{nbsp}\") // empty headline .replaceAll(\"(?sm)^ [+] *\\$\", \"\") // filepath attribute .replaceAll(\"%7Bfilepath%7D\", \"{filepath}\") println(pages[pageId].title) def linkedAttachments = \"\\n\" if (adoc.contains('%%attachments%%')) { linkedAttachments += \".Attachments\\n\\n\" attachments.findAll{it.value.pageId == pageId}.each { attachmentId, attributes -&gt; linkedAttachments += \"* link:${ \"../\" * (folderStructure.size() )}images/${folderStructure.join(\"/\")}/\" + attributes.version+\"_\"+attributes.filename +\"[\"+attributes.filename+\" (v${attributes.version})]\\n\" } adoc = adoc.replace('%%attachments%%', linkedAttachments) linkedAttachments = \"\\n\" } attachments.findAll{it.value.pageId == pageId}.each { attachmentId, attributes -&gt; linkedAttachments += \"// attachment /images/${folderStructure.join(\"/\")}/\" + attributes.filename +\"[\"+attributes.filename+\"]\\n\" } outFileAdoc.write( fileHeader + \"== ${pages[pageId].title}\\n\\n\" + adoc + linkedAttachments + \"\\n\" + childIncludes, 'utf-8' ) outFile.delete() // menuFile.append(\"\"\" //${\"*\" * folderStructure.size()} xref:${metaData.filename.toString()}.adoc[${pages[pageId].title}] //\"\"\") } } break } } return unknownTags } def createMenu(pages, startPageId) { def pageList = pages.findAll { it.value.parentId == startPageId} def menu = \"\" pageList.sort{(it.value.position?:'-1') as Integer}.each { page -&gt; def folderStructure = getFolderStructure(pages, page.key) menu += \"*\"*(folderStructure.size()+1) + \" xref:{jbake-root}\"+folderStructure.join(\"/\")+'/'+page.value.filename+\".adoc[\"+page.value.title+\"]\\n\" def childPageList = pages.findAll { it.value.parentId == page.key} if (childPageList.size()&gt;0) { menu += createMenu(pages, page.key) } } return menu } // this is where the main code starts def (File srcDir, File destDir) = parseCliArgs(args) println srcDir.canonicalPath println destDir.canonicalPath lucidInfoFile = new File( destDir,\"lucidinfos.txt\") lucidInfoFile.write(\"\", 'utf-8') File inFile = new File(srcDir, \"entities.xml\") def entities = new XmlSlurper().parseText(inFile.getText('utf-8')) def (unknownTags, pages, attachments, space, users) = parseMetaData(entities) println \"Space: \" + space copyAttachments(attachments, pages, srcDir, destDir) unknownTags &lt;&lt; extractBodies(entities, pages, attachments, space, users, destDir) unknownTags = unknownTags.unique() new File(destDir, '_config.adoc').write(\"\"\" ++++ &lt;style&gt; div.ulist ul { margin-left: 1em !important; } &lt;/style&gt; ++++ include::_menu.adoc[] ++++ &lt;!-- endtoc --&gt; ++++ \"\"\", 'utf-8') println \"\" println \"pages converted: \" + pages.findAll{it.value.status=='current'}.size() println \"unknown tags found: \" + unknownTags.unique() unknownTagsStats.sort{a, b -&gt; b.value.size() &lt;=&gt; a.value.size()}.each { tag, tagpages -&gt; println tagpages.size().toString().padLeft(5)+\" : \"+tag tagpages.each { pageid -&gt; println \" \"*10+\"- \"+pages[pageid].title } } new File(destDir, '_menu.adoc').write( createMenu(pages, 0), 'utf-8') "
},

{
    "id": 42,
    "uri": "015_tasks/03_task_createReferenceDoc.html",
    "menu": "tasks",
    "title": "createReferenceDoc",
    "text": " Table of Contents createReferenceDoc Before You Begin About This Task Config.groovy Notes Source .gravatar img { margin-left: 3px; border-radius: 4px; } createReferenceDoc 1 minute to read Before You Begin Install pandoc . About This Task This task creates a reference docx file used by pandoc during docbook-to-docx conversion. Use task convertToDocx to edit this file so it uses your preferred styles. Important The contents of the reference docx are ignored, but its stylesheets and document properties (including margins, page size, header and footer) are used in the new docx. For more information, see Pandoc User&#8217;s Guide: Options affecting specific writers (--reference-doc) And if you have problems with changing the default table style: see https://github.com/jgm/pandoc/issues/3275 . Config.groovy Notes The 'referenceDocFile' property must be set to your custom reference file in Config.groovy: inputPath = '.' // use a style reference file in the input path for conversion from docbook to docx referenceDocFile = \"${inputPath}/my-ref-file.docx\" Source Show source code of scripts/pandoc.gradle or go directly to GitHub · docToolchain/scripts/pandoc.gradle . scripts/pandoc.gradle task createReferenceDoc ( group: 'docToolchain helper', description: 'creates a docx file to be used as a format style reference in task convertToDocx. Needs pandoc installed.', type: Exec ) { workingDir \"$docDir\" executable = \"pandoc\" args = [\"-o\", \"${docDir}/${referenceDocFile}\", \"--print-default-data-file\", \"reference.docx\"] doFirst { if(!(referenceDocFile?.trim())) { throw new GradleException(\"Option `referenceDocFile` is not defined in config.groovy or has an empty value.\") } } } "
},

{
    "id": 43,
    "uri": "015_tasks/03_task_exportJiraSprintChangelog.html",
    "menu": "tasks",
    "title": "exportJiraSprintChangelogIssues",
    "text": " Table of Contents exportJiraSprintChangelogIssues About This Task Configuration Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportJiraSprintChangelogIssues 1 minute to read About This Task This task exports a simplified (key and summary) list of Jira issues for a specific sprint defined in the task configuration. Only a few additional fields (such as assignee) can be switched using configuration flags. Once you define the sprint, the relevant AsciiDoc and Excel files will be generated. If a sprint is not defined in the configuration, changelogs for all sprints that match the configuration will be saved in separate AsciiDoc files and in different tabs within an Excel file. The task configuration can be found within Config.gradle . In addition to the configuration snippet below, it is important to configure the Jira API and credentials in the Jira section of the configuration inside the same file. Configuration Config.groovy // Sprint changelog configuration generate changelog lists based on tickets in sprints of an Jira instance. // This feature requires at least Jira API &amp; credentials to be properly set in Jira section of this configuration sprintChangelog = [:] sprintChangelog.with { sprintState = 'closed' // it is possible to define multiple states, i.e. 'closed, active, future' ticketStatus = \"Done, Closed\" // it is possible to define multiple ticket statuses, i.e. \"Done, Closed, 'in Progress'\" showAssignee = false showTicketStatus = false showTicketType = true sprintBoardId = 12345 // Jira instance probably have multiple boards; here it can be defined which board should be used // Output folder for this task inside main outputPath resultsFolder = 'Sprints' // if sprintName is not defined or sprint with that name isn't found, release notes will be created on for all sprints that match sprint state configuration sprintName = 'PRJ Sprint 1' // if sprint with a given sprintName is found, release notes will be created just for that sprint allSprintsFilename = 'Sprints_Changelogs' // Extension will be automatically added. } Source Show source code of scripts/exportJiraSprintChangelog.gradle or go directly to GitHub · docToolchain/scripts/exportJiraSprintChangelog.gradle . scripts/exportJiraSprintChangelog.gradle task exportJiraSprintChangelog( description: 'exports all jira issues from Sprint for release notes', group: 'docToolchain' ) { doLast { config.targetDir = targetDir new ExportJiraSprintChangelogTask(config).execute() } } "
},

{
    "id": 44,
    "uri": "015_tasks/03_task_convertToDocx.html",
    "menu": "tasks",
    "title": "convertToDocx",
    "text": " Table of Contents convertToDocx Before You Begin Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } convertToDocx 1 minute to read Before You Begin Before using this task: Install pandoc . Ensure that 'docbook' and 'docx' are added to the inputFiles formats in Config.groovy. As an optional step, specify a reference doc file with custom stylesheets (see task createReferenceDoc ). Further Reading and Resources Read the Render AsciiDoc to docx (MS Word) blog post. Source Show source code of scripts/pandoc.gradle or go directly to GitHub · docToolchain/scripts/pandoc.gradle . scripts/pandoc.gradle task convertToDocx ( group: 'docToolchain', description: 'converts file to .docx via pandoc. Needs pandoc installed.', type: Exec ) { // All files with option `docx` in config.groovy is converted to docbook and then to docx. def sourceFilesDocx = sourceFiles.findAll { 'docx' in it.formats } def explicitSourceFilesCount = sourceFilesDocx.size() if(explicitSourceFilesCount==0){ sourceFilesDocx = sourceFiles.findAll { 'docbook' in it.formats } } sourceFilesDocx.each { def sourceFile = it.file.replace('.adoc', '.xml') def targetFile = sourceFile.replace('.xml', '.docx') new File(\"$targetDir/docx/$targetFile\") .getParentFile() .getAbsoluteFile().mkdirs() workingDir \"$targetDir/docbook\" executable = \"pandoc\" def pandocOptions = config.pandocOptions ?: [] if(referenceDocFile?.trim()) { args = [\"-r\",\"docbook\", \"-t\",\"docx\", \"-o\",\"../docx/$targetFile\", *pandocOptions, \"--reference-doc=${docDir}/${referenceDocFile}\", sourceFile] } else { args = [\"-r\",\"docbook\", \"-t\",\"docx\", \"-o\",\"./../docx/$targetFile\", *pandocOptions, sourceFile] } } doFirst { if(sourceFilesDocx.size()==0){ throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'docx'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } if(explicitSourceFilesCount==0) { logger.warn('WARNING: No source files defined for type \"docx\". Converting with best effort') } } } "
},

{
    "id": 45,
    "uri": "015_tasks/03_task_collectIncludes.html",
    "menu": "tasks",
    "title": "collectIncludes",
    "text": " Table of Contents collectIncludes About This Task The Optional Parameter Configurations Example Source .gravatar img { margin-left: 3px; border-radius: 4px; } collectIncludes 2 minutes to read About This Task This task crawls through your entire project looking for AsciiDoc files with a specific name pattern, then creates a single AsciiDoc file which includes only those files. When you create modular documentation, most includes are static. For example, the arc42-template has 12 chapters and a master template that includes those 12 chapters. Normally when you work with dynamic modules like ADRs (Architecture Decision Records) you create those files on the fly. Maybe not within your /src/docs folder, but alongside the code file for which you wrote the ADR. In order to include these files in your documentation, you have to add the file with its whole relative path to one of your AsciiDoc files. This task will handle it for you! Just stick to this file-naming pattern ^[A-Za-z]{3,}[-_].* (begin with at least three letters and a dash/underscore) and this task will collect the file and write it to your build folder. You only have to include this generated file from within your documentation. If you provide templates for the documents, those templates are skipped if the name matches the pattern ^.\\*[-\\_][tT]emplate [-\\_].* . The Optional Parameter Configurations You can configure which files are found by the script be setting the parameters in the Config.groovy file. collectIncludes = [:] collectIncludes.with { fileFilter = \"adoc\" // define which files are considered. default: \"ad|adoc|asciidoc\" minPrefixLength = \"3\" // define what minimum length the prefix. default: \"3\" maxPrefixLength = \"3\" // define what maximum length the prefix. default: \"\" separatorChar = \"_\" // define the allowed separators after prefix. default: \"-_\" cleanOutputFolder = true // should the output folder be emptied before generation? default: false excludeDirectories = [] // define additional directories that should not be traversed. } Example You have a file called: /src/java/yourCompany/domain/books/ADR-1-whyWeUseTheAISINInsteadOFISBN.adoc The task will collect this file and write another file called: /build/docs/_includes/ADR_includes.adoc &#8230;&#8203;which will look like this: include::../../../src/java/yourCompany/domain/books/ADR-1-whyWeUseTheAISINInsteadOFISBN.adoc[] Obviously, you&#8217;ll reap the most benefits if the task has several ADR files to collect. 😎 You can then include these files in your main documentation by using a single include: include::{targetDir}/docs/_includes/ADR_includes.adoc[] Source Show source code of scripts/collectIncludes.gradle or go directly to GitHub · docToolchain/scripts/collectIncludes.gradle . scripts/collectIncludes.gradle import static groovy.io.FileType.* import static groovy.io.FileVisitResult.* import java.security.MessageDigest task collectIncludes( description: 'collect all ADRs as includes in one file', group: 'docToolchain' ) { doFirst { boolean cleanOutputFolder = config.collectIncludes.cleanOutputFolder?:false String outputFolder = targetDir + '/_includes' if (cleanOutputFolder){ delete fileTree(outputFolder) } new File(outputFolder).mkdirs() } doLast { //let's search the whole project for files, not only the docs folder //exclude typical system folders final defaultExcludedDirectories = [ '.git', '.github', '.idea', '.gradle', '.repo', '.svn', 'build', 'node_modules' ] //running as subproject? set scandir to main project String scanDir_save = scanDir if (project.name!=rootProject.name &amp;&amp; scanDir=='.') { scanDir = project(':').projectDir.path } if (docDir.startsWith('.')) { docDir = file(new File(projectDir, docDir).canonicalPath) } logger.info \"docToolchain&gt; docDir: ${docDir}\" logger.info \"docToolchain&gt; scanDir: ${scanDir}\" if (scanDir.startsWith('.')) { scanDir = file(new File(docDir, scanDir).canonicalPath) } else { scanDir = file(new File(scanDir, \"\").canonicalPath) } logger.info \"docToolchain&gt; scanDir: ${scanDir}\" logger.info \"docToolchain&gt; includeRoot: ${includeRoot}\" if (includeRoot.startsWith('.')) { includeRoot = file(new File(docDir, includeRoot).canonicalPath) } logger.info \"docToolchain&gt; includeRoot: ${includeRoot}\" File sourceFolder = scanDir println \"sourceFolder: \" + sourceFolder.canonicalPath def collections = [:] String fileFilter = config.collectIncludes.fileFilter?:\"ad|adoc|asciidoc\" String minPrefixLength = config.collectIncludes.minPrefixLength?:\"3\" String maxPrefixLength = config.collectIncludes.maxPrefixLength?:\"\" String separatorChar = config.collectIncludes.separatorChar?:\"-_\" def extraExcludeDirectories = config.collectIncludes.excludeDirectories?:[] def excludedDirectories = defaultExcludedDirectories + extraExcludeDirectories String prefixRegEx = \"[A-Za-z]{\" + minPrefixLength + \",\" + maxPrefixLength + \"}\" String separatorCharRegEx = \"[\" + separatorChar + \"]\" String fileFilterRegEx = \"^\" + prefixRegEx + separatorCharRegEx + \".*[.](\" + fileFilter + \")\\$\" logger.info \"considering files with this pattern: \" + fileFilterRegEx sourceFolder.traverse( type: FILES, preDir : { if (it.name in excludedDirectories) return SKIP_SUBTREE }, excludeNameFilter: excludedDirectories ) { file -&gt; if (file.name ==~ fileFilterRegEx) { String typeRegEx = \"^(\" + prefixRegEx + \")\" + separatorCharRegEx + \".*\\$\" def type = file.name.replaceAll(typeRegEx,'\\$1').toUpperCase() if (!collections[type]) { collections[type] = [] } logger.info \"file: \" + file.canonicalPath def fileName = (file.canonicalPath - scanDir.canonicalPath)[1..-1] if (file.name ==~ '^.*[Tt]emplate.*$') { logger.info \"ignore template file: \" + fileName } else { String includeFileRegEx = \"^.*\" + prefixRegEx + \"_includes.adoc\\$\" if (file.name ==~ includeFileRegEx) { logger.info \"ignore generated _includes files: \" + fileName } else { if ( fileName.startsWith('docToolchain') || fileName.replace(\"\\\\\", \"/\").matches('^.*/docToolchain/.*$')) { //ignore docToolchain as submodule } else { logger.info \"include corrected file: \" + fileName collections[type] &lt;&lt; fileName } } } } } println \"targetFolder: \" + (targetDir - docDir) logger.info \"targetDir - includeRoot: \" + (targetDir - includeRoot) def pathDiff = '../' * ((targetDir - docDir) .replaceAll('^/','') .replaceAll('/$','') .replaceAll(\"[^/]\",'').size()+1) logger.info \"pathDiff: \" + pathDiff collections.each { type, fileNames -&gt; if (fileNames) { def outFile = new File(targetDir + '/_includes', type + '_includes.adoc') logger.info outFile.canonicalPath-sourceFolder.canonicalPath outFile.write(\"// this is autogenerated\\n\") logger.info \"docToolchain&gt; Use Antora integration: ${useAntoraIntegration}\" fileNames.sort().each { fileName -&gt; if (useAntoraIntegration) { outFile.append(\"ifndef::optimize-content[]\\n\") outFile.append (\"include::../\" + pathDiff + scanDir_save + \"/\" + fileName.replace(\"\\\\\", \"/\")+\"[]\\n\") outFile.append(\"endif::optimize-content[]\\n\\n\") outFile.append(\"ifdef::optimize-content[]\\n\") outFile.append (\"include::example\\$\" + fileName.replace(\"\\\\\", \"/\").replace(\"${inputPath}/modules/ROOT/examples/\", \"\")+\"[]\\n\") outFile.append(\"endif::optimize-content[]\\n\\n\") } else { outFile.append (\"include::../\" + pathDiff + scanDir_save + \"/\" + fileName.replace(\"\\\\\", \"/\")+\"[]\\n\\n\") } } } } } } "
},

{
    "id": 46,
    "uri": "015_tasks/03_task_generateSite.html",
    "menu": "tasks",
    "title": "generateSite",
    "text": " Table of Contents generateSite About This Task Pages Configuration Templates and Style Landing Page Blog Search CI/CD Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } generateSite 8 minutes to read About This Task When you have only one document, the output of generateHTML might meet your requirements. But as your documentation grows, and you have multiple documents, you will need a microsite which bundles all the information. The generateSite task uses jBake to create a static site with a landing page, a blog and search. Pages The microsite is page-oriented, not document-oriented. If you have already organized your documents by chapter, use them as pages to create a great user experience. The arc42-template sources are a good example. To include a page in the microsite, add a metadata header to it. page metadata :jbake-menu: arc42 :jbake-title: Solution Strategy :jbake-order: 4 :jbake-type: page_toc :jbake-status: published :filename: 015_tasks/03_task_generateSite.adoc :toc: [[section-solution-strategy]] === Solution Strategy Here is an overview of each element: jbake-menu The top-level menu&#8217;s code for this page. Defaults to the top-level folder name (without the order prefix) of the .adoc file within the docDir . Example: if the top-level folder name is 10_news it will default to the value news . For each code, the display text and the order in the top-level menu can be configured . jbake-title The title to be displayed in the drop-down top-level menu. Defaults to the first headline of the file. jbake-order Applies a sort order to drop-down entries. Defaults to a prefixed file number, such as 04 _filename.adoc or to the prefixed number of the second-level folder name. When nothing is defined the default value is -1 or -987654321 for index pages. jbake-type The page type. Controls which template is used to render the page. You will mostly use page for a full-width page or page_toc for a page with a table of contents (toc) rendered on the left. Defaults to page_toc . jbake-status Either draft or published . Only published pages will be rendered. Defaults to published for files with a jbake-order and draft for files without jbake-order or files prefixed with _ . filename Required for edit and feedback links (coming soon). Defaults to the filename :-). ifndef Fixes the imagesdir according to the nesting level of your docs folder. Defaults to the main docDir/images . toc For :jbake-type: page_toc , you need this line to generate the toc. Note Start your pages with a == level headline. You can fix the level offset when you include the page in a larger document with include::chapter.adoc[leveloffset=+1] . Configuration The configuration follows the convention-over-configuration approach. If you follow the conventions, you don&#8217;t have to configure anything. But if you want to, you can override the convention behaviour with a configuration. Menu Navigation elements The navigation is organized with following elements: A top level menu. For each item of this top level menu, a section sidebar on the left. The location of a page in the top-level menu and in the section sidebar depends on: Its location in the folder structure Page attributes Site configurations Example: src/docs/ ├── 10_foo │   ├── 10_first.adoc │   └── 20_second.adoc └── 20_bar ├── 10_lorem.adoc ├── 20_ipsum │   ├── 10_topic-A.adoc │   └── 20_topic-B.adoc └── 30_delis ├── 10_one.adoc ├── 20_two.adoc └── index.adoc The top level folders ( 10_foo and 20_bar ) are used to determine to which menu-code the page belongs ( foo and bar , unless overridden by the :jbake-menu: inside each page). In the section sidebar, the navigation tree is determined by the folder structure. Folders are nodes in the sidebar tree. Each node can contain pages (leafs) or other folders (child nodes). The order is controlled by the prefix of the file or folder name (unless overridden by the :jbake-order: inside each page). When an index page is present (like 20_bar/30_delis/index.adoc in the example) then the navigation tree node corresponds to this index page (you can click on it and the title is taken from the page). When this index.adoc does not declare a specific order with :jbake-order: then the order of the parent folder (for the example: 30 because the folder is named 30_delis ). When the index page is absent (like there is no 20_bar/20_ipsum/index.adoc in the example) then the name of the folder is used to create the node, and you can not click on the node because no pages is associated with this node. You can still define the order with the name (for the example 20 because the folder is named 20_ipsum ). When there is no sub-folder, only a flat list of pages is created. Note When an index.adoc page is defined inside the top level folder (like: 10_foo/index.adoc or 20_bar/index.adoc ) then the page will be listed in the section navigation tree in the sidebar as any other regular page. By default, it will be the first element of the tree, unless the value is overridden by a :jbake-order: attribute. Configuring the top level menu The :jbake-menu: is only the code for the menu entry to be created. You can map these codes to menu entries through the configuration ( microsite -Section) in the following way: menu = [code1: 'Some Title 1', code2: 'Other Title 2', code3: '-'] When no mapping is defined in the configuration file, the code is used as title. The menu configuration is also impacting the display order. If you have four files, located in following folder structure: src/docs ├── code1 │   ├── demo1.adoc │   └── demo2.adoc └── code3    ├── demo3.adoc    └── _demo4.adoc Where demo1.adoc and demo3.adoc contain no :jbake-menu: header, demo2.adoc contains :jbake-menu: code2 , then: demo1.adoc will have a menu-code of code1 because it is located in the folder code1 . This code is translated through the configuration to the menu named Some Title 1 . demo2.adoc is in the same folder, but the :jbake-menu: attribute has a higher precedence which results in menu-code code2 . This code is translated through the configuration to the menu named Other Title 2 . demo3.adoc will have a menu-code code3 because it is located in the folder code3 . This code is translated through the configuration to the special menu - which will not be displayed. This is an easy way to hide a menu in the rendered microsite. _demo4.adoc starts with an underscore _ and thus will be handled as draft ( :jbake-status: draft ). It will not be rendered as part of any menu, but it will be available in the microsite as \"hidden\" _demo4-draft.html . Feel free to remove these draft renderings before you publish your microsite. Links In the column on the right, links are driven by the values defined in docToolchainConfig.groovy . \"Improve this doc\": displayed when gitRepoUrl is set. \"Create an issue\": displayed when issueUrl is set. Configuring the JBake plugin Behind the scene the generateSite task is relying on Jbake. In the docToolchainConfig.groovy it is possible to amend the configuration of the jbake gradle plugin: Add additional asciidoctorj plugins (add dependencies to the jbake configuration) Add additional asciidoctor attributes jbake configuration //customization of the Jbake gradle plugin used by the generateSite task jbake.with { // possibility to configure additional asciidoctorj plugins used by jbake plugins = [ ] // possibiltiy to configure additional asciidoctor attributes passed to the jbake task asciidoctorAttributes = [ ] } The plugins are retrieved from a repository (by default maven-central) configured with project property depsMavenRepository . When a repository requiring credentials is used the properties depsMavenUsername and depsMavenPassword can be set as well. Templates and Style The jBake templates and CSS are hidden for convenience. The basic template uses Twitter Bootstrap 5 as its CSS framework. Use the copyThemes task to copy all hidden jBake resources to your project. You can then remove the resources you don&#8217;t need, and change those you want to change. Note copyThemes overwrites existing files, but because your code is safely managed using version control, this shouldn&#8217;t be a problem. Landing Page Place an index.gsp page as your landing page in src/site/templates . This landing page is plain HTML5 styled with Twitter Bootstrap. The page header and footer are added by docToolchain. An example can be found at copyThemes or on GitHub . Blog The microsite also contains a simple but powerful blog. Use it to inform your team about changes, as well as architecture decision records (ADRs). To create a new blog post, create a new file in src/docs/blog/&lt;year&gt;/&lt;post-name&gt;.adoc with the following template: blog post template :jbake-title: &lt;title-of your post&gt; :jbake-date: &lt;date formatted as 2021-02-28&gt; :jbake-type: post :jbake-tags: &lt;blog, asciidoc&gt; :jbake-status: published :imagesdir: ../../images = {jbake-title} {jbake-author} {jbake-date} &lt;insert your text here&gt; Search The microsite does not have its own local search. But it does have a search input field which can be used to link to another search engine. CI/CD When running in an automated build, set the environment variable DTC_HEADLESS to true or 1 . This stops docToolchain from asking to install the configured theme, and it will simply assume that you do want to install it. You can also avoid the theme downloading with every build by copying the themes folder from $HOME/.doctoolchain/themes to the corresponding folder in your build container. Further Reading and Resources Read about the previewSite task here. Source Show source code of scripts/generateSite.gradle or go directly to GitHub · docToolchain/scripts/generateSite.gradle . scripts/generateSite.gradle import groovy.util.* import static groovy.io.FileType.* buildscript { repositories { maven { credentials { username mavenUsername password mavenPassword } url mavenRepository } } dependencies { classpath libs.asciidoctorj.diagram } } repositories { maven { credentials { username depsMavenUsername password depsMavenPassword } url depsMavenRepository } } dependencies { jbake libs.asciidoctorj.diagram jbake libs.pebble config.jbake.plugins.each { plugin -&gt; jbake plugin } } apply plugin: 'org.jbake.site' def color = { color, text -&gt; def colors = [black: 30, red: 31, green: 32, yellow: 33, blue: 34, magenta: 35, cyan: 36, white: 37] return new String((char) 27) + \"[${colors[color]}m${text}\" + new String((char) 27) + \"[0m\" } jbake { version = '2.6.7' srcDirName = \"${targetDir}/microsite/tmp/site\" destDirName = \"${targetDir}/microsite/output\" configuration['asciidoctor.option.requires'] = \"asciidoctor-diagram\" config.microsite.each { key, value -&gt; configuration['site.'+key-'config.microsite.'] = value?:'' //println 'site.'+key-'config.microsite.' +\" = \"+ value } def micrositeContextPath = config.microsite.contextPath?:'/' configuration['asciidoctor.attributes'] = [ \"sourceDir=${targetDir}\", 'source-highlighter=prettify@', //'imagesDir=../images@', \"imagesoutDir=${targetDir}/microsite/output/images@\", \"imagesDir=${micrositeContextPath.endsWith('/') ? micrositeContextPath : micrositeContextPath.concat('/')}images@\", \"targetDir=${targetDir}\", \"docDir=${docDir}\", \"projectRootDir=${new File(docDir).canonicalPath}@\", ] if(config.jbake.asciidoctorAttributes) { config.jbake.asciidoctorAttributes.each { entry -&gt; configuration['asciidoctor.attributes'] &lt;&lt; entry } } } def prepareAndCopyTheme = { //copy internal theme println \"copy internal theme ${new File(projectDir, 'src/site').canonicalPath}\" copy { from('src/site') into(\"${targetDir}/microsite/tmp/site\") } //check if a remote pdfTheme is defined def siteTheme = System.getenv('DTC_SITETHEME')?:\"\" def themeFolder = new File(projectDir, \"../themes/\" + siteTheme.md5()) try { if (siteTheme) { println \"use siteTheme $siteTheme\" //check if it is already installed if (!themeFolder.exists()) { if (System.getenv('DTC_HEADLESS')) { ant.yesno = \"y\" } else { println \"${color 'green', \"\"\"\\nTheme '$siteTheme' is not installed yet. \"\"\"}\" def input = ant.input(message: \"\"\" ${color 'green', 'do you want me to download and install it to '} ${color 'green', ' ' + themeFolder.canonicalPath} ${color 'green', 'for you?'}\\n\"\"\", validargs: 'y,n', addproperty: 'yesno') } if (ant.yesno == \"y\") { themeFolder.mkdirs() download.run { src siteTheme dest new File(themeFolder, 'siteTheme.zip') overwrite true } copy { from zipTree(new File(themeFolder, 'siteTheme.zip')) into themeFolder } delete { delete new File(themeFolder, 'siteTheme.zip') } } else { println \"${color 'green', \"\"\"\\nI will continue without the theme for now... \"\"\"}\" siteTheme = \"\" } } //copy external theme if (siteTheme) { copy { from(themeFolder) {} into(\"${targetDir}/microsite/tmp/\") } //check if the config has to be updated // check if config still contains /** microsite **/ def configFile = new File(docDir, mainConfigFile) def configFileText = configFile.text if (configFileText.contains(\"/** start:microsite **/\")) { def configFragment = new File(targetDir,'/microsite/tmp/site/configFragment.groovy') if (configFragment.exists()) { println \"${color 'green', \"\"\" It seems that this theme is used for the first time in this project. Let's configure it! If you are unsure, change these settings later in your config file $configFile.canonicalPath \"\"\"}\" def comment = \"\" def conf = \"\" def example = \"\" def i = 0 configFragment.eachLine { line -&gt; if (line.trim()) { if (line.startsWith(\"//\")) { conf += \" \" + line + \"\\n\" def tmp = line[2..-1].trim() comment += color('green', tmp) + \"\\n\" if (tmp.toLowerCase().startsWith(\"example\")) { example = tmp.replaceAll(\"[^ ]* \", \"\") } } else { //only prompt if there is something to prompt if (line.contains(\"##\")) { def property = line.replaceAll(\"[ =].*\", \"\") if (!example) { example = config.microsite[property] } comment = color('blue', \"$property\") + \"\\n\" + comment if (example) { ant.input(message: comment, addproperty: 'res' + i, defaultvalue: example) } else { ant.input(message: comment, addproperty: 'res' + i) } (comment, example) = [\"\", \"\"] line = line.replaceAll(\"##.+##\", ant['res' + i]) conf += \" \" + line + \"\\n\" i++ } else { conf += \" \" + line + \"\\n\" } } } else { conf += \"\\n\" } } configFile.write(configFileText.replaceAll(\"(?sm)/[*][*] start:microsite [*][*]/.*/[*][*] end:microsite [*][*]/\", \"%%marker%%\").replace(\"%%marker%%\", conf)) println color('green', \"config written\\nopen ${targetDir}/microsite/output/index.html in your browser\\nto see your microsite!\") } //copy the dummy docs (blog, landing page) to the project repository copy { from(new File(themeFolder, 'site/doc')) {} into(new File(docDir, inputPath)) } } } } } catch (Exception e) { println color('red', e.message) if (e.message.startsWith(\"Not Found\")) { themeFolder.deleteDir() throw new GradleException(\"Couldn't find theme. Did you specify the right URL?\\n\"+e.message) } else { throw new GradleException(e.message) } } //copy project theme if (config.microsite.siteFolder) { def projectTheme = new File(new File(docDir, inputPath), config.microsite.siteFolder) println \"copy project theme ${projectTheme.canonicalPath}\" copy { from(projectTheme) {} into(\"${targetDir}/microsite/tmp/site\") } } } def convertAdditionalFormats = { if (config.microsite.additionalConverters) { File sourceFolder = new File(targetDir, '/microsite/tmp/site/doc') sourceFolder.traverse(type: FILES) { file -&gt; def extension = '.' + file.name.split(\"[.]\")[-1] if (config.microsite.additionalConverters[extension]) { def command = config.microsite.additionalConverters[extension].command def type = config.microsite.additionalConverters[extension].type def binding = new Binding([ file : file, config: config ]) def shell = new GroovyShell(getClass().getClassLoader(), binding) switch (type) { case 'groovy': shell.evaluate(command) break case 'groovyFile': shell.evaluate(new File(docDir, command).text) break case 'bash': if (command=='dtcw:rstToHtml.py') { // this is an internal script command = projectDir.canonicalPath+'/scripts/rstToHtml.py' } command = ['bash', '-c', command + ' \"' + file + '\"'] def process = command.execute([], new File(docDir)) process.waitFor() if (process.exitValue()) { def error = process.err.text println \"\"\" can't convert '${file.canonicalPath-docDir-'/build/microsite/tmp/site/doc'}': ${error} \"\"\" throw new Exception(\"\"\" can't convert '${file.canonicalPath-docDir-'/build/microsite/tmp/site/doc'}': ${error} \"\"\") } } } } } } def parseAsciiDocAttribs = { origText, jbake -&gt; def parseAttribs = true def text = \"\" def beforeToc = \"\" origText.eachLine { line -&gt; if (parseAttribs &amp;&amp; line.startsWith(\":jbake\")) { def parsedJbakeAttribute = (line - \":jbake-\").split(\": +\", 2) if(parsedJbakeAttribute.length != 2) { logger.warn(\"jbake-attribute is not valid or Asciidoc conform: $line\") logger.warn(\"jbake-attribute $line will be ignored, trying to continue...\") } else { jbake[parsedJbakeAttribute[0]] = parsedJbakeAttribute[1] } } else { if (line.startsWith(\"[\")) { // stop parsing jBake-attribs when a [source] - block starts which might contain those attribs as example parseAttribs = false } text += line+\"\\n\" //there are some attributes which have to be set before the toc if (line.startsWith(\":toc\") ) { beforeToc += line+\"\\n\" } } } return [text, beforeToc] } def parseOtherAttribs = { origText, jbake -&gt; if (origText.contains('~~~~~~')) { def parseAttribs = true def text = \"\" origText.eachLine { line -&gt; if (parseAttribs &amp;&amp; line.contains(\"=\")) { line = (line - \"jbake-\").split(\"=\", 2) jbake[line[0]] = line[1] } else { if (line.startsWith(\"~~~~~~\")) { // stop parsing jBake-attribs when delimiter shows up parseAttribs = false } else { text += line + \"\\n\" } } } return text } else { return origText } } def renderHeader = { fileName, jbake -&gt; def header = '' if (fileName.toLowerCase() ==~ '^.*(html|md)$') { jbake.each { key, value -&gt; if (key == 'order') { header += \"jbake-${key}=${(value ?: '1') as Integer}\\n\" } else { if (key in ['type', 'status']) { header += \"${key}=${value}\\n\" } else { header += \"jbake-${key}=${value}\\n\" } } } header += \"~~~~~~\\n\\n\" } else { jbake.each { key, value -&gt; if (key == 'order') { header += \":jbake-${key}: ${(value ?: '1') as Integer}\\n\" } else { header += \":jbake-${key}: ${value}\\n\" } } } return header } def fixMetaDataHeader = { //fix MetaData-Header File sourceFolder = new File(targetDir, '/microsite/tmp/site/doc') logger.info(\"sourceFolder: \" + sourceFolder.canonicalPath) sourceFolder.traverse(type: FILES) { file -&gt; if (file.name.toLowerCase() ==~ '^.*(ad|adoc|asciidoc|html|md)$') { if (file.name.startsWith(\"_\") || file.name.startsWith(\".\")) { //ignore } else { def origText = file.text //parse jbake attributes def text = \"\" def jbake = [ status: \"published\", order: -1, type: 'page_toc' ] if (file.name.toLowerCase() ==~ '^.*(md|html)$') { // we don't have a toc for md or html jbake.type = 'page' } def beforeToc = \"\" if (file.name.toLowerCase() ==~ '^.*(ad|adoc|asciidoc)$') { (text, beforeToc) = parseAsciiDocAttribs(origText, jbake) } else { text = parseOtherAttribs(origText, jbake) } def name = file.canonicalPath - (sourceFolder.canonicalPath+File.separator) if (File.separator=='\\\\') { name = name.split(\"\\\\\\\\\") } else { name = name.split(\"/\") } if (name.size()&gt;1) { if (!jbake.menu) { jbake.menu = name[0] if (jbake.menu ==~ /[0-9]+[-_].*/) { jbake.menu = jbake.menu.split(\"[-_]\", 2)[1] } } def docname = name[-1] if (docname ==~ /[0-9]+[-_].*/) { jbake.order = docname.split(\"[-_]\",2)[0] docname = docname.split(\"[-_]\",2)[1] } if (name.size() &gt; 2) { if ((jbake.order as Integer)==0) { // let's take the order from the second level dir or file and not the file def secondLevel = name[1] if (secondLevel ==~ /[0-9]+[-_].*/) { jbake.order = secondLevel.split(\"[-_]\",2)[0] } } else { if (((jbake.order?:'1') as Integer) &gt; 0) { // } else { jbake.status = \"draft\" } } } if (jbake.order==-1 &amp;&amp; docname.startsWith('index')) { jbake.order = -987654321 // special 'magic value' given to index pages. jbake.status = \"published\" } // news blog if (jbake.order==-1 &amp;&amp; jbake.type=='post') { jbake.order = 0 try { jbake.order = Date.parse(\"yyyy-MM-dd\", jbake.date).time / 100000 } catch ( Exception e) { System.out.println \"unparsable date ${jbake.date} in $name\" } jbake.status = \"published\" } def leveloffset = 0 if (file.name.toLowerCase() ==~ '^.*(ad|adoc|asciidoc)$') { text.eachLine { line -&gt; if (!jbake.title &amp;&amp; line ==~ \"^=+ .*\") { jbake.title = (line =~ \"^=+ (.*)\")[0][1] def level = (line =~ \"^(=+) .*\")[0][1] if (level == \"=\") { leveloffset = 1 } } } } else { if (file.name.toLowerCase() ==~ '^.*(html)$') { if (!jbake.title) { text.eachLine { line -&gt; if (!jbake.title &amp;&amp; line ==~ \"^&lt;h[1-9]&gt;.*&lt;/h.*\") { jbake.title = (line =~ \"^&lt;h[1-9]&gt;(.*)&lt;/h.*\")[0][1] } } } } else { // md if (!jbake.title) { text.eachLine { line -&gt; if (!jbake.title &amp;&amp; line ==~ \"^#+ .*\") { jbake.title = (line =~ \"^#+ (.*)\")[0][1] } } } } } if (!jbake.title) { jbake.title = docname } if (leveloffset==1) { //leveloffset needed // we always start with \"==\" not with \"=\" // only used for adoc text = text.replaceAll(\"(?ms)^(=+) \", '$1= ') } if (config.microsite.customConvention) { def binding = new Binding([ file : file, sourceFolder : sourceFolder, config: config, headers : jbake ]) def shell = new GroovyShell(getClass().getClassLoader(), binding) shell.evaluate(config.microsite.customConvention) System.out.println jbake } def header = renderHeader(file.name, jbake) if (file.name.toLowerCase() ==~ '^.*(ad|adoc|asciidoc)$') { file.write(header + \"\\nifndef::dtc-magic-toc[]\\n:dtc-magic-toc:\\n$beforeToc\\n\\n:toc: left\\n\\n++++\\n&lt;!-- endtoc --&gt;\\n++++\\nendif::[]\\n\" + text, \"utf-8\") } else { file.write(header + \"\\n\" + text, \"utf-8\") } } } } } } task generateSite( group: 'docToolchain', description: 'generate a microsite using jBake.') { doLast { new File(\"${targetDir}/microsite/tmp\").mkdirs() println new File(\"${targetDir}/microsite/tmp/\").canonicalPath prepareAndCopyTheme() //copy docs copy { from(new File(docDir, inputPath)) {} into(\"${targetDir}/microsite/tmp/site/doc\") } // if configured, convert restructuredText or anything else convertAdditionalFormats() // convention over configuration fixMetaDataHeader() } } task previewSite( group: 'docToolchain', dependsOn: [], description: 'preview your Microsite', ) { doLast { println(\"previewSite command has been deprecated.\") println(\"To preview your site, open ${targetDir}/microsite/output/index.html in your browser.\") println(\"To read alternative ways to preview your site, please consult the documentation.\") } } previewSite.dependsOn(generateSite) previewSite.mustRunAfter(bake) task copyImages(type: Copy) { config.imageDirs.each { imageDir -&gt; from(new File (new File(docDir, inputPath),imageDir)) {} logger.info ('imageDir: '+imageDir) into(\"${targetDir}/microsite/output/images\") } config.resourceDirs.each { resource -&gt; from(new File(file(srcDir),resource.source)) logger.info ('resource: '+resource.source) into(\"${targetDir}/microsite/output/\" + resource.target) } } bake.dependsOn copyImages generateSite.finalizedBy bake "
},

{
    "id": 47,
    "uri": "015_tasks/03_task_exportContributors.html",
    "menu": "tasks",
    "title": "exportContributors",
    "text": " Table of Contents exportContributors About This Task How to Use This Task About the Avatar-Icons File Attributes .gravatar img { margin-left: 3px; border-radius: 4px; } exportContributors 3 minutes to read About This Task This task crawls through all Asciidoctor source files and extracts a list of contributors, which is then rendered as AsciiDoc images of each contributor&#8217;s gravatar picture. The extracted list is stored in /home/runner/work/docToolchain/docToolchain/build/contributors/015_tasks/03_task_exportContributors.adoc so it can be easily included in your documents. How to Use This Task The best way to use this task is to create a feedback.adoc file similar to this: feedback.adoc ifndef::backend-pdf[] // (1) image::https://img.shields.io/badge/improve-this%20doc-orange.svg[link={manualdir}{filename}, float=right] // (2) image::https://img.shields.io/badge/create-an%20issue-blue.svg[link=\"https://github.com/docToolchain/documentation/issues/new?title=&amp;body=%0A%0A%5BEnter%20feedback%20here%5D%0A%0A%0A---%0A%23page:{filename}\", float=right] // (3) endif::[] include::{targetDir}/contributors/{filename}[] // (4) Key: Do not show this section when docs are rendered as PDF. Create an Improve This Doc button which links to your GitHub sources. Create a Create an Issue button which links to your issue tracker. Include the list of contributors created by this task. (The task automatically adds the estimated reading time to the list of contributors.) About the Avatar-Icons It seems not to be possible to extract a link to the github avatar icons from the log. So, the solution is to use Gravatar icons. For this to work, the contributors email address is hashed and an icon link is generated from that hash. http://www.gravatar.com/avatar/cc5f3bf8b3cb91c985ed4fd046aa451d?d=identicon This result at least in an icon which has a distinct color. Contributors can set up their own image through Gravatar.com . For this to work, the git commits need to use an email address which can be verified by Gravatar.com. Unfortunately, this is not the case if a contributor decided to make his email address private in the email sections of her github account. File Attributes This task also exports some GitHub file attributes. The extracted attributes are stored in /home/runner/work/docToolchain/docToolchain/build/fileattribs/015_tasks/03_task_exportContributors.adoc . :lastUpdated: 16.05.2019 06:22 :lastAuthorName: Ralf D. Müller :lastAuthorEmail: ralf.d.mueller@gmail.com :lastAuthorAvatar: http://www.gravatar.com/avatar/cc5f3bf8b3cb91c985ed4fd046aa451d?d=identicon[32,32,role='gravatar',alt='Ralf D. Müller',title='Ralf D. Müller'] :lastMessage: #310 started to document config options You can import and use these attributes in the same way as you import the contributors list. Important please make sure that you do not accidentally publish the email address if your contributors do not want it. For example: feedback.adoc include::{targetDir}/fileattribs/{filename}[] Last updated {lastUpdated} by {lastAuthorName} "
},

{
    "id": 48,
    "uri": "015_tasks/03_task_downloadTemplate.html",
    "menu": "tasks",
    "title": "downloadTemplate",
    "text": " Table of Contents downloadTemplate About This Task Setup and Configuration experimental Antora support Further Reading and Resources .gravatar img { margin-left: 3px; border-radius: 4px; } downloadTemplate 2 minutes to read About This Task This task is primarily used to bootstrap a new project. You can choose to download an official template like arc42 or req42 (both available in multiple languages) or you can register and use your own custom template. Setup and Configuration You can choose to bootstrap your project as an Antora project or as a plain AsciiDoc project. The Antora integration is currently in beta. The Antora integration enables you to register the project seamlessly with an existing Antora playbook. experimental Antora support to test the Antora template install antora: https://docs.antora.org/antora/latest/install/install-antora/ download the arc42 template as antora style ./dtcw downloadTemplate create a playbook.yaml within the root of your project make sure that your project is a valid git repository and contains at least one commit execute antora playbook.yml playbook.yml site: title: Antora ARC42 Template start_page: arc42-template::index.adoc content: sources: - url: ./ start_path: src/docs/arc42 branches: [HEAD] ui: bundle: url: https://gitlab.com/antora/antora-ui-default/-/jobs/artifacts/HEAD/raw/build/ui-bundle.zip?job=bundle-stable snapshot: true asciidoc: attributes: sectanchors: true output: dir: build/antora Note To install antora, follow the instructions on https://docs.antora.org/antora/latest/install-and-run-quickstart/ Further Reading and Resources Arc42 Req42 "
},

{
    "id": 49,
    "uri": "015_tasks/03_task_generateDeck.html",
    "menu": "tasks",
    "title": "generateDeck",
    "text": " Table of Contents generateDeck About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } generateDeck 1 minute to read About This Task This task makes use of the asciidoctor-reveal.js backend to render your documents into an HTML-based presentation. It creates a PowerPoint presentation, then enriches it by adding reveal.js slide definitions in AsciiDoc to the speaker notes. For best results, use this task with the exportPPT task. Configure RevealJs docToolchain comes with some opinionated, sane defaults for RevealJs. You can overwrite any of them and provide further configuration as per asciidoctor-reveal.js documentation. Source Show source code of scripts/AsciiDocBasics.gradle or go directly to GitHub · docToolchain/scripts/AsciiDocBasics.gradle . scripts/AsciiDocBasics.gradle task generateDeck ( type: AsciidoctorJRevealJSTask, group: 'docToolchain', description: 'use revealJs as asciidoc backend to create a presentation') { // corresponding Asciidoctor reveal.js config // :revealjs_theme: theme = 'black' revealjsOptions { // :revealjs_hideAddressBar: hideAddressBarOnMobile = 'true' // :revealjs_history: pushToHistory = 'true' // :revealjs_progress: progressBar = 'true' // :revealjs_slideNumber: slideNumber = 'true' // :revealjs_touch: touchMode = 'true' // :revealjs_transition: transition = 'linear' } attributes ( 'idprefix': 'slide-', 'idseparator': '-', 'docinfo1': '', ) def sourceFilesREVEAL = findSourceFilesByType(['revealjs']) sources { sourceFilesREVEAL.each { include it.file logger.info it.file File useFile = new File(srcDir, it.file) if (!useFile.exists()) { throw new Exception (\"\"\" The file $useFile in REVEAL config does not exist! Please check the configuration 'inputFiles' in $mainConfigFile.\"\"\") } } } outputDir = file(targetDir+'/decks/') resources { from(sourceDir) { include 'images/**' } into(\"\") logger.info \"${docDir}/${config.outputPath}/images\" } doFirst { if (sourceFilesREVEAL.size()==0) { throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'revealjs'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } } } generateDeck.dependsOn asciidoctorGemsPrepare "
},

{
    "id": 50,
    "uri": "015_tasks/03_task_generateContent.html",
    "menu": "tasks",
    "title": "generateContent",
    "text": " Table of Contents generateContent About This Task Configuration Example Source .gravatar img { margin-left: 3px; border-radius: 4px; } generateContent 3 minutes to read About This Task This task makes use of openAI to render documentation into your input Asciidoc files. It can help you to get started with the outline of your documentation or even with real content. This task implements OpenAI completions . Simply put an asciidoc comment block that starts with AI: followed by your description what you need. Note You need a valid API-Key from OpenAI to execute this task. Be aware that whatever content you use to describe what you want, OpenAI will process this data! Configuration Config.groovy // Configuration for openAI related tasks openAI = [:] openAI.with { // This task requires a person access token for openAI. // Ensure to pass this token as parameters when calling the task // using -PopenAI.token=xx-xxxxxxxxxxxxxx //model = \"text-davinci-003\" //maxToken = '500' //temperature = '0.3' } Warning Token is a credential, it is best not to put it into your config, but pass this parameter to the task using -PopenAI.token=xx-xxxxxxxxxxxxx at task execution. Example Given a config in your project, that specifies the following inputFiles: docToolchainConfig.groovy /** config redacted **/ inputFiles = [ [file: 'example/example.adoc', formats: ['html','pdf', 'docbook']], /** inputFiles **/ ] /** config redacted **/ You could generate a whole file, e.g. an outline for your documentation. example/example.adoc //// AI: Create an outline for a documentation of a Java based microservice called fraud-detector. The documentation should follow the Divio structure. Use Asciidoc syntax for the output. The result should define a toc. //// Note The result varies based on your input you give, the more specific you are, the better suited the output. The result could look like the following: example/example.adoc = Fraud-Detector :toc: == Overview * Description of fraud-detector microservice * Abstract view of architecture * List of core libraries used == Getting Started * Setup instructions * How to add it as a dependency * Configuration instructions == Architecture * In-depth view of architecture * Components * Services * Data Structure == Development * Contribution Guidelines * Coding Standards * Debugging Suggestions == Troubleshooting * Known Issues and Solutions * Support == FAQs * Common Questions and Answers You can also let just parts of your docs, like installation of basic tools, e.g. JDK 17, generate. Note You can specify as many AI: blocks as you want. They will al be replaced by openAI. example/example.adoc == Getting Started * Setup instructions //// AI: Write a short how-to install JDK 17 on Windows, Mac and Linux using sdkman. Use Asciidoc syntax for the output. //// * How to add it as a dependency The example above, will lead to a result similar to: example/example.adoc = Installing JDK 17 using SDKMAN JDK 17 is a version of the Java Development Kit that is suitable for general use. It can be installed quickly and easily with the help of SDKMAN. This guide includes instructions for installation on Windows, Mac and Linux operating systems. == Windows JDK 17 can be installed on Windows with the following commands: [source,shell] ---- sdk install java 17.0.1-open ---- == Mac JDK 17 can be installed on Mac with the following commands: [source,shell] ---- sdk install java 17.0.1-open ---- == Linux JDK 17 can be installed on Linux with the following commands: [source,shell] ---- sdk install java 17.0.1-open ---- Source Show source code of scripts/generateContent.gradle or go directly to GitHub · docToolchain/scripts/generateContent.gradle . scripts/generateContent.gradle task generateContent ( description: 'Generate documentation with the help of OpenAI', group: 'docToolchain' ) { doLast{ def token = findProperty(\"openAI.token\")?:null if(token == null){ throw new Exception (\"\"\" &gt;&gt; No Token provided for openAI. &gt;&gt; Please specify the token passing the parameter -PopenAI.token=xx-xxxxxxxxxxxxxxxx \"\"\") } def model = (findProperty(\"openAI.model\")?:config.openAI.model)?:\"text-davinci-003\" def maxToken = (findProperty(\"openAI.maxToken\")?:config.openAI.maxToken)?:500 def temperature = (findProperty(\"openAI.temperature\")?:config.openAI.temperature)?:0.3 logger.info \"docToolchain&gt; Generating AI content\" logger.info \"docToolchain&gt; using model ${model}\" logger.info \"docToolchain&gt; limiting output to ${maxToken} tokens\" def pattern = /\\/\\/\\/\\/[\\r\\n\\s]AI:*(.*?)[\\r\\n\\s]*\\/\\/\\/\\// // match asciidoc block comments def service = new OpenAiService(token, Duration.ofSeconds(60)); def sourceFiles = config.inputFiles srcDir = \"${docDir}/${inputPath}\" logger.info \"docToolchain&gt; Checking for AI comment block in ${sourceFiles}\" sourceFiles.every { def sourceFile = new File(srcDir, it.file) def alltext = sourceFile.text def matcher = alltext =~ pattern matcher.each { match -&gt; println(\"---------\") println(\"Request: \\n${match[1]}\") println(\"---------\") def completionRequest = CompletionRequest.builder() .prompt(match[1]) .model(model) .maxTokens(maxToken) .temperature(temperature) .echo(false) .build(); def result = service.createCompletion(completionRequest).getChoices()[0] def generatedContent = result.text.replaceAll(/^[\\s\\n\\r]+/, '') if(result.finish_reason == \"length\"){ generatedContent += \"\\n// [maxToken ${maxToken} exceeded. Raise to get the full content...]\" } println(\"Result:\") println(generatedContent) alltext = alltext.replace(match[0], generatedContent) } sourceFile.write(alltext) } service.shutdownExecutor(); } } "
},

{
    "id": 51,
    "uri": "015_tasks/03_task_fixencoding.html",
    "menu": "tasks",
    "title": "fixEncoding",
    "text": " Table of Contents fixEncoding About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } fixEncoding 1 minute to read About This Task Whenever Asciidoctor has to process a file that is not UTF-8 encoded, Ruby tries to read it, then throws an error similar to this one: asciidoctor: FAILED: /home/demo/test.adoc: Failed to load AsciiDoc document - invalid byte sequence in UTF-8 Unfortunately, finding the incorrectly encoded file is difficult if a lot of includes:: are used, and Asciidoctor will only show the name of the main document. This is not Asciidoctor&#8217;s fault. The fault lies with the Ruby interpreter that sits underneath. The fixEncoding task crawls through all *.ad and *.adoc files and checks their encoding. If it comes across a file which is not UTF-8 encoded, it will rewrite it with the UTF-8 encoding. Source Show source code of scripts/fixEncoding.gradle or go directly to GitHub · docToolchain/scripts/fixEncoding.gradle . scripts/fixEncoding.gradle import groovy.util.* import static groovy.io.FileType.* task fixEncoding( description: 'finds and converts non UTF-8 adoc files to UTF-8', group: 'docToolchain helper', ) { doLast { File sourceFolder = new File(\"${docDir}/${inputPath}\") println(\"sourceFolder: \" + sourceFolder.canonicalPath) sourceFolder.traverse(type: FILES) { file -&gt; if (file.name ==~ '^.*(ad|adoc|asciidoc)$') { CharsetToolkit toolkit = new CharsetToolkit(file); // guess the encoding def guessedCharset = toolkit.getCharset().toString().toUpperCase(); if (guessedCharset!='UTF-8') { def text = file.text file.write(text, \"utf-8\") println(\" converted ${file.name} from '${guessedCharset}' to 'UFT-8'\") } } } } } "
},

{
    "id": 52,
    "uri": "015_tasks/03_task_copy_themes.html",
    "menu": "tasks",
    "title": "copyThemes",
    "text": " Table of Contents copyThemes About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } copyThemes 1 minute to read About This Task docToolchain provides you with a simple Twitter bootstrap default theme to get you started. You can use the copyThemes task to apply a different theme (either jBakeTheme or pdfTheme) to your project. Feel free to remove all files which should remain as the default and change all others. When you next run docToolchain, your theme files will be laid over the default theme in order to generate the PDF or site. Source Show source code of scripts/copyThemes.gradle or go directly to GitHub · docToolchain/scripts/copyThemes.gradle . scripts/copyThemes.gradle //tag::copyThemes[] task copyThemes( description: 'copy some default files to your project for you to modify', group: 'docToolchain helper' ) { doFirst { } doLast { def color = { color, text -&gt; def colors = [black: 30, red: 31, green: 32, yellow: 33, blue: 34, magenta: 35, cyan: 36, white: 37] return new String((char) 27) + \"[${colors[color]}m${text}\" + new String((char) 27) + \"[0m\" } def lang = ant.input(message: \"${color 'green', 'What do you want me to copy?'}\", validargs: 'pdfTheme,jBakeTheme', addproperty: 'what') switch (ant.what) { case 'pdfTheme': def targetDir = new File(pdfThemeDir) /** if (targetDir.exists()) { println \"${targetDir.canonicalPath} already exists\" println \"in order to re-install the theme, please remove the folder first and re-run the script\" throw new RuntimeException(\"pdfTheme folder already exists\") } **/ targetDir.mkdirs() def source = new File(projectDir, 'template_config/pdfTheme') println source.canonicalPath println targetDir.canonicalPath copy { from new File(projectDir, 'template_config/pdfTheme') into targetDir } println \"pdfTheme copied into ${targetDir}\" break case 'jBakeTheme': def targetDir = new File(new File(docDir, inputPath), config.microsite.siteFolder?:'../site') /** if (targetDir.exists()) { println \"${targetDir.canonicalPath} already exists\" println \"in order to re-install the theme, please remove the folder first and re-run the script\" throw new RuntimeException(\"jBakeTheme folder already exists\") } **/ targetDir.mkdirs() copy { from new File(projectDir, 'src/site') into targetDir } def siteTheme = System.getenv('DTC_SITETHEME')?:\"\" def themeFolder = new File(projectDir, \"../themes/\" + siteTheme.md5()) copy { from(themeFolder) {} into targetDir } println \"jBakeTheme copied into ${targetDir.canonicalPath}\" break } } } //end::copyThemes[] "
},

{
    "id": 53,
    "uri": "015_tasks/03_task_generateDocBook.html",
    "menu": "tasks",
    "title": "generateDocbook",
    "text": " Table of Contents generateDocbook About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } generateDocbook 1 minute to read About This Task A helper task, generateDocbook generates the intermediate format for convertToDocx &lt;&lt;&gt;&gt; and convertToEpub . Source Show source code of scripts/AsciiDocBasics.gradle or go directly to GitHub · docToolchain/scripts/AsciiDocBasics.gradle . scripts/AsciiDocBasics.gradle task generateDocbook ( type: AsciidoctorTask, group: 'docToolchain', description: 'use docbook as asciidoc backend') { def sourceFilesDOCBOOK = findSourceFilesByType(['docbook', 'epub', 'docx']) // onlyIf { // sourceFilesDOCBOOK // } sources { sourceFilesDOCBOOK.each { include it.file logger.info it.file File useFile = new File(srcDir, it.file) if (!useFile.exists()) { throw new Exception (\"\"\" The file $useFile in DOCBOOK config does not exist! Please check the configuration 'inputFiles' in $mainConfigFile.\"\"\") } } } outputOptions { backends = ['docbook'] } outputDir = file(targetDir+'/docbook/') doFirst { if (sourceFilesDOCBOOK.size()==0) { throw new Exception (\"\"\" &gt;&gt; No source files defined for type of '[docbook, epub, docx]'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } } } "
},

{
    "id": 54,
    "uri": "015_tasks/03_task_exportOpenApi.html",
    "menu": "tasks",
    "title": "exportOpenAPI",
    "text": " Table of Contents exportOpenAPI About This Task Configuration Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportOpenAPI 1 minute to read About This Task This task exports an OpenAPI Specification definition yaml file to a AsciiDoc document. Currently, this task depends on OpenAPI Generator (v4.3.1) and its gradle plugin . Configuration Config.groovy // Configuration for OpenAPI related task openApi = [:] // 'specFile' is the name of OpenAPI specification yaml file. Tool expects this file inside working dir (as a filename or relative path with filename) // 'infoUrl' and 'infoEmail' are specification metadata about further info related to the API. By default this values would be filled by openapi-generator plugin placeholders // openApi.with { specFile = 'src/docs/petstore-v2.0.yaml' // i.e. 'petstore.yaml', 'src/doc/petstore.yaml' infoUrl = 'https://my-api.company.com' infoEmail = 'info@company.com' } Source Show source code of scripts/exportOpenApi.gradle or go directly to GitHub · docToolchain/scripts/exportOpenApi.gradle . scripts/exportOpenApi.gradle task exportOpenApi ( type: org.openapitools.generator.gradle.plugin.tasks.GenerateTask, group: 'docToolchain', description: 'exports OpenAPI specification to the asciidoc file') { if (!specFile) { logger.info(\"\\n---&gt; OpenAPI specification file not found in Config.groovy (https://doctoolchain.github.io/docToolchain/#_exportopenapi)\") return } else { logger.info(\"Found OpenAPI specification in Config.groovy\") } outputs.upToDateWhen { false } outputs.cacheIf { false } generatorName = 'asciidoc' outputDir = \"${targetDir}/OpenAPI\".toString() inputSpec = \"${docDir}/${specFile}\" // plugin is not able to find file if inputPath is defined as '.' logger.debug(\"\\n=====================\\nProject Config:\\n=====================\") logger.debug(\"Docdir: ${docDir}\") logger.debug(\"Target: ${targetDir}\") logger.info(\"\\n=====================\\nOpenAPI Config:\\n=====================\") logger.info(\"Specification file: ${specFile}\") logger.info(\"inputSpec: ${inputSpec}\") logger.info(\"outputDir: ${outputDir}\\n\") additionalProperties = [ infoEmail:\"${config.openApi.infoEmail}\", infoUrl:\"${config.openApi.infoUrl}\" ] } "
},

{
    "id": 55,
    "uri": "015_tasks/03_task_exportJiraIssues.html",
    "menu": "tasks",
    "title": "exportJiraIssues",
    "text": " Table of Contents exportJiraIssues About This Task Migrate configuration to version &gt;= 3.2.0 Configuration Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportJiraIssues 3 minutes to read About This Task This task exports all issues for a given query or queries from Jira as either an AsciiDoc table, an Excel file or both. The configuration for this task can be found within Config.gradle ( gradle.properties can be used as a fallback). Username/password is deprecated, so you need to use username/API-token instead. An API-token can be created through https://id.atlassian.com/manage/api-tokens . We recommend that you keep username and API-token out of your GitHub repository, and instead pass them as environment variables to docToolchain. Migrate configuration to version &gt;= 3.2.0 Since version 3.2.0, the configuration requests is deprecated. Please migrate to and use exports instead. The old configuration will be removed in the near future. To migrate your configuration, replace the JiraRequest class with a Map. The following example shows how to migrate a configuration with a single JiraRequest to the new configuration: Prior to 3.2.0 jira.requests = [ new JiraRequest( filename: 'jiraIssues', jql: 'project = %jiraProject% AND labels = %jiraLabel%', customfields: [ 'customfield_10026': 'StoryPoints' ] ) ] will be migrated to: From 3.2.0 onwards jira.exports = [ [ filename: 'jiraIssues', jql: 'project = %jiraProject% AND labels = %jiraLabel%', customfields: [ 'customfield_10026': 'StoryPoints' ] ] ] Configuration Jira configuration support list requests to Jira where results of each request will be saved in a file with specifies filename. Flags saveAsciidoc &amp; saveExcel allow you to easily configure the format in which results should be saved. Deprecation Notice The old configuration was based on the single Jira query is deprecated (single 'jql' parameter). Support for it will be removed in the near future. Please migrate to the new configuration which allows multiple Jira queries. Since version 3.2.0, the configuration requests is deprecated. Please migrate to and use exports instead. The old configuration will be removed in the near future. Configuration Options exports (since 3.2.0), List of Maps that contains the following keys: filename : The filename of the exported file. The file extension will be added automatically. jql : The Jira query to be executed. Can have placeholders that are interpolated. Allowed placeholders are: %jiraProject% (interpolated with jira.project ), %jiraLabel% (interpolated with jira.label ) customfields : A Map of custom fields to be included in the export. Key is the technical name of the custom field in Jira, value is the name of the column in the export. rateLimit (since 3.2.0), The rate limit for Jira requests. Default is 10 requests per second. requests ( deprecated since 3.2.0, please use exports instead), List of JiraRequest that has the following properties: class JiraRequest { String filename //filename (without extension) of the file in which JQL results will be saved. Extension will be determined automatically for Asciidoc or Excel file String jql // Jira Query Language syntax Map&lt;String,String&gt; customfields // map of customFieldId:displayName values for Jira fields which don't have default names, i.e. customfield_10026:StoryPoints } Full configuration options: Config.groovy // Configuration for Jira related tasks jira = [:] jira.with { // endpoint of the JiraAPI (REST) to be used api = 'https://your-jira-instance' // requests per second for Jira API calls rateLimit = 10 /* WARNING: It is strongly recommended to store credentials securely instead of commiting plain text values to your git repository!!! Tool expects credentials that belong to an account which has the right permissions to read the JIRA issues for a given project. Credentials can be used in a form of: - passed parameters when calling script (-PjiraUser=myUsername -PjiraPass=myPassword) which can be fetched as a secrets on CI/CD or - gradle variables set through gradle properties (uses the 'jiraUser' and 'jiraPass' keys) Often, Jira &amp; Confluence credentials are the same, in which case it is recommended to pass CLI parameters for both entities as -Pusername=myUser -Ppassword=myPassword */ // the key of the Jira project project = 'PROJECTKEY' // the format of the received date time values to parse dateTimeFormatParse = \"yyyy-MM-dd'T'H:m:s.SSSz\" // i.e. 2020-07-24'T'9:12:40.999 CEST // the format in which the date time should be saved to output dateTimeFormatOutput = \"dd.MM.yyyy HH:mm:ss z\" // i.e. 24.07.2020 09:02:40 CEST // the label to restrict search to label = 'label1' // Legacy settings for Jira query. This setting is deprecated &amp; support for it will soon be completely removed. Please use JiraRequests settings jql = \"project='%jiraProject%' AND labels='%jiraLabel%' ORDER BY priority DESC, duedate ASC\" // Base filename in which Jira query results should be stored resultsFilename = 'JiraTicketsContent' saveAsciidoc = true // if true, asciidoc file will be created with *.adoc extension saveExcel = true // if true, Excel file will be created with *.xlsx extension // Output folder for this task inside main outputPath resultsFolder = 'JiraRequests' /* List of requests to Jira API: These are basically JQL expressions bundled with a filename in which results will be saved. User can configure custom fields IDs and name those for column header, i.e. customfield_10026:'Story Points' for Jira instance that has custom field with that name and will be saved in a coloumn named \"Story Points\" */ exports = [ [ filename:\"File1_Done_issues\", jql:\"project='%jiraProject%' AND status='Done' ORDER BY duedate ASC\", customfields: [customfield_10026:'Story Points'] ], [ filename:'CurrentSprint', jql:\"project='%jiraProject%' AND Sprint in openSprints() ORDER BY priority DESC, duedate ASC\", customfields: [customfield_10026:'Story Points'] ] ] } Source Show source code of scripts/exportJiraIssues.gradle or go directly to GitHub · docToolchain/scripts/exportJiraIssues.gradle . scripts/exportJiraIssues.gradle task exportJiraIssues( description: 'exports all jira issues from a given search', group: 'docToolchain' ) { doLast { config.targetDir = targetDir new ExportJiraIssuesTask(config).execute() } } "
},

{
    "id": 56,
    "uri": "015_tasks/03_task_publishToConfluence.html",
    "menu": "tasks",
    "title": "publishToConfluence",
    "text": " Table of Contents publishToConfluence About This Task Special Features Configuration Attributes CSS Styling Source .gravatar img { margin-left: 3px; border-radius: 4px; } publishToConfluence 10 minutes to read About This Task This task takes a generated HTML file, splits it by headline, and pushes it to your instance of Confluence . This lets you use the docs-as-code approach even if your organisation insists on using Confluence as its main document repository. Note From the 01.01.2024 on, Atlassian turns off API V1 for Confluence Cloud, if there is a V2 equivalent. docToolchain versions from 3.1 on support API V2. If you are using an older version of docToolchain, you&#8217;ll need to upgrade to a newer version. To enable API V2 , set useV1Api to false in the Confluence section of the docToolchain configuration file. Note Currently, docToolchain only has full support for the old Confluence editor. The new editor is not fully supported yet. You can use the new editor, but you may experience some unexpected layout issues/ changes. To make use of the new editor you need to set enforceNewEditor to true in the Confluence section of the docToolchain configuration file. Special Features Easy Code Block Conversion [source] -blocks are converted to code-macro blocks in Confluence. Confluence supports a very limited list of languages supported for code block syntax highlighting. When specifying an unknown language, it would even display an error. Therefore, some transformation is applied. If no language is given in the source block, it is explicitly set to plain text (because the default would be Java that might not always apply). Some known and common AsciiDoc source languages are mapped to Confluence code block languages. source target note json yml produces an acceptable highlighting shell bash only a specific shell is supported yaml yml different name of language If the language of the source block is not supported by Confluence, it is set to plain text as fallback to avoid the error. Note Get a list of valid languages (and learn how to add others) here . Minimal Impact on Non-Techie Confluence Users Only pages and images that changed between task runs are published, and only those changes are notified to page watchers, cutting down on 'spam'. Keywords Automatically Attached as Labels :keywords: are attached as labels to every Confluence page generated using the publishToConfluence task. See Atlassian&#8217;s own guidelines on labels . Several keywords are allowed, and they must be separated by commas. For example: :keywords: label_1, label-2, label3, &#8230;&#8203; . Labels (keywords) must not contain a space character. Use either '_' or '-'. Configuration You configure the publishToConfluence task in the file docToolchainConfig.groovy. It is located in the root of your project folder. We try to make the configuration self-explanatory, but below is some more information about each config option. input is an array of files to upload to Confluence with the ability to configure a different parent page for each file. Attributes file : absolute or relative path to the asciidoc generated html file to be exported url : absolute URL to an asciidoc generated html file to be exported ancestorName (optional): the name of the parent page in Confluence as string; this attribute has priority over ancestorId, but if page with given name doesn&#8217;t exist, ancestorId will be used as a fallback ancestorId (optional): the id of the parent page in Confluence as string; leave this empty if a new parent shall be created in the space The following four keys can also be used in the global section below spaceKey : page specific variable for the key of the confluence space to write to case sensitive! If the case is not correct, it can be that new page will be created but can&#8217;t be updated in the next run. subpagesForSections (optional): The number of nested sub-pages to create. Default is '1'. '0' means creating all on one page. The following migration for removed configuration can be used. allInOnePage = true is the same as subpagesForSections = 0 allInOnePage = false &amp;&amp; createSubpages = false is the same as subpagesForSections = 1 allInOnePage = false &amp;&amp; createSubpages = true is the same as subpagesForSections = 2 pagePrefix (optional): page specific variable, the pagePrefix will be a prefix for the page title and it&#8217;s sub-pages use this if you only have access to one confluence space but need to store several pages with the same title - a different pagePrefix will make them unique pageSuffix (optional): same usage as prefix but appended to the title and it&#8217;s subpages only 'file' or 'url' is allowed. If both are given, 'url' is ignored ancestorId The page ID of the parent page where you want your docs to be published. Go to this page, click Edit and the required ID will show up in the URL. Specify the ID as a string within the config file. api Endpoint of the confluenceAPI (REST) to be used and looks like https://[yourServer]/[context] , while [context] is optional. If you use Confluence Cloud, you can omit the context. If you use Confluence Server, you may need to set a context, depending on your Confluence configuration. rateLimit (since 3.2.0), The rate limit for Confluence requests. Default is 10 requests per second. useV1Api This feature is available for docToolchain &gt;= 3.1 only Note If you set this to false , ensure the api config is set to https://[yourCloudDomain] . (Mind no context given here) If you are using Confluence Cloud, you can set this to false to use the new API V2. If you are using Confluence Server, you can set this to true to use the old API V1. If you are using Confluence Cloud and set this to false , you will get an error message, once Atlassian turns off API V1 (starting 01.01.2024). enforceNewEditor Atlassian is currently rolling out a new editor for Confluence. If you want to use the new editor, you can set this to true . If you are using the old editor, you can set this to false . If you are using the new editor, you may experience some unexpected layout issues/ changes, since the new editor has yet no feature parity and therefore may be incompatible. disableToC This boolean configuration determines whether the table of contents (ToC) is disabled on the page once uploaded to Confluence. false by default, so the ToC is active. pagePrefix/pageSuffix Confluence can&#8217;t handle two pages with the same name - even with different casing (lowercase, UPPERCASE, a mix). This script matches pages regardless of case and refuses to replace a page whose name differs from an existing page only by casing. Ideally, you should create a new Confluence space for each piece of larger documentation. If you are restricted and can&#8217;t create new spaces, you can use pagePrefix / pageSuffix to define a prefix/suffix for the doc so that it doesn&#8217;t conflict with other page names. pageVersionComment Set an optional comment for the new page version in Confluence. credentials For security reasons it is highly recommended to store your credentials in a separate file outside the Git repository, such as in your Home folder. To authenticate with username and API token, use: credentials = \"user:${new File(\"/users/me/apitoken\").text}\" or credentials = \"user:${new File(\"/users/me/apitoken\").text}\"`.bytes.encodeBase64().toString()` to &#8230;&#8203;&#8230;&#8203;.. You can create an API-token in your profile . To authenticate with username and password, use: credentials = &#8230;&#8203;&#8230;&#8203; You can also set your username, password of apitoken as an environment variable. You then do the following: 1. Open the file that contains the environment variables: a. On a Mac, go to your Home folder and open the file .zpfrofile. 2. &#8230;&#8203;. If you wish to simplify the injection of credentials from external sources, do the following: 1. In docToolchainConfig.groovy, do not enter the credentials. Make sure the credentials are escaped. 2. Create a gradle.properties file in the project or home directory. See the gradle user guide . 3. Open the file, and put the variables in it: - confluenceUser=myusername, and on a new line - confluencePass=myuserpassword apikey In situations where you have to use full user authorisation because of internal Confluence permission handling, you&#8217;ll need to add the API-token in addition to the credentials. The API-token cannot be added to the credentials because it&#8217;s used for user and password exchange. Therefore, the API-token can be added as parameter apikey , which makes the addition of the token a separate header field with key: keyId and value of apikey . An example (including storing of the real value outside this configuration) is: apikey = \"${new File(\"/home/me/apitoken\").text}\" . bearerToken You can pass a Confluence Personal Access Token as the bearerToken . It is an alternative to credentials . Do not confuse it with apiKey . extraPageContent If you need to prefix your pages with a warning stating that 'this is generated content', this is where you do it. enableAttachments If value is set to true , any links to local file references will be uploaded as attachments. The current implementation only supports a single folder, the name of which will be used as a prefix to validate whether your file should be uploaded. If you enable this feature, and use a folder which starts with 'attachment', an adaption of this prefix is required. pageLimit Limits the number of pages retrieved from the server to check if a page with this name already exists. jiraServerId Only required if you are using Jira on-premise. If you are using Jira cloud you do not need to set this value. Stores the Jira server ID that your Confluence instance is connected to. If a value is set, all anchors pointing to a Jira ticket will be replaced by the Confluence Jira macro. How-To find your Jira server ID please check the Atlassian documentation . All files to attach will need to be linked inside the document: link:attachment/myfolder/myfile.json[My API definition] attachmentPrefix Stores the expected foldername of your output directory. Default is attachment . proxy If you need to provide proxy to access Confluence, you can set a map with the keys host (e.g. 'my.proxy.com' ), port (e.g. '1234' ) and schema (e.g. 'http' ) of your proxy. useOpenapiMacro If this option is present and equal to confluence-open-api or swagger-open-api then any source block marked with class openapi will be wrapped in the Elitesoft Swagger Editor macro (see Elitesoft Swagger Editor ). The key depends on the version of the macro. For backward compatibility, if this option is present and equal to true , then again the Elitesoft Swagger Editor macro will be used. If this option is present and equal to \"open-api\" then any source block marked with class openapi will be wrapped in Open API Documentation for Confluence macro: (see Open API Documentation for Confluence ). A download source (yaml) button is shown by default. Using the plugin can be handled on different ways. copy/paste the content of the YAML file to the plugin without linking to the origin source by using the url to the YAML file [source.openapi,yaml] ---- \\include::https://my-domain.com/path-to-yaml[] ---- copy/paste the content of the YAML file to the plugin without linking to the origin source by using a YAML file in your project structure: [source.openapi,yaml] ---- \\include::my-yaml-file.yaml[] ---- create a link between the plugin and the YAML file without copying the content into the plugin. The advantage following this way is that even in case the API specification is changed without re-generating the documentation, the new version of the configuration is used in Confluence. [source.openapi,yaml,role=\"url:https://my-domain.com/path-to-yaml\"] ---- \\include::https://my-domain.com/path-to-yaml[] ---- publishToConfluence.gradle //Configureation for publishToConfluence confluence = [:] // 'input' is an array of files to upload to Confluence with the ability // to configure a different parent page for each file. // // Attributes // - 'file': absolute or relative path to the asciidoc generated html file to be exported // - 'url': absolute URL to an asciidoc generated html file to be exported // - 'ancestorName' (optional): the name of the parent page in Confluence as string; // this attribute has priority over ancestorId, but if page with given name doesn't exist, // ancestorId will be used as a fallback // - 'ancestorId' (optional): the id of the parent page in Confluence as string; leave this empty // if a new parent shall be created in the space // Set it for every file so the page scanning is done only for the given ancestor page trees. // // The following four keys can also be used in the global section below // - 'spaceKey' (optional): page specific variable for the key of the confluence space to write to // - 'subpagesForSections' (optional): The number of nested sub-pages to create. Default is '1'. // '0' means creating all on one page. // The following migration for removed configuration can be used. // 'allInOnePage = true' is the same as 'subpagesForSections = 0' // 'allInOnePage = false &amp;&amp; createSubpages = false' is the same as 'subpagesForSections = 1' // 'allInOnePage = false &amp;&amp; createSubpages = true' is the same as 'subpagesForSections = 2' // - 'pagePrefix' (optional): page specific variable, the pagePrefix will be a prefix for the page title and it's sub-pages // use this if you only have access to one confluence space but need to store several // pages with the same title - a different pagePrefix will make them unique // - 'pageSuffix' (optional): same usage as prefix but appended to the title and it's subpages // only 'file' or 'url' is allowed. If both are given, 'url' is ignored confluence.with { input = [ [ file: \"build/docs/html5/arc42-template-de.html\" ], ] // endpoint of the confluenceAPI (REST) to be used // https://[yourServer] api = 'https://[yourServer]' // requests per second for confluence API calls rateLimit = 10 // Additionally, spaceKey, subpagesForSections, pagePrefix and pageSuffix can be globally defined here. The assignment in the input array has precedence // the key of the confluence space to write to spaceKey = 'asciidoc' // if true, all pages will be created using the new editor v2 // enforceNewEditor = false // variable to determine how many layers of sub pages should be created subpagesForSections = 1 // the pagePrefix will be a prefix for each page title // use this if you only have access to one confluence space but need to store several // pages with the same title - a different pagePrefix will make them unique pagePrefix = '' pageSuffix = '' /* WARNING: It is strongly recommended to store credentials securely instead of commiting plain text values to your git repository!!! Tool expects credentials that belong to an account which has the right permissions to to create and edit confluence pages in the given space. Credentials can be used in a form of: - passed parameters when calling script (-PconfluenceUser=myUsername -PconfluencePass=myPassword) which can be fetched as a secrets on CI/CD or - gradle variables set through gradle properties (uses the 'confluenceUser' and 'confluencePass' keys) Often, same credentials are used for Jira &amp; Confluence, in which case it is recommended to pass CLI parameters for both entities as -Pusername=myUser -Ppassword=myPassword */ //optional API-token to be added in case the credentials are needed for user and password exchange. //apikey = \"[API-token]\" // HTML Content that will be included with every page published // directly after the TOC. If left empty no additional content will be // added // extraPageContent = '&lt;ac:structured-macro ac:name=\"warning\"&gt;&lt;ac:parameter ac:name=\"title\" /&gt;&lt;ac:rich-text-body&gt;This is a generated page, do not edit!&lt;/ac:rich-text-body&gt;&lt;/ac:structured-macro&gt; extraPageContent = '' // enable or disable attachment uploads for local file references enableAttachments = false // default attachmentPrefix = attachment - All files to attach will require to be linked inside the document. // attachmentPrefix = \"attachment\" // Optional proxy configuration, only used to access Confluence // schema supports http and https // proxy = [host: 'my.proxy.com', port: 1234, schema: 'http'] // Optional: specify which Confluence OpenAPI Macro should be used to render OpenAPI definitions // possible values: [\"confluence-open-api\", \"open-api\", \"swagger-open-api\", true]. true is the same as \"confluence-open-api\" for backward compatibility // useOpenapiMacro = \"confluence-open-api\" } CSS Styling Some AsciiDoctor features depend on specific CSS style definitions. Unless these styles are defined, some formatting that is present in the HTML version will not be represented when published to Confluence. To configure Confluence to include additional style definitions: Log in to Confluence as a space admin. Go to the desired space. Select Space tools &gt; Look and Feel &gt; Stylesheet . Click Edit then enter the desired style definitions. Click Save . The default style definitions can be found in the AsciiDoc project as asciidoctor-default.css . You will most likely NOT want to include the entire thing, as some of the definitions are likely to disrupt Confluence&#8217;s layout. The following style definitions are Confluence-compatible, and will enable the use of the built-in roles ( big / small , underline / overline / line-through , COLOR / COLOR -background for the sixteen HTML color names ): .big{font-size:larger} .small{font-size:smaller} .underline{text-decoration:underline} .overline{text-decoration:overline} .line-through{text-decoration:line-through} .aqua{color:#00bfbf} .aqua-background{background-color:#00fafa} .black{color:#000} .black-background{background-color:#000} .blue{color:#0000bf} .blue-background{background-color:#0000fa} .fuchsia{color:#bf00bf} .fuchsia-background{background-color:#fa00fa} .gray{color:#606060} .gray-background{background-color:#7d7d7d} .green{color:#006000} .green-background{background-color:#007d00} .lime{color:#00bf00} .lime-background{background-color:#00fa00} .maroon{color:#600000} .maroon-background{background-color:#7d0000} .navy{color:#000060} .navy-background{background-color:#00007d} .olive{color:#606000} .olive-background{background-color:#7d7d00} .purple{color:#600060} .purple-background{background-color:#7d007d} .red{color:#bf0000} .red-background{background-color:#fa0000} .silver{color:#909090} .silver-background{background-color:#bcbcbc} .teal{color:#006060} .teal-background{background-color:#007d7d} .white{color:#bfbfbf} .white-background{background-color:#fafafa} .yellow{color:#bfbf00} .yellow-background{background-color:#fafa00} Source Show source code of scripts/publishToConfluence.gradle or go directly to GitHub · docToolchain/scripts/publishToConfluence.gradle . scripts/publishToConfluence.gradle task publishToConfluence( description: 'publishes the HTML rendered output to confluence', group: 'docToolchain' ) { doLast { logger.info(\"docToolchain&gt; docDir: \"+docDir) config.confluence.api = findProperty(\"confluence.api\")?:config.confluence.api //TODO default should be false, if the V1 has been removed in cloud config.confluence.useV1Api = findProperty(\"confluence.useV1Api\") != null ? findProperty(\"confluence.useV1Api\") : config.confluence.useV1Api != [:] ? config.confluence.useV1Api :true Asciidoc2ConfluenceTask.From(config, docDir).execute() } } Show source code of core/src/main/groovy/org/docToolchain/scripts/asciidoc2confluence.groovy or go directly to GitHub · docToolchain/core/src/main/groovy/org/docToolchain/scripts/asciidoc2confluence.groovy . core/src/main/groovy/org/docToolchain/scripts/asciidoc2confluence.groovy package org.docToolchain.scripts /** * THIS SCRIPT HAS BEEN DEPRECATED. IT IS NOT USED ANYMORE. PLEASE REFER TO THE NEW Asciidoc2ConfluenceTask * IMPLEMENTATION INSTEAD. REFERENCE ONLY. */ import org.docToolchain.atlassian.transformer.HtmlTransformer /** * Created by Ralf D. Mueller and Alexander Heusingfeld * https://github.com/rdmueller/asciidoc2confluence * * this script expects an HTML document created with AsciiDoctor * in the following style (default AsciiDoctor output) * &lt;div class=\"sect1\"&gt; * &lt;h2&gt;Page Title&lt;/h2&gt; * &lt;div class=\"sectionbody\"&gt; * &lt;div class=\"sect2\"&gt; * &lt;h3&gt;Sub-Page Title&lt;/h3&gt; * &lt;/div&gt; * &lt;div class=\"sect2\"&gt; * &lt;h3&gt;Sub-Page Title&lt;/h3&gt; * &lt;/div&gt; * &lt;/div&gt; * &lt;/div&gt; * &lt;div class=\"sect1\"&gt; * &lt;h2&gt;Page Title&lt;/h2&gt; * ... * &lt;/div&gt; * */ /* Additions for issue #342 marked as #342-dierk42 ;-) */ // some dependencies import org.jsoup.nodes.Document import org.jsoup.nodes.Element import org.jsoup.nodes.Entities import org.jsoup.nodes.TextNode import org.jsoup.select.Elements import groovy.transform.Field import java.nio.charset.Charset import java.nio.file.Path import java.security.MessageDigest import static groovy.io.FileType.FILES import org.docToolchain.atlassian.confluence.clients.ConfluenceClientV1 import org.docToolchain.atlassian.confluence.clients.ConfluenceClientV2 import org.docToolchain.configuration.ConfigService import org.docToolchain.atlassian.confluence.ConfluenceService @Field ConfigService configService = new ConfigService(config) @Field ConfluenceService confluenceService = new ConfluenceService(configService) @Field def confluenceClient = configService.getConfigProperty(\"confluence.useV1Api\") ? new ConfluenceClientV1(configService) : new ConfluenceClientV2(configService) @Field def CDATA_PLACEHOLDER_START = '&lt;cdata-placeholder&gt;' @Field def CDATA_PLACEHOLDER_END = '&lt;/cdata-placeholder&gt;' @Field def baseUrl def allPages // #938-mksiva: global variable to hold input spaceKey passed in the Config.groovy def spaceKeyInput // configuration def confluenceSpaceKey def confluenceSubpagesForSections @Field def confluencePagePrefix @Field def confluencePageSuffix //def baseApiPath = new URI(config.confluence.api).path // helper functions def MD5(String s) { MessageDigest.getInstance(\"MD5\").digest(s.bytes).encodeHex().toString() } def parseAdmonitionBlock(block, String type) { content = block.select(\".content\").first() titleElement = content.select(\".title\") titleText = '' if(titleElement != null) { titleText = \"&lt;ac:parameter ac:name=\\\"title\\\"&gt;${titleElement.text()}&lt;/ac:parameter&gt;\" titleElement.remove() } block.after(\"&lt;ac:structured-macro ac:name=\\\"${type}\\\"&gt;${titleText}&lt;ac:rich-text-body&gt;${content}&lt;/ac:rich-text-body&gt;&lt;/ac:structured-macro&gt;\") block.remove() } /* #342-dierk42 add labels to a Confluence page. Labels are taken from :keywords: which are converted as meta tags in HTML. Building the array: see below Confluence allows adding labels only after creation of a page. Therefore we need extra API calls. Currently the labels are added one by one. Suggestion for improvement: Build a label structure of all labels an place them with one call. Replaces exisiting labels. No harm Does not check for deleted labels when keywords are deleted from source document! */ def addLabels = { def pageId, def labelsArray -&gt; // Attach each label in a API call of its own. The only prefix possible // in our own Confluence is 'global' labelsArray.each { label -&gt; label_data = [ prefix : 'global', name : label ] confluenceClient.addLabel(pageId, label_data) println \"added label \" + label + \" to page ID \" + pageId } } def uploadAttachment = { def pageId, String url, String fileName, String note -&gt; def is def localHash if (url.startsWith('http')) { is = new URL(url).openStream() //build a hash of the attachment localHash = MD5(new URL(url).openStream().text) } else { is = new File(url).newDataInputStream() //build a hash of the attachment localHash = MD5(new File(url).newDataInputStream().text) } def attachment = confluenceClient.getAttachment(pageId, fileName) if (attachment?.results) { // attachment exists. need an update? if (confluenceClient.attachmentHasChanged(attachment, localHash)) { //hash is different -&gt; attachment needs to be updated confluenceClient.updateAttachment(pageId, attachment.results[0].id, is, fileName, note, localHash) println \" updated attachment\" } } else { confluenceClient.createAttachment(pageId, is, fileName, note, localHash) } } def realTitle(pageTitle){ confluencePagePrefix + pageTitle + confluencePageSuffix } def rewriteMarks (body) { // Confluence strips out mark elements. Replace them with default formatting. body.select('mark').wrap('&lt;span style=\"background:#ff0;color:#000\"&gt;&lt;/style&gt;').unwrap() } // #352-LuisMuniz: Helper methods // Fetch all pages of the defined config ancestorsIds. Only keep relevant info in the pages Map // The map is indexed by lower-case title def retrieveAllPages = { String spaceKey -&gt; // #938-mksiva: added a condition spaceKeyInput is null, if it is null, it means that, space key is different, so re fetch all pages. if (allPages != null &amp;&amp; spaceKeyInput == null) { println \"allPages already retrieved\" allPages } else { def pageIds = [] def checkSpace = false int pageLimit = config.confluence.pageLimit ? config.confluence.pageLimit : 100 config.confluence.input.each { input -&gt; if (!input.ancestorId) { // if one ancestorId is missing we should scan the whole space checkSpace = true; return } pageIds.add(input.ancestorId) } println (\".\") if(checkSpace) { allPages = confluenceClient.fetchPagesBySpaceKey(spaceKey, pageLimit) } else { allPages = confluenceClient.fetchPagesByAncestorId(pageIds, pageLimit) } allPages } } // Retrieve a page by id with contents and version def retrieveFullPage = { String id -&gt; println(\"retrieving page with id \" + id) confluenceClient.retrieveFullPageById(id) } //if a parent has been specified, check whether a page has the same parent. boolean hasRequestedParent(Map existingPage, String requestedParentId) { if (requestedParentId) { existingPage.parentId == requestedParentId } else { true } } def rewriteDescriptionLists(body) { def TAGS = [ dt: 'th', dd: 'td' ] body.select('dl').each { dl -&gt; // WHATWG allows wrapping dt/dd in divs, simply unwrap them dl.select('div').each { it.unwrap() } // group dts and dds that belong together, usually it will be a 1:1 relation // but HTML allows for different constellations def rows = [] def current = [dt: [], dd: []] rows &lt;&lt; current dl.select('dt, dd').each { child -&gt; def tagName = child.tagName() if (tagName == 'dt' &amp;&amp; current.dd.size() &gt; 0) { // dt follows dd, start a new group current = [dt: [], dd: []] rows &lt;&lt; current } current[tagName] &lt;&lt; child.tagName(TAGS[tagName]) child.remove() } rows.each { row -&gt; def sizes = [dt: row.dt.size(), dd: row.dd.size()] def rowspanIdx = [dt: -1, dd: sizes.dd - 1] def rowspan = Math.abs(sizes.dt - sizes.dd) + 1 def max = sizes.dt if (sizes.dt &lt; sizes.dd) { max = sizes.dd rowspanIdx = [dt: sizes.dt - 1, dd: -1] } (0..&lt;max).each { idx -&gt; def tr = dl.appendElement('tr') ['dt', 'dd'].each { type -&gt; if (sizes[type] &gt; idx) { tr.appendChild(row[type][idx]) if (idx == rowspanIdx[type] &amp;&amp; rowspan &gt; 1) { row[type][idx].attr('rowspan', \"${rowspan}\") } } else if (idx == 0) { tr.appendElement(TAGS[type]).attr('rowspan', \"${rowspan}\") } } } } dl.wrap('&lt;table&gt;&lt;/table&gt;') .unwrap() } } def rewriteInternalLinks (body, anchors, pageAnchors) { // find internal cross-references and replace them with link macros body.select('a[href]').each { a -&gt; def href = a.attr('href') if (href.startsWith('#')) { def anchor = href.substring(1) def pageTitle = anchors[anchor] ?: pageAnchors[anchor] if (pageTitle &amp;&amp; a.text()) { // as Confluence insists on link texts to be contained // inside CDATA, we have to strip all HTML and // potentially loose styling that way. a.html(a.text()) a.wrap(\"&lt;ac:link${anchors.containsKey(anchor) ? ' ac:anchor=\"' + anchor + '\"' : ''}&gt;&lt;/ac:link&gt;\") .before(\"&lt;ri:page ri:content-title=\\\"${realTitle pageTitle}\\\"/&gt;\") .wrap(\"&lt;ac:plain-text-link-body&gt;${CDATA_PLACEHOLDER_START}${CDATA_PLACEHOLDER_END}&lt;/ac:plain-text-link-body&gt;\") .unwrap() } } } } def rewriteJiraLinks = { body -&gt; // find links to jira tickets and replace them with jira macros body.select('a[href]').each { a -&gt; def href = a.attr('href') if (href.startsWith(config.jira.api + \"/browse/\")) { def ticketId = a.text() a.before(\"\"\"&lt;ac:structured-macro ac:name=\\\"jira\\\" ac:schema-version=\\\"1\\\"&gt; &lt;ac:parameter ac:name=\\\"key\\\"&gt;${ticketId}&lt;/ac:parameter&gt; &lt;ac:parameter ac:name=\\\"serverId\\\"&gt;${config.confluence.jiraServerId}&lt;/ac:parameter&gt; &lt;/ac:structured-macro&gt;\"\"\") a.remove() } } } def rewriteOpenAPI (org.jsoup.nodes.Element body) { if (config.confluence.useOpenapiMacro == true || config.confluence.useOpenapiMacro == 'confluence-open-api') { body.select('div.openapi pre &gt; code').each { code -&gt; def parent=code.parent() def rawYaml=code.wholeText() code.parent() .wrap('&lt;ac:structured-macro ac:name=\"confluence-open-api\" ac:schema-version=\"1\" ac:macro-id=\"1dfde21b-6111-4535-928a-470fa8ae3e7d\"&gt;&lt;/ac:structured-macro&gt;') .unwrap() code.wrap(\"&lt;ac:plain-text-body&gt;${CDATA_PLACEHOLDER_START}${CDATA_PLACEHOLDER_END}&lt;/ac:plain-text-body&gt;\") .replaceWith(new TextNode(rawYaml)) } } else if (config.confluence.useOpenapiMacro == 'swagger-open-api') { body.select('div.openapi pre &gt; code').each { code -&gt; def parent=code.parent() def rawYaml=code.wholeText() code.parent() .wrap('&lt;ac:structured-macro ac:name=\"swagger-open-api\" ac:schema-version=\"1\" ac:macro-id=\"f9deda8a-1375-4488-8ca5-3e10e2e4ee70\"&gt;&lt;/ac:structured-macro&gt;') .unwrap() code.wrap(\"&lt;ac:plain-text-body&gt;${CDATA_PLACEHOLDER_START}${CDATA_PLACEHOLDER_END}&lt;/ac:plain-text-body&gt;\") .replaceWith(new TextNode(rawYaml)) } } else if (config.confluence.useOpenapiMacro == 'open-api') { def includeURL=null for (Element e : body.select('div .listingblock.openapi')) { for (String s : e.className().split(\" \")) { if (s.startsWith(\"url\")) { //include the link to the URL for the macro includeURL = s.replace('url:', '') } } } body.select('div.openapi pre &gt; code').each { code -&gt; def parent=code.parent() def rawYaml=code.wholeText() code.parent() .wrap('&lt;ac:structured-macro ac:name=\"open-api\" ac:schema-version=\"1\" data-layout=\"default\" ac:macro-id=\"4302c9d8-fca4-4f14-99a9-9885128870fa\"&gt;&lt;/ac:structured-macro&gt;') .unwrap() if (includeURL!=null) { code.before('&lt;ac:parameter ac:name=\"url\"&gt;'+includeURL+'&lt;/ac:parameter&gt;') } else { //default: show download button code.before('&lt;ac:parameter ac:name=\"showDownloadButton\"&gt;true&lt;/ac:parameter&gt;') code.wrap(\"&lt;ac:plain-text-body&gt;${CDATA_PLACEHOLDER_START}${CDATA_PLACEHOLDER_END}&lt;/ac:plain-text-body&gt;\") .replaceWith(new TextNode(rawYaml)) } } } } def getEmbeddedImageData(src){ def imageData = src.split(\"[;:,]\") def fileExtension = imageData[1].split(\"/\")[1] // treat svg+xml as svg to be able to create a file from the embedded image // more MIME types: https://www.iana.org/assignments/media-types/media-types.xhtml#image if(fileExtension == \"svg+xml\"){ fileExtension = \"svg\" } return Map.of( \"fileExtension\", fileExtension, \"encoding\", imageData[2], \"encodedContent\", imageData[3] ) } def handleEmbeddedImage(basePath, fileName, fileExtension, encodedContent) { def imageDir = \"images/\" if(config.imageDirs.size() &gt; 0){ def dir = config.imageDirs.find { it -&gt; def configureImagesDir = it.replace('./', '/') Path.of(basePath, configureImagesDir, fileName).toFile().exists() } if(dir != null){ imageDir = dir.replace('./', '/') } } if(!Path.of(basePath, imageDir, fileName).toFile().exists()){ println \"Could not find embedded image at a known location\" def embeddedImagesLocation = \"/confluence/images/\" new File(basePath + embeddedImagesLocation).mkdirs() def imageHash = MD5(encodedContent) println \"Embedded Image Hash \" + imageHash def image = new File(basePath + embeddedImagesLocation + imageHash + \".${fileExtension}\") if(!image.exists()){ println \"Creating image at \" + basePath + embeddedImagesLocation image.withOutputStream {output -&gt; output.write(encodedContent.decodeBase64())} } fileName = imageHash + \".${fileExtension}\" return Map.of( \"filePath\", image.canonicalPath, \"fileName\", fileName ) } else { return Map.of( \"filePath\", basePath + imageDir + fileName, \"fileName\", fileName ) } } //modify local page in order to match the internal confluence storage representation a bit better //definition lists are not displayed by confluence, so turn them into tables //body can be of type Element or Elements def parseBody(body, anchors, pageAnchors) { def uploads = [] rewriteOpenAPI body body.select('div.paragraph').unwrap() body.select('div.ulist').unwrap() //body.select('div.sect3').unwrap() [ 'note':'info', 'warning':'warning', 'important':'warning', 'caution':'note', 'tip':'tip' ].each { adType, cType -&gt; body.select('.admonitionblock.'+adType).each { block -&gt; parseAdmonitionBlock(block, cType) } } //special for the arc42-template body.select('div.arc42help').select('.content') .wrap('&lt;ac:structured-macro ac:name=\"expand\"&gt;&lt;/ac:structured-macro&gt;') .wrap('&lt;ac:rich-text-body&gt;&lt;/ac:rich-text-body&gt;') .wrap('&lt;ac:structured-macro ac:name=\"info\"&gt;&lt;/ac:structured-macro&gt;') .before('&lt;ac:parameter ac:name=\"title\"&gt;arc42&lt;/ac:parameter&gt;') .wrap('&lt;ac:rich-text-body&gt;&lt;p&gt;&lt;/p&gt;&lt;/ac:rich-text-body&gt;') body.select('div.arc42help').unwrap() body.select('div.title').wrap(\"&lt;strong&gt;&lt;/strong&gt;\").before(\"&lt;br /&gt;\").wrap(\"&lt;div&gt;&lt;/div&gt;\") body.select('div.listingblock').wrap(\"&lt;p&gt;&lt;/p&gt;\").unwrap() // see if we can find referenced images and fetch them new File(\"tmp/images/.\").mkdirs() // find images, extract their URLs for later uploading (after we know the pageId) and replace them with this macro: // &lt;ac:image ac:align=\"center\" ac:width=\"500\"&gt; // &lt;ri:attachment ri:filename=\"deployment-context.png\"/&gt; // &lt;/ac:image&gt; body.select('img').each { img -&gt; def src = img.attr('src') def imgWidth = img.attr('width')?:500 def imgAlign = img.attr('align')?:\"center\" //it is not an online image, so upload it to confluence and use the ri:attachment tag if(!src.startsWith(\"http\")) { def sanitizedBaseUrl = baseUrl.toString().replaceAll('\\\\\\\\','/').replaceAll('/[^/]*$','/') def newUrl def fileName //it is an embedded image if(src.startsWith(\"data:image\")){ def imageData = getEmbeddedImageData(src) def fileExtension = imageData.get(\"fileExtension\") def encodedContent = imageData.get(\"encodedContent\") fileName = img.attr('alt').replaceAll(/\\s+/,\"_\").concat(\".${fileExtension}\") def embeddedImage = handleEmbeddedImage(sanitizedBaseUrl, fileName, fileExtension, encodedContent) newUrl = embeddedImage.get(\"filePath\") fileName = embeddedImage.get(\"fileName\") }else { newUrl = sanitizedBaseUrl + src fileName = java.net.URLDecoder.decode((src.tokenize('/')[-1]),\"UTF-8\") } newUrl = java.net.URLDecoder.decode(newUrl,\"UTF-8\") println \" image: \"+newUrl uploads &lt;&lt; [0,newUrl,fileName,\"automatically uploaded\"] img.after(\"&lt;ac:image ac:align=\\\"${imgAlign}\\\" ac:width=\\\"${imgWidth}\\\"&gt;&lt;ri:attachment ri:filename=\\\"${fileName}\\\"/&gt;&lt;/ac:image&gt;\") } // it is an online image, so we have to use the ri:url tag else { img.after(\"&lt;ac:image ac:align=\\\"imgAlign\\\" ac:width=\\\"${imgWidth}\\\"&gt;&lt;ri:url ri:value=\\\"${src}\\\"/&gt;&lt;/ac:image&gt;\") } img.remove() } if(config.confluence.enableAttachments){ attachmentPrefix = config.confluence.attachmentPrefix ? config.confluence.attachmentPrefix : 'attachment' body.select('a').each { link -&gt; def src = link.attr('href') println \" attachment src: \"+src //upload it to confluence and use the ri:attachment tag if(src.startsWith(attachmentPrefix)) { def newUrl = baseUrl.toString().replaceAll('\\\\\\\\','/').replaceAll('/[^/]*$','/')+src def fileName = java.net.URLDecoder.decode((src.tokenize('/')[-1]),\"UTF-8\") newUrl = java.net.URLDecoder.decode(newUrl,\"UTF-8\") uploads &lt;&lt; [0,newUrl,fileName,\"automatically uploaded non-image attachment by docToolchain\"] def uriArray=fileName.split(\"/\") def pureFilename = uriArray[uriArray.length-1] def innerhtml = link.html() link.after(\"&lt;ac:structured-macro ac:name=\\\"view-file\\\" ac:schema-version=\\\"1\\\"&gt;&lt;ac:parameter ac:name=\\\"name\\\"&gt;&lt;ri:attachment ri:filename=\\\"${pureFilename}\\\"/&gt;&lt;/ac:parameter&gt;&lt;/ac:structured-macro&gt;\") link.after(\"&lt;ac:link&gt;&lt;ri:attachment ri:filename=\\\"${pureFilename}\\\"/&gt;&lt;ac:plain-text-link-body&gt; &lt;![CDATA[\\\"${innerhtml}\\\"]]&gt;&lt;/ac:plain-text-link-body&gt;&lt;/ac:link&gt;\") link.remove() } } } if(config.confluence.jiraServerId){ rewriteJiraLinks body } rewriteMarks body rewriteDescriptionLists body rewriteInternalLinks body, anchors, pageAnchors //not really sure if must check here the type String bodyString = body if(body instanceof Element){ bodyString = body.html() } Element saneHtml = new Document(\"\") .outputSettings(new Document.OutputSettings().syntax(Document.OutputSettings.Syntax.xml).prettyPrint(false)) .html(bodyString) def pageString = new HtmlTransformer().transformToConfluenceFormat(saneHtml) return Map.of( \"page\", pageString, \"uploads\", uploads ) } def generateAndAttachToC(localPage) { def content if(config.confluence.disableToC){ def prefix = (config.confluence.extraPageContent?:'') content = prefix+localPage }else{ def default_toc = '&lt;p&gt;&lt;ac:structured-macro ac:name=\"toc\"/&gt;&lt;/p&gt;' def prefix = (config.confluence.tableOfContents?:default_toc)+(config.confluence.extraPageContent?:'') content = prefix+localPage def default_children = '&lt;p&gt;&lt;ac:structured-macro ac:name=\"children\"&gt;&lt;ac:parameter ac:name=\"sort\"&gt;creation&lt;/ac:parameter&gt;&lt;/ac:structured-macro&gt;&lt;/p&gt;' content += (config.confluence.tableOfChildren?:default_children) } def localHash = MD5(localPage) content += '&lt;ac:placeholder&gt;hash: #'+localHash+'#&lt;/ac:placeholder&gt;' return content } // the create-or-update functionality for confluence pages // #342-dierk42: added parameter 'keywords' def pushToConfluence = { pageTitle, pageBody, parentId, anchors, pageAnchors, keywords -&gt; parentId = parentId?.toString() def deferredUpload = [] String realTitleLC = realTitle(pageTitle).toLowerCase() String realTitle = realTitle(pageTitle) //try to get an existing page def parsedBody = parseBody(pageBody, anchors, pageAnchors) localPage = parsedBody.get(\"page\") deferredUpload.addAll(parsedBody.get(\"uploads\")) def localHash = MD5(localPage) localPage = generateAndAttachToC(localPage) // #938-mksiva: Changed the 3rd parameter from 'config.confluence.spaceKey' to 'confluenceSpaceKey' as it was always taking the default spaceKey // instead of the one passed in the input for each row. def pages = retrieveAllPages(confluenceSpaceKey) println(\"pages retrieved\") // println \"Suche nach vorhandener Seite: \" + pageTitle Map existingPage = pages[realTitleLC] def page if (existingPage) { if (hasRequestedParent(existingPage, parentId)) { page = retrieveFullPage(existingPage.id as String) } else { page = null } } else { page = null } // println \"Gefunden: \" + page.id + \" Titel: \" + page.title if (page) { println \"found existing page: \" + page.id +\" version \"+page.version.number //extract hash from remote page to see if it is different from local one def remotePage = page.body.storage.value.toString().trim() def remoteHash = remotePage =~ /(?ms)hash: #([^#]+)#/ remoteHash = remoteHash.size()==0?\"\":remoteHash[0][1] // println \"remoteHash: \" + remoteHash // println \"localHash: \" + localHash if (remoteHash == localHash) { println \"page hasn't changed!\" deferredUpload.each { uploadAttachment(page?.id, it[1], it[2], it[3]) } deferredUpload = [] // #324-dierk42: Add keywords as labels to page. if (keywords) { addLabels(page.id, keywords) } return page.id } else { def newPageVersion = (page.version.number as Integer) + 1 confluenceClient.updatePage( page.id, realTitle, confluenceSpaceKey, localPage, newPageVersion, config.confluence.pageVersionComment ?: '', parentId ) println \"&gt; updated page \"+page.id deferredUpload.each { uploadAttachment(page.id, it[1], it[2], it[3]) } deferredUpload = [] // #324-dierk42: Add keywords as labels to page. if (keywords) { addLabels(page.id, keywords) } return page.id } } else { //#352-LuisMuniz if the existing page's parent does not match the requested parentId, fail if (existingPage &amp;&amp; !hasRequestedParent(existingPage, parentId)) { throw new IllegalArgumentException(\"Cannot create page, page with the same \" + \"title=${existingPage.title} \" + \"with id=${existingPage.id} already exists in the space. \" + \"A Confluence page title must be unique within a space, consider specifying a 'confluencePagePrefix' in ConfluenceConfig.groovy\") } //create a page page = confluenceClient.createPage( realTitle, confluenceSpaceKey, localPage, config.confluence.pageVersionComment ?: '', parentId ) println \"&gt; created page \"+page?.id deferredUpload.each { uploadAttachment(page?.id, it[1], it[2], it[3]) } deferredUpload = [] // #324-dierk42: Add keywords as labels to page. if (keywords) { addLabels(page?.id, keywords) } return page?.id } } def parseAnchors(page) { def anchors = [:] page.body.select('[id]').each { anchor -&gt; def name = anchor.attr('id') anchors[name] = page.title anchor.before(\"&lt;ac:structured-macro ac:name=\\\"anchor\\\"&gt;&lt;ac:parameter ac:name=\\\"\\\"&gt;${name}&lt;/ac:parameter&gt;&lt;/ac:structured-macro&gt;\") } anchors } def pushPages pushPages = { pages, anchors, pageAnchors, labels -&gt; pages.each { page -&gt; page.title = page.title.trim() println page.title def id = pushToConfluence page.title, page.body, page.parent, anchors, pageAnchors, labels page.children*.parent = id // println \"Push children von id \" + id pushPages page.children, anchors, pageAnchors, labels // println \"Ende Push children von id \" + id } } def recordPageAnchor(head) { def a = [:] if (head.attr('id')) { a[head.attr('id')] = head.text() } a } def promoteHeaders(tree, start, offset) { (start..7).each { i -&gt; tree.select(\"h${i}\").tagName(\"h${i-offset}\").before('&lt;br /&gt;') } } def retrievePageIdByName = { String name -&gt; def data = confluenceClient.retrievePageIdByName(name, confluenceSpaceKey) return data?.results?.get(0)?.id } def getPagesRecursive(Element element, String parentId, Map anchors, Map pageAnchors, int level, int maxLevel) { def pages = [] element.select(\"div.sect${level}\").each { sect -&gt; def title = sect.select(\"h${level + 1}\").text() pageAnchors.putAll(recordPageAnchor(sect.select(\"h${level + 1}\"))) Elements pageBody if (level == 1) { pageBody = sect.select('div.sectionbody') } else { pageBody = new Elements(sect) pageBody.select(\"h${level + 1}\").remove() } def currentPage = [ title: title, body: pageBody, children: [], parent: parentId ] if (maxLevel &gt; level) { currentPage.children.addAll(getPagesRecursive(sect, null, anchors, pageAnchors, level + 1, maxLevel)) pageBody.select(\"div.sect${level + 1}\").remove() } else { pageBody.select(\"div.sect${level + 1}\").unwrap() } promoteHeaders sect, level + 2, level + 1 pages &lt;&lt; currentPage anchors.putAll(parseAnchors(currentPage)) } return pages } def getPages(Document dom, String parentId, int maxLevel) { def anchors = [:] def pageAnchors = [:] def sections = pages = [] def title = dom.select('h1').text() if (maxLevel &lt;= 0) { dom.select('div#content').each { pageBody -&gt; pageBody.select('div.sect2').unwrap() promoteHeaders pageBody, 2, 1 def page = [title : title, body : pageBody, children: [], parent : parentId] pages &lt;&lt; page sections = page.children parentId = null anchors.putAll(parseAnchors(page)) } } else { // let's try to select the \"first page\" and push it to confluence dom.select('div#preamble div.sectionbody').each { pageBody -&gt; pageBody.select('div.sect2').unwrap() def preamble = [ title: title, body: pageBody, children: [], parent: parentId ] pages &lt;&lt; preamble sections = preamble.children parentId = null anchors.putAll(parseAnchors(preamble)) } sections.addAll(getPagesRecursive(dom, parentId, anchors, pageAnchors, 1, maxLevel)) } return [pages, anchors, pageAnchors] } if(config.confluence.inputHtmlFolder) { htmlFolder = \"${docDir}/${config.confluence.inputHtmlFolder}\" println \"Starting processing files in folder: \" + config.confluence.inputHtmlFolder def dir = new File(htmlFolder) dir.eachFileRecurse (FILES) { fileName -&gt; if (fileName.isFile()){ def map = [file: config.confluence.inputHtmlFolder+fileName.getName()] config.confluence.input.add(map) } } } config.confluence.input.each { input -&gt; // TODO check why this is necessary if(input.file) { input.file = confluenceService.checkAndBuildCanonicalFileName(input.file) // assignend, but never used in pushToConfluence(...) (fixed here) // #938-mksiva: assign spaceKey passed for each file in the input spaceKeyInput = input.spaceKey confluenceSpaceKey = input.spaceKey ?: config.confluence.spaceKey confluenceCreateSubpages = (input.createSubpages != null) ? input.createSubpages : config.confluence.createSubpages confluenceAllInOnePage = (input.allInOnePage != null) ? input.allInOnePage : config.confluence.allInOnePage if (!(confluenceCreateSubpages instanceof ConfigObject &amp;&amp; confluenceAllInOnePage instanceof ConfigObject)) { println \"ERROR:\" println \"Deprecated configuration, migrate as follows:\" println \"allInOnePage = true -&gt; subpagesForSections = 0\" println \"allInOnePage = false &amp;&amp; createSubpages = false -&gt; subpagesForSections = 1\" println \"allInOnePage = false &amp;&amp; createSubpages = true -&gt; subpagesForSections = 2\" throw new RuntimeException(\"config problem\") } confluenceSubpagesForSections = (input.subpagesForSections != null) ? input.subpagesForSections : config.confluence.subpagesForSections if (confluenceSubpagesForSections instanceof ConfigObject) { confluenceSubpagesForSections = 1 } // hard to read in case of using :sectnums: -&gt; so we add a suffix confluencePagePrefix = input.pagePrefix ?: config.confluence.pagePrefix // added confluencePageSuffix = input.pageSuffix ?: config.confluence.pageSuffix confluencePreambleTitle = input.preambleTitle ?: config.confluence.preambleTitle if (!(confluencePreambleTitle instanceof ConfigObject)) { println \"ERROR:\" println \"Deprecated configuration, use first level heading in document instead of preambleTitle configuration\" throw new RuntimeException(\"config problem\") } File htmlFile = new File(input.file) baseUrl = htmlFile Document dom = confluenceService.parseFile(htmlFile) // if ancestorName is defined try to find machingAncestorId in confluence def retrievedAncestorId if (input.ancestorName) { // Retrieve a page id by name retrievedAncestorId = retrievePageIdByName(input.ancestorName) println(\"Retrieved pageId for given ancestorName '${input.ancestorName}' is ${retrievedAncestorId}\") } // if input does not contain an ancestorName, check if there is ancestorId, otherwise check if there is a global one def parentId = retrievedAncestorId ?: input.ancestorId ?: config.confluence.ancestorId // if parentId is still not set, create a new parent page (parentId = null) parentId = parentId ?: null //println(\"ancestorName: '${input.ancestorName}', ancestorId: ${input.ancestorId} ---&gt; final parentId: ${parentId}\") // #342-dierk42: get the keywords from the meta tags def keywords = confluenceService.getKeywords(dom) def (pages, anchors, pageAnchors) = getPages(dom, parentId, confluenceSubpagesForSections) pushPages pages, anchors, pageAnchors, keywords if (parentId) { println \"published to ${config.confluence.api - \"rest/api/\"}/spaces/${confluenceSpaceKey}/pages/${parentId}\" } else { println \"published to ${config.confluence.api - \"rest/api/\"}/spaces/${confluenceSpaceKey}\" } } } \"\" "
},

{
    "id": 57,
    "uri": "015_tasks/03_task_exportEA.html",
    "menu": "tasks",
    "title": "exportEA",
    "text": " Table of Contents exportEA About This Task Important The Optional Parameter Configurations Glossary export Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportEA 4 minutes to read About This Task By default, no special configuration is necessary. However, several optional parameter configurations are available to support a project and packages to be used for export. These parameters can be used independently from one another. A sample of how to edit your projects' Config.groovy is provided in the 'Config.groovy' of the docToolchain project itself. Important Currently this feature is WINDOWS-only. See this related issue . The Optional Parameter Configurations connection Either set the connection to a certain project, or comment it out to use all project files inside the src folder or its child folder. packageFilter Add one or multiple packageGUIDs to be used for export. All packages are analysed, if no packageFilter is set. exportPath Relative path to base 'docDir' to which the diagrams and notes are to be exported. Default: \"src/docs\". Example: docDir = 'D:\\work\\mydoc\\' ; exportPath = 'src/pdocs' ; Images will be exported to 'D:\\work\\mydoc\\src\\pdocs\\images\\ea', Notes will be exported to 'D:\\work\\mydoc\\src\\pdocs\\ea', searchPath Relative path to base 'docDir', in which Enterprise Architect project files are searched Default: \"src/docs\". Example: docDir = 'D:\\work\\mydoc\\' ; exportPath = 'src/projects' ; Lookup for eap and eapx files starts in 'D:\\work\\mydoc\\src\\projects' and goes down the folder structure. Note : In case parameter 'connection' is already defined, the searchPath value is also used. exportEA starts opening the database parameter 'connection' first then looks for further project files either in the searchPath (if set) or in the docDir folder of the project. glossaryAsciiDocFormat Whether the EA project glossary is exported depends on this parameter. If not set or an empty string, no glossary is exported. The glossaryAsciiDocFormat string is used to format each glossary entry in a certain AsciiDoc format. The following placeholders are defined for the format string: ID, TERM, MEANING, TYPE. One or more can be used by the output format. For example: A valid output format is to include the glossary as a flat list. The file can be included where needed in the documentation. glossaryAsciiDocFormat = \"TERM:: MEANING\" Other format strings can be used to include it as a table row. The glossary terms are sorted in alphabetical order. glossaryTypes This parameter is used in case a glossaryAsciiDocFormat is defined, otherwise it is not evaluated. It&#8217;s used to filter for certain types. If the glossaryTypes list is empty, all entries will be used. For example: glossaryTypes = [\"Business\", \"Technical\"] diagramAttributes If set, the string is used to create and store diagram attributes to be included in the document alongside a diagram. These placeholders are defined and populated with the diagram attributes, if used in the diagramAttributes string: %DIAGRAM_AUTHOR% , %DIAGRAM_CREATED% , %DIAGRAM_GUID% , %DIAGRAM_MODIFIED% , %DIAGRAM_NAME% , %DIAGRAM_NOTES% , %DIAGRAM_DIAGRAM_TYPE% , %DIAGRAM_VERSION% , %NEWLINE% Example: diagramAttributes = \"Last modification: %DIAGRAM_MODIFIED%%NEWLINE%Version: %DIAGRAM_VERSION%\" You can add the string %NEWLINE% where a line break will be added. The resulting text is stored next to the diagram image using the same path and file name, but a different file extension (.ad). This can be included in the document if required. If diagramAttributes is not set or an empty string, no file is written. imageFormat If set, the set image format is used to export the diagrams. Default is set to \".png\". Please check your Enterprise Architect version which formats are supported. additionalOptions This parameter is used to define the specific behavior of the export. Currently, these options are supported: KeepFirstDiagram If diagrams are not uniquely named, the last diagram will be saved. If you want to prevent diagrams from being overwritten, add this parameter to additionalOptions. Glossary export By setting the glossaryAsciiDocFormat, the glossary terms stored in the EA project will be exported into a folder named 'glossary' below the configured exportPath. In case multiple EA projects are found for export, one glossary per project is exported - each named using the project&#8217;s GUID plus extension '.ad'. Each individual file will be filtered (see glossaryTypes) and sorted in alphabetical order. In addition, a global glossary is created by using all single glossary files. This global file is named 'glossary.ad' and is also placed in the glossary folder. The global glossary is also filtered and sorted. If there is only one EA project, only the global glossary is written. Further Reading and Resources JIRA to Sparx EA blog post. Did you Ever Wish you Had Better Diagrams? blog post. Source Show source code of scripts/exportEA.gradle or go directly to GitHub · docToolchain/scripts/exportEA.gradle . scripts/exportEA.gradle task exportEA( dependsOn: [streamingExecute], description: 'exports all diagrams and some texts from EA files', group: 'docToolchain' ) { doFirst { } doLast { logger.info(\"docToolchain &gt; exportEA: \" + docDir) logger.info(\"docToolchain &gt; exportEA: \" + mainConfigFile) def configFile = new File(docDir, mainConfigFile) def config = new ConfigSlurper().parse(configFile.text) def scriptParameterString = \"\" def exportPath = \"\" def searchPath = \"\" def glossaryPath = \"\" def imageFormat = \"\" def readme = \"\"\"This folder contains exported diagrams or notes from Enterprise Architect. Please note that these are generated files but reside in the `src`-folder in order to be versioned. This is to make sure that they can be used from environments other than windows. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradle exportEA` to re-export files \"\"\" if (!config.exportEA.connection.isEmpty()) { logger.info(\"docToolchain &gt; exportEA: found \" + config.exportEA.connection) scriptParameterString = scriptParameterString + \"-c \\\"${config.exportEA.connection}\\\"\" } if (!config.exportEA.packageFilter.isEmpty()) { def packageFilterToCreate = config.exportEA.packageFilter as List logger.info(\"docToolchain &gt; exportEA: package filter list size: \" + packageFilterToCreate.size()) packageFilterToCreate.each { packageFilter -&gt; scriptParameterString = scriptParameterString + \" -p \\\"${packageFilter}\\\"\" } } if (!config.exportEA.exportPath.isEmpty()) { exportPath = new File(docDir, config.exportEA.exportPath).getAbsolutePath() } else { exportPath = new File(docDir, 'src/docs').getAbsolutePath() } if (!config.exportEA.searchPath.isEmpty()) { searchPath = new File(docDir, config.exportEA.searchPath).getAbsolutePath() } else if (!config.exportEA.absoluteSearchPath.isEmpty()) { searchPath = new File(config.exportEA.absoluteSearchPath).getAbsolutePath() } else { searchPath = new File(docDir, 'src').getAbsolutePath() } if (config.exportEA.imageFormat.isEmpty()) { imageFormat = \".png\" } else if(!config.exportEA.imageFormat.startsWith(\".\")) { imageFormat = \".\" + config.exportEA.imageFormat } else { imageFormat = config.exportEA.imageFormat } scriptParameterString = scriptParameterString + \" -d \\\"$exportPath\\\"\" scriptParameterString = scriptParameterString + \" -s \\\"$searchPath\\\"\" scriptParameterString = scriptParameterString + \" -f \\\"$imageFormat\\\"\" logger.info(\"docToolchain &gt; exportEA: exportPath: \" + exportPath) //remove old glossary files/folder if exist new File(exportPath, 'glossary').deleteDir() //set the glossary file path in case an output format is configured, other no glossary is written if (!config.exportEA.glossaryAsciiDocFormat.isEmpty()) { //create folder to store glossaries new File(exportPath, 'glossary/.').mkdirs() glossaryPath = new File(exportPath, 'glossary').getAbsolutePath() scriptParameterString = scriptParameterString + \" -g \\\"$glossaryPath\\\"\" } //configure additional diagram attributes to be exported if (!config.exportEA.diagramAttributes.isEmpty()) { scriptParameterString = scriptParameterString + \" -da \\\"$config.exportEA.diagramAttributes\\\"\" } //configure additional diagram attributes to be exported if (!config.exportEA.additionalOptions.isEmpty()) { scriptParameterString = scriptParameterString + \" -ao \\\"$config.exportEA.additionalOptions\\\"\" } //make sure path for notes exists //and remove old notes new File(exportPath, 'ea').deleteDir() //also remove old diagrams new File(exportPath, 'images/ea').deleteDir() //create a readme to clarify things new File(exportPath, 'images/ea/.').mkdirs() new File(exportPath, 'images/ea/readme.ad').write(readme) new File(exportPath, 'ea/.').mkdirs() new File(exportPath, 'ea/readme.ad').write(readme) //execute through cscript in order to make sure that we get WScript.echo right logger.info(\"docToolchain &gt; exportEA: parameters: \" + scriptParameterString) \"%SystemRoot%\\\\System32\\\\cscript.exe //nologo ${projectDir}/scripts/exportEAP.vbs ${scriptParameterString}\".executeCmd() //the VB Script is only capable of writing iso-8859-1-Files. //we now have to convert them to UTF-8 new File(exportPath, 'ea/.').eachFileRecurse { file -&gt; if (file.isFile()) { println \"exported notes \" + file.canonicalPath file.write(file.getText('iso-8859-1'), 'utf-8') } } //sort, filter and reformat a glossary if an output format is configured if (!config.exportEA.glossaryAsciiDocFormat.isEmpty()) { def glossaryTypes if (!config.exportEA.glossaryTypes.isEmpty()) { glossaryTypes = config.exportEA.glossaryTypes as List } new GlossaryHandler().execute(glossaryPath, config.exportEA.glossaryAsciiDocFormat, glossaryTypes); } } } Show source code of scripts/exportEAP.vbs or go directly to GitHub · docToolchain/scripts/exportEAP.vbs . scripts/exportEAP.vbs ' based on the \"Project Interface Example\" which comes with EA ' http://stackoverflow.com/questions/1441479/automated-method-to-export-enterprise-architect-diagrams Dim EAapp 'As EA.App Dim Repository 'As EA.Repository Dim FS 'As Scripting.FileSystemObject Dim projectInterface 'As EA.Project Const ForAppending = 8 Const ForWriting = 2 ' Helper ' http://windowsitpro.com/windows/jsi-tip-10441-how-can-vbscript-create-multiple-folders-path-mkdir-command Function MakeDir (strPath) Dim strParentPath, objFSO Set objFSO = CreateObject(\"Scripting.FileSystemObject\") On Error Resume Next strParentPath = objFSO.GetParentFolderName(strPath) If Not objFSO.FolderExists(strParentPath) Then MakeDir strParentPath If Not objFSO.FolderExists(strPath) Then objFSO.CreateFolder strPath On Error Goto 0 MakeDir = objFSO.FolderExists(strPath) End Function ' Replaces certain characters with '_' to avoid unwanted file or folder names causing errors or structure failures. ' Regular expression can easily be extended with further characters to be replaced. Function NormalizeName(theName) dim re : Set re = new regexp re.Pattern = \"[\\\\/\\[\\]\\s:]\" re.Global = True NormalizeName = re.Replace(theName, \"_\") End Function Sub WriteNote(currentModel, currentElement, notes, prefix) If (Left(notes, 6) = \"{adoc:\") Then strFileName = Trim(Mid(notes,7,InStr(notes,\"}\")-7)) strNotes = Right(notes,Len(notes)-InStr(notes,\"}\")) set objFSO = CreateObject(\"Scripting.FileSystemObject\") If (currentModel.Name=\"Model\") Then ' When we work with the default model, we don't need a sub directory path = objFSO.BuildPath(exportDestination,\"ea/\") Else path = objFSO.BuildPath(exportDestination,\"ea/\"&amp;NormalizeName(currentModel.Name)&amp;\"/\") End If MakeDir(path) post = \"\" If (prefix&lt;&gt;\"\") Then post = \"_\" End If MakeDir(path&amp;prefix&amp;post) set objFile = objFSO.OpenTextFile(path&amp;prefix&amp;post&amp;\"/\"&amp;strFileName&amp;\".ad\",ForAppending, True) name = currentElement.Name name = Replace(name,vbCr,\"\") name = Replace(name,vbLf,\"\") strCombinedNotes = \"_all_notes.ad\" set objCombinedNotesFile = objFSO.OpenTextFile(path&amp;prefix&amp;post&amp;\"/\"&amp;strCombinedNotes,ForAppending, True) if (Left(strNotes, 3) = vbCRLF&amp;\"|\") Then ' content should be rendered as table - so don't interfere with it objFile.WriteLine(vbCRLF) objCombinedNotesFile.WriteLine(vbCRLF) else 'let's add the name of the object objFile.WriteLine(vbCRLF&amp;vbCRLF&amp;\".\"&amp;name) objCombinedNotesFile.WriteLine(vbCRLF&amp;vbCRLF&amp;\".\"&amp;name) End If objFile.WriteLine(vbCRLF&amp;strNotes) objFile.Close objCombinedNotesFile.WriteLine(vbCRLF&amp;strNotes) objCombinedNotesFile.Close if (prefix&lt;&gt;\"\") Then ' write the same to a second file set objFile = objFSO.OpenTextFile(path&amp;prefix&amp;\".ad\",ForAppending, True) objFile.WriteLine(vbCRLF&amp;vbCRLF&amp;\".\"&amp;name&amp;vbCRLF&amp;strNotes) objFile.Close End If End If End Sub Sub SyncJira(currentModel, currentDiagram) notes = currentDiagram.notes set currentPackage = Repository.GetPackageByID(currentDiagram.PackageID) updated = 0 created = 0 If (Left(notes, 6) = \"{jira:\") Then WScript.echo \" &gt;&gt;&gt;&gt; Diagram jira tag found\" strSearch = Mid(notes,7,InStr(notes,\"}\")-7) Set objShell = CreateObject(\"WScript.Shell\") 'objShell.CurrentDirectory = fso.GetFolder(\"./scripts\") Set objExecObject = objShell.Exec (\"cmd /K groovy ./scripts/exportEAPJiraPrintHelper.groovy \"\"\" &amp; strSearch &amp;\"\"\" &amp; exit\") strReturn = \"\" x = 0 y = 0 Do While Not objExecObject.StdOut.AtEndOfStream output = objExecObject.StdOut.ReadLine() ' WScript.echo output jiraElement = Split(output,\"|\") name = jiraElement(0)&amp;\":\"&amp;vbCR&amp;vbLF&amp;jiraElement(4) On Error Resume Next Set requirement = currentPackage.Elements.GetByName(name) On Error Goto 0 if (IsObject(requirement)) then ' element already exists requirement.notes = \"\" requirement.notes = requirement.notes&amp;\"&lt;a href='\"&amp;jiraElement(5)&amp;\"'&gt;\"&amp;jiraElement(0)&amp;\"&lt;/a&gt;\"&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Priority: \"&amp;jiraElement(1)&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Created: \"&amp;jiraElement(2)&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Assignee: \"&amp;jiraElement(3)&amp;vbCR&amp;vbLF requirement.Update() updated = updated + 1 else Set requirement = currentPackage.Elements.AddNew(name,\"Requirement\") requirement.notes = \"\" requirement.notes = requirement.notes&amp;\"&lt;a href='\"&amp;jiraElement(5)&amp;\"'&gt;\"&amp;jiraElement(0)&amp;\"&lt;/a&gt;\"&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Priority: \"&amp;jiraElement(1)&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Created: \"&amp;jiraElement(2)&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Assignee: \"&amp;jiraElement(3)&amp;vbCR&amp;vbLF requirement.Update() currentPackage.Elements.Refresh() Set dia_obj = currentDiagram.DiagramObjects.AddNew(\"l=\"&amp;(10+x*200)&amp;\";t=\"&amp;(10+y*50)&amp;\";b=\"&amp;(10+y*50+44)&amp;\";r=\"&amp;(10+x*200+180),\"\") x = x + 1 if (x&gt;3) then x = 0 y = y + 1 end if dia_obj.ElementID = requirement.ElementID dia_obj.Update() created = created + 1 end if Loop Set objShell = Nothing WScript.echo \"created \"&amp;created&amp;\" requirements\" WScript.echo \"updated \"&amp;updated&amp;\" requirements\" End If End Sub ' This sub routine checks if the format string defined in diagramAttributes ' does contain any characters. It replaces the known placeholders: ' %DIAGRAM_AUTHOR%, %DIAGRAM_CREATED%, %DIAGRAM_GUID%, %DIAGRAM_MODIFIED%, ' %DIAGRAM_NAME%, %DIAGRAM_NOTES%, %DIAGRAM_DIAGRAM_TYPE%, %DIAGRAM_VERSION% ' with the attribute values read from the EA diagram object. ' None, one or multiple number of placeholders can be used to create a diagram attribute ' to be added to the document. The attribute string is stored as a file with the same ' path and name as the diagram image, but with suffix .ad. So, it can ' easily be included in an asciidoc file. Sub SaveDiagramAttribute(currentDiagram, path, diagramName) If Len(diagramAttributes) &gt; 0 Then filledDiagAttr = diagramAttributes set objFSO = CreateObject(\"Scripting.FileSystemObject\") filename = objFSO.BuildPath(path, diagramName &amp; \".ad\") set objFile = objFSO.OpenTextFile(filename, ForWriting, True) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_AUTHOR%\", currentDiagram.Author) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_CREATED%\", currentDiagram.CreatedDate) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_GUID%\", currentDiagram.DiagramGUID) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_MODIFIED%\", currentDiagram.ModifiedDate) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_NAME%\", currentDiagram.Name) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_NOTES%\", currentDiagram.Notes) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_DIAGRAM_TYPE%\", currentDiagram.Type) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_VERSION%\", currentDiagram.Version) filledDiagAttr = Replace(filledDiagAttr, \"%NEWLINE%\", vbCrLf) objFile.WriteLine(filledDiagAttr) objFile.Close End If End Sub Sub SaveDiagram(currentModel, currentDiagram) Dim exportDiagram ' As Boolean ' Open the diagram Repository.OpenDiagram(currentDiagram.DiagramID) ' Save and close the diagram set objFSO = CreateObject(\"Scripting.FileSystemObject\") If (currentModel.Name=\"Model\") Then ' When we work with the default model, we don't need a sub directory path = objFSO.BuildPath(exportDestination,\"/images/ea/\") Else path = objFSO.BuildPath(exportDestination,\"/images/ea/\" &amp; NormalizeName(currentModel.Name) &amp; \"/\") End If path = objFSO.GetAbsolutePathName(path) MakeDir(path) diagramName = currentDiagram.Name diagramName = Replace(diagramName,vbCr,\"\") diagramName = Replace(diagramName,vbLf,\"\") diagramName = NormalizeName(diagramName) filename = objFSO.BuildPath(path, diagramName &amp; imageFormat) exportDiagram = True If objFSO.FileExists(filename) Then WScript.echo \" --- \" &amp; filename &amp; \" already exists.\" If Len(additionalOptions) &gt; 0 Then If InStr(additionalOptions, \"KeepFirstDiagram\") &gt; 0 Then WScript.echo \" --- Skipping export -- parameter 'KeepFirstDiagram' set.\" Else WScript.echo \" --- Overwriting -- parameter 'KeepFirstDiagram' not set.\" exportDiagram = False End If Else WScript.echo \" --- Overwriting -- parameter 'KeepFirstDiagram' not set.\" End If End If If exportDiagram Then projectInterface.SaveDiagramImageToFile(filename) WScript.echo \" extracted image to \" &amp; filename If Not IsEmpty(diagramAttributes) Then SaveDiagramAttribute currentDiagram, path, diagramName End If End If Repository.CloseDiagram(currentDiagram.DiagramID) ' Write the note of the diagram WriteNote currentModel, currentDiagram, currentDiagram.Notes, diagramName&amp;\"_notes\" For Each diagramElement In currentDiagram.DiagramObjects Set currentElement = Repository.GetElementByID(diagramElement.ElementID) WriteNote currentModel, currentElement, currentElement.Notes, diagramName&amp;\"_notes\" Next For Each diagramLink In currentDiagram.DiagramLinks set currentConnector = Repository.GetConnectorByID(diagramLink.ConnectorID) WriteNote currentModel, currentConnector, currentConnector.Notes, diagramName&amp;\"_links\" Next End Sub ' ' Recursively saves all diagrams under the provided package and its children ' Sub DumpDiagrams(thePackage,currentModel) Set currentPackage = thePackage ' export element notes For Each currentElement In currentPackage.Elements WriteNote currentModel, currentElement, currentElement.Notes, \"\" ' export connector notes For Each currentConnector In currentElement.Connectors ' WScript.echo currentConnector.ConnectorGUID if (currentConnector.ClientID=currentElement.ElementID) Then WriteNote currentModel, currentConnector, currentConnector.Notes, \"\" End If Next if (Not currentElement.CompositeDiagram Is Nothing) Then SyncJira currentModel, currentElement.CompositeDiagram SaveDiagram currentModel, currentElement.CompositeDiagram End If if (Not currentElement.Elements Is Nothing) Then DumpDiagrams currentElement,currentModel End If Next ' Iterate through all diagrams in the current package For Each currentDiagram In currentPackage.Diagrams SyncJira currentModel, currentDiagram SaveDiagram currentModel, currentDiagram Next ' Process child packages Dim childPackage 'as EA.Package ' otPackage = 5 if (currentPackage.ObjectType = 5) Then For Each childPackage In currentPackage.Packages call DumpDiagrams(childPackage, currentModel) Next End If End Sub Function SearchEAProjects(path) For Each folder In path.SubFolders SearchEAProjects folder Next For Each file In path.Files If fso.GetExtensionName (file.Path) = \"eap\" OR fso.GetExtensionName (file.Path) = \"eapx\" OR fso.GetExtensionName (file.Path) = \"qea\" OR fso.GetExtensionName (file.Path) = \"qeax\" Then WScript.echo \"found \"&amp;file.path If (Left(file.name, 1) = \"_\") Then WScript.echo \"skipping, because it start with `_` (replication)\" Else OpenProject(file.Path) End If End If Next End Function 'Gets the package object as referenced by its GUID from the Enterprise Architect project. 'Looks for the model node, the package is a child of as it is required for the diagram export. 'Calls the Sub routine DumpDiagrams for the model and package found. 'An error is printed to console only if the packageGUID is not found in the project. Function DumpPackageDiagrams(EAapp, packageGUID) WScript.echo \"DumpPackageDiagrams\" WScript.echo packageGUID Dim package Set package = EAapp.Repository.GetPackageByGuid(packageGUID) If (package Is Nothing) Then WScript.echo \"invalid package - as package is not part of the project\" Else Dim currentModel Set currentModel = package while currentModel.IsModel = false Set currentModel = EAapp.Repository.GetPackageByID(currentModel.parentID) wend ' Iterate through all child packages and save out their diagrams ' save all diagrams of package itself call DumpDiagrams(package, currentModel) End If End Function Function FormatStringToJSONString(inputString) outputString = Replace(inputString, \"\\\", \"\\\\\") outputString = Replace(outputString, \"\"\"\", \"\\\"\"\") outputString = Replace(outputString, vbCrLf, \"\\n\") outputString = Replace(outputString, vbLf, \"\\n\") outputString = Replace(outputString, vbCr, \"\\n\") FormatStringToJSONString = outputString End Function 'If a valid file path is set, the glossary terms are read from EA repository, 'formatted in a JSON compatible format and written into file. 'The file is read and reformatted by the exportEA gradle task afterwards. Function ExportGlossaryTermsAsJSONFile(EArepo) If (Len(glossaryFilePath) &gt; 0) Then set objFSO = CreateObject(\"Scripting.FileSystemObject\") GUID = Replace(EArepo.ProjectGUID,\"{\",\"\") GUID = Replace(GUID,\"}\",\"\") currentGlossaryFile = objFSO.BuildPath(glossaryFilePath,\"/\"&amp;GUID&amp;\".ad\") set objFile = objFSO.OpenTextFile(currentGlossaryFile,ForAppending, True) Set glossary = EArepo.Terms() objFile.WriteLine(\"[\") dim counter counter = 0 For Each term In glossary if (counter &gt; 0) Then objFile.Write(\",\") end if objFile.Write(\"{ \"\"term\"\" : \"\"\"&amp;FormatStringToJSONString(term.term)&amp;\"\"\", \"\"meaning\"\" : \"\"\"&amp;FormatStringToJSONString(term.Meaning)&amp;\"\"\",\") objFile.WriteLine(\" \"\"termID\"\" : \"\"\"&amp;FormatStringToJSONString(term.termID)&amp;\"\"\", \"\"type\"\" : \"\"\"&amp;FormatStringToJSONString(term.type)&amp;\"\"\" }\") counter = counter + 1 Next objFile.WriteLine(\"]\") objFile.Close End If End Function Sub OpenProject(file) ' open Enterprise Architect Set EAapp = CreateObject(\"EA.App\") WScript.echo \"opening Enterprise Architect. This might take a moment...\" ' load project EAapp.Repository.OpenFile(file) ' make Enterprise Architect to not appear on screen EAapp.Visible = False ' get repository object Set Repository = EAapp.Repository ' Show the script output window ' Repository.EnsureOutputVisible(\"Script\") call ExportGlossaryTermsAsJSONFile(Repository) Set projectInterface = Repository.GetProjectInterface() Dim childPackage 'As EA.Package ' Iterate through all model nodes Dim currentModel 'As EA.Package If (InStrRev(file,\"{\") &gt; 0) Then ' the filename references a GUID ' like {04C44F80-8DA1-4a6f-ECB8-982349872349} WScript.echo file GUID = Mid(file, InStrRev(file,\"{\")+0,38) WScript.echo GUID ' Iterate through all child packages and save out their diagrams call DumpPackageDiagrams(EAapp, GUID) Else If packageFilter.Count = 0 Then WScript.echo \"done\" ' Iterate through all model nodes For Each currentModel In Repository.Models ' Iterate through all child packages and save out their diagrams For Each childPackage In currentModel.Packages call DumpDiagrams(childPackage,currentModel) Next Next Else ' Iterate through all packages found in the package filter given by script parameter. For Each packageGUID In packageFilter call DumpPackageDiagrams(EAapp, packageGUID) Next End If End If EAapp.Repository.CloseFile() ' Since EA 15.2 the Enterprise Architect background process hangs without calling Exit explicitly On Error Resume Next EAapp.Repository.CloseFile() EAapp.Repository.Exit() EAapp.Repository = null ' end fix EA End Sub Private connectionString Private packageFilter Private exportDestination Private searchPath Private glossaryFilePath Private imageFormat Private diagramAttributes Private additionalOptions exportDestination = \"./src/docs\" searchPath = \"./src\" Set packageFilter = CreateObject(\"System.Collections.ArrayList\") Set objArguments = WScript.Arguments Dim argCount argCount = 0 While objArguments.Count &gt; argCount+1 Select Case objArguments(argCount) Case \"-c\" connectionString = objArguments(argCount+1) Case \"-p\" packageFilter.Add objArguments(argCount+1) Case \"-d\" exportDestination = objArguments(argCount+1) Case \"-s\" searchPath = objArguments(argCount+1) Case \"-g\" glossaryFilePath = objArguments(argCount+1) Case \"-f\" imageFormat = objArguments(argCount+1) Case \"-da\" diagramAttributes = objArguments(argCount+1) Case \"-ao\" additionalOptions = objArguments(argCount+1) Case Else WScript.echo \"unknown argument: \" &amp; objArguments(argCount) End Select argCount = argCount + 2 WEnd set fso = CreateObject(\"Scripting.fileSystemObject\") WScript.echo \"Image extractor\" ' Check both types in parallel - 1st check Enterprise Architect database connection, 2nd look for local project files If Not IsEmpty(connectionString) Then WScript.echo \"opening database connection now\" OpenProject(connectionString) End If WScript.echo \"looking for .eap(x) and .qea(x) files in \" &amp; fso.GetAbsolutePathName(searchPath) ' Dim f As Scripting.Files SearchEAProjects fso.GetFolder(searchPath) WScript.echo \"finished exporting images\" "
},

{
    "id": 58,
    "uri": "015_tasks/03_task_convertToEpub.html",
    "menu": "tasks",
    "title": "convertToEpub",
    "text": " Table of Contents convertToEpub Dependency About This Task Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } convertToEpub 1 minute to read Dependency generateDocBook About This Task This task uses pandoc to convert the DocBook output from AsciiDoctor to ePub. This publishes the output as an eBook which can be read using any eBook reader. The resulting file can be found in build/docs/epub . Further Reading and Resources Turn your Document into an Audio-Book blog post. Source Show source code of scripts/pandoc.gradle or go directly to GitHub · docToolchain/scripts/pandoc.gradle . scripts/pandoc.gradle task convertToEpub ( group: 'docToolchain', description: 'converts file to .epub via pandoc. Needs pandoc installed.', type: Exec ) { // All files with option `epub` in config.groovy is converted to docbook and then to epub. def sourceFilesEpub = sourceFiles.findAll { 'epub' in it.formats } def explicitSourceFilesCount = sourceFilesEpub.size() if(explicitSourceFilesCount==0){ sourceFilesEpub = sourceFiles.findAll { 'docbook' in it.formats } } sourceFilesEpub.each { def sourceFile = it.file.replace('.adoc', '.xml') def targetFile = sourceFile.replace('.xml', '.epub') new File(\"$targetDir/epub/$targetFile\") .getParentFile() .getAbsoluteFile().mkdirs() workingDir \"$targetDir/docbook\" executable = \"pandoc\" args = ['-r','docbook', '-t','epub', '-o',\"../epub/$targetFile\", sourceFile] } doFirst { if(sourceFilesEpub.size()==0){ throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'epub'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } if(explicitSourceFilesCount==0) { logger.warn('WARNING: No source files defined for type \"epub\". Converting with best effort') } } } "
},

{
    "id": 59,
    "uri": "015_tasks/03_task_exportVisio.html",
    "menu": "tasks",
    "title": "exportVisio",
    "text": " Table of Contents exportVisio About This Task Important Information About This Task Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportVisio 1 minute to read About This Task This task searches for Visio files in the /src/docs folder then exports all diagrams and element notes to /src/docs/images/visio and /src/docs/visio . Images are stored as /images/visio/[filename]-[pagename].png . Notes are stored as /visio/[filename]-[pagename].adoc You can specify a filename to export notes to by starting any comment with {adoc:[filename].adoc} . It will then be written to /visio/[filename].adoc . Important Information About This Task Currently, only Visio files stored directly in /src/docs are supported. All others will export to the wrong location. Before running this task, close any open Visio instance. Further Reading and Resources Issue #112 . Source Show source code of scripts/exportVisio.gradle or go directly to GitHub · docToolchain/scripts/exportVisio.gradle . scripts/exportVisio.gradle task exportVisio( dependsOn: [streamingExecute], description: 'exports all diagrams and notes from visio files', group: 'docToolchain' ) { doLast { //make sure path for notes exists //and remove old notes new File(docDir, 'src/docs/visio').deleteDir() //also remove old diagrams new File(docDir, 'src/docs/images/visio').deleteDir() //create a readme to clarify things def readme = \"\"\"This folder contains exported diagrams and notes from visio files. Please note that these are generated files but reside in the `src`-folder in order to be versioned. This is to make sure that they can be used from environments other than windows. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradle exportVisio` to re-export files \"\"\" new File(docDir, 'src/docs/images/visio/.').mkdirs() new File(docDir, 'src/docs/images/visio/readme.ad').write(readme) new File(docDir, 'src/docs/visio/.').mkdirs() new File(docDir, 'src/docs/visio/readme.ad').write(readme) def sourcePath = new File(docDir, 'src/docs/.').canonicalPath def scriptPath = new File(projectDir, 'scripts/VisioPageToPngConverter.ps1').canonicalPath \"powershell ${scriptPath} -SourcePath ${sourcePath}\".executeCmd() } } Show source code of scripts/VisioPageToPngConverter.ps1 or go directly to GitHub · docToolchain/scripts/VisioPageToPngConverter.ps1 . scripts/VisioPageToPngConverter.ps1 # Convert all pages in all visio files in the given directory to png files. # A Visio windows might flash shortly. # The converted png files are stored in the same directory # The name of the png file is concatenated from the Visio file name and the page name. # In addtion all the comments are stored in adoc files. # If the Viso file is named \"MyVisio.vsdx\" and the page is called \"FirstPage\" # the name of the png file will be \"MyVisio-FirstPage.png\" and the comment will # be stored in \"MyVisio-FirstPage.adoc\". # But for the name of the adoc files there is an alternative. It can be given in the first # line of the comment. If it is given in the comment it has to be given in curly brackes # with the prefix \"adoc:\", e.g. {adoc:MyCommentFile.adoc} # Prerequisites: Viso and PowerShell has to be installed on the computer. # Parameter: SourcePath where visio files can be found # Example powershell VisoPageToPngConverter.ps1 -SourcePath c:\\convertertest\\ Param ( [Parameter(Mandatory=$true,ValueFromPipeline=$true,Position=0)] [Alias('p')][String]$SourcePath ) Write-Output \"starting to export visio\" If (!(Test-Path -Path $SourcePath)) { Write-Warning \"The path \"\"$SourcePath\"\" does not exist or is not accessible, please input the correct path.\" Exit } # Extend the source path to get only Visio files of the given directory and not in subdircetories If ($SourcePath.EndsWith(\"\\\")) { $SourcePath = \"$SourcePath\" } Else { $SourcePath = \"$SourcePath\\\" } $VisioFiles = Get-ChildItem -Path \"$SourcePath*\" -Recurse -Include *.vsdx,*.vssx,*.vstx,*.vxdm,*.vssm,*.vstm,*.vsd,*.vdw,*.vss,*.vst If(!($VisioFiles)) { Write-Warning \"There are no Visio files in the path \"\"$SourcePath\"\".\" Exit } $VisioApp = New-Object -ComObject Visio.Application $VisioApp.Visible = $false # Extract the png from all the files in the folder Foreach($File in $VisioFiles) { $FilePath = $File.FullName Write-Output \"found \"\"$FilePath\"\" .\" $FileDirectory = $File.DirectoryName # Get the folder containing the Visio file. Will be used to store the png and adoc files $FileBaseName = $File.BaseName -replace '[ :/\\\\*?|&lt;&gt;]','-' # Get the filename to be used as part of the name of the png and adoc files Try { $Document = $VisioApp.Documents.Open($FilePath) $Pages = $VisioApp.ActiveDocument.Pages Foreach($Page in $Pages) { # Create valid filenames for the png and adoc files $PngFileName = $Page.Name -replace '[ :/\\\\*?|&lt;&gt;]','-' $PngFileName = \"$FileBaseName-$PngFileName.png\" $AdocFileName = $PngFileName.Replace(\".png\", \".adoc\") #TODO: this needs better logic Write-Output(\"$SourcePath\\images\\visio\\$PngFileName\") $Page.Export(\"$SourcePath\\images\\visio\\$PngFileName\") $AllPageComments = \"\" ForEach($PageComment in $Page.Comments) { # Extract adoc filename from comment text if the syntax is valid # Remove the filename from the text and save the comment in a file with a valid name $EofStringIndex = $PageComment.Text.IndexOf(\".adoc}\") if ($PageComment.Text.StartsWith(\"{adoc\") -And ($EofStringIndex -gt 6)) { $AdocFileName = $PageComment.Text.Substring(6, $EofStringIndex -1) $AllPageComments += $PageComment.Text.Substring($EofStringIndex + 6) } else { $AllPageComments += $PageComment.Text+\"`n\" } } If ($AllPageComments) { $AdocFileName = $AdocFileName -replace '[:/\\\\*?|&lt;&gt;]','-' #TODO: this needs better logic $stream = [System.IO.StreamWriter] \"$SourcePath\\visio\\$AdocFileName\" $stream.WriteLine($AllPageComments) $stream.close() } } $Document.Close() } Catch { if ($Document) { $Document.Close() } Write-Warning \"One or more visio page(s) in file \"\"$FilePath\"\" have been lost in this converting.\" Write-Warning \"Error was: $_\" } } $VisioApp.Quit() "
},

{
    "id": 60,
    "uri": "015_tasks/03_task_dependencyUpdates.html",
    "menu": "tasks",
    "title": "dependencyUpdates",
    "text": " Table of Contents dependencyUpdates About This Task Further Reading and Resources .gravatar img { margin-left: 3px; border-radius: 4px; } dependencyUpdates 1 minute to read About This Task This task uses the Gradle versions plugin created by Ben Manes to check for outdated build dependencies. Use this task to keep all dependencies up to date. Warning If you discover newer version, it doesn&#8217;t mean that versions and dependencies will play nicely together. To ensure that everything works, we recommend the versions selected by docToolchain contributors. Further Reading and Resources Read the Handle Dependency Updates the Easy Way blog post. "
},

{
    "id": 61,
    "uri": "015_tasks/03_task_wipeConfluenceSpace.html",
    "menu": "tasks",
    "title": "wipeConfluenceSpace",
    "text": " Table of Contents wipeConfluenceSpace About This Task Usage Source .gravatar img { margin-left: 3px; border-radius: 4px; } wipeConfluenceSpace 1 minute to read About This Task Warning This task is destructive and can harm your environment This task will wipe all content from your Confluence space, configured in your docToolchainConfig.groovy . It will not delete the space itself. The task makes it easy if you want to start from scratch with your documentation, or if you want to re-import your documentation from scratch after you did refactor your document structure and want to get rid of all the old pages. Usage ./dtcw wipeConfluenceSpace -PconfluenceUser=foo.bar@example.corp -PconfluencePass=&lt;REDACTED&gt; You will be asked to confirm the deletion of all pages in the space. Enter y to confirm. ... To honour the JVM settings for this build a single-use Daemon process will be forked. See https://docs.gradle.org/8.1.1/userguide/gradle_daemon.html#sec:disabling_the_daemon. Daemon will be stopped at the end of the build &gt; Task :wipeConfluenceSpace [ant:input] Do you really want to delete all pages in myDemoSpace (y, n) Source Show source code of scripts/publishToConfluence.gradle or go directly to GitHub · docToolchain/scripts/publishToConfluence.gradle . scripts/publishToConfluence.gradle task wipeConfluenceSpace( description: 'deletes all pages in the configured confluence space', group: 'docToolchain' ) { doLast { ant.input(message: \"${'Do you really want to delete all pages in ' + config.confluence.spaceKey}\", validargs: 'y,n', addproperty: 'confirm') if(ant.confirm.toBoolean()) { //TODO default should be false, if the V1 has been removed in cloud config.confluence.useV1Api = findProperty(\"confluence.useV1Api\") != null ? findProperty(\"confluence.useV1Api\") : config.confluence.useV1Api != [:] ? config.confluence.useV1Api :true new WipeConfluenceSpaceTask(config).execute() } else { println(\"Aborting wipe confluence space, this task needs to be confirmed with 'y'\") } } } "
},

{
    "id": 62,
    "uri": "015_tasks/03_task_prependFilename.html",
    "menu": "tasks",
    "title": "prependFilename",
    "text": " Table of Contents prependFilename About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } prependFilename 1 minute to read About This Task When Asciidoctor renders a file, the file context only knows the name of the top-level AsciiDoc file. But an include file doesn&#8217;t know that it is being included. It simply gets the name of the master file and has no chance to get its own name as an attribute. This task crawls through all AsciiDoc files and prepends the name of the current file like this: :filename: 015_tasks/03_task_prependFilename.adoc This way, each file gets its own filename. This enables features like the inclusion of file contributors (see exportContributors-task). Note This task skips all files named config.* , _config.* , feedback.* and _feedback.* . Source Show source code of scripts/prependFilename.gradle or go directly to GitHub · docToolchain/scripts/prependFilename.gradle . scripts/prependFilename.gradle import static groovy.io.FileType.* task prependFilename( description: 'crawls through all AsciiDoc files and prepends the name of the current file', group: 'docToolchain helper', ) { doLast { File sourceFolder = new File(\"${docDir}/${inputPath}\") println(\"sourceFolder: \" + sourceFolder.canonicalPath) sourceFolder.traverse(type: FILES) { file -&gt; if (file.name ==~ '^.*(ad|adoc|asciidoc)$') { if (file.name.split('[.]')[0] in [\"feedback\", \"_feedback\", \"config\", \"_config\"]) { println \"skipped \"+file.name } else { def text = file.getText('utf-8') def name = file.canonicalPath - sourceFolder.canonicalPath name = name.replace(\"\\\\\", \"/\").replaceAll(\"^/\", \"\") if (text.contains(\":filename:\")) { text = text.replaceAll(\":filename:.*\", \":filename: $name\") println \"updated \"+name } else { text = \":filename: $name\\n\" + text println \"added \"+name } file.write(text,'utf-8') } } } } } "
},

{
    "id": 63,
    "uri": "015_tasks/03_task_htmlSanityCheck.html",
    "menu": "tasks",
    "title": "htmlSanityCheck",
    "text": " Table of Contents htmlSanityCheck About This Task Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } htmlSanityCheck 1 minute to read About This Task This task invokes the htmlSanityCheck gradle plugin. It is a standalone (batch- and command-line) HTML sanity checker whose role is to detect missing images, dead links and duplicated bookmarks. In docToolchain, the htmlSanityCheck task ensures that generated HTML contains no missing links or other problems. It is the last default task, and creates a report in build/reports/htmlchecks/index.html (see example below). Figure 1. sample report Further Reading and Resources Read the Automated Quality-Checks blog post. Visit https://github.com/aim42/htmlSanityCheck for more information about this task. Source Show source code of scripts/htmlSanityCheck.gradle or go directly to GitHub · docToolchain/scripts/htmlSanityCheck.gradle . scripts/htmlSanityCheck.gradle htmlSanityCheck { sourceDir = new File(config.htmlSanityCheck.sourceDir?targetDir+\"/\"+config.htmlSanityCheck.sourceDir:\"$targetDir/html5\") // files to check - in Set-notation //sourceDocuments = [ \"one-file.html\", \"another-file.html\", \"index.html\"] // where to put results of sanityChecks... checkingResultsDir = new File(config.htmlSanityCheck.checkingResultsDir?:checkingResultsPath) // directory where the results written to in JUnit XML format junitResultsDir = new File(config.htmlSanityCheck.junitResultsDir?:\"$targetDir/test-results/htmlchecks\") // which statuscodes shall be interpreted as warning, error or success defaults to standard httpSuccessCodes = config.htmlSanityCheck.httpSuccessCodes?:[] httpWarningCodes = config.htmlSanityCheck.httpWarningCodes?:[] httpErrorCodes = config.htmlSanityCheck.httpErrorCodes?:[] // fail build on errors? failOnErrors = config.htmlSanityCheck.failOnErrors?:false logger.info \"docToolchain&gt; HSC sourceDir: ${sourceDir}\" logger.info \"docToolchain&gt; HSC checkingResultsDir: ${checkingResultsDir}\" } "
},

{
    "id": 64,
    "uri": "015_tasks/03_task_exportDrawIo.html",
    "menu": "tasks",
    "title": "exportDrawIo",
    "text": " Table of Contents exportDrawIo About This Task About diagrams.net How to Change Your Workflow to Use diagrams.net How to Convert a Confluence Page to AsciiDoc .gravatar img { margin-left: 3px; border-radius: 4px; } exportDrawIo 2 minutes to read About This Task There is no exportDrawIo task available in docToolchain because such a task is not required. You can continue to use diagrams.net (formerly known as draw.io) to edit your diagrams simply by making a change to your diagram-authoring workflow. About diagrams.net diagrams.net offers free and open source desktop editors for all major operating system platforms. Visit https://www.diagrams.net/integrations to find a desktop editor application compatible with your operating system. When you use the desktop version, just create your diagram with the .png (or even better, .dio.png ) extension and diagrams.net will always save your diagram as a PNG with the source as metadata. They have also launched a free plugin for VS Code and IntelliJ, so you can edit your diagrams offline! How to Change Your Workflow to Use diagrams.net Export your diagrams.net/draw.io diagrams as a PNG with the source embedded in the file metadata. This allows you to embed your diagrams into AsciiDoc source as you normally would (using the image:: macro) with the added advantage of storing the diagram source with the image itself. How to Convert a Confluence Page to AsciiDoc If you are converting a Confluence page with embedded draw.io diagrams to AsciiDoc, use this export workflow to continue using diagrams.net: Export an editable PNG diagram from Confluence. Load the diagram you want to export from Confluence. Click File &#160; &#8250; Export as &#160; &#8250; PNG&#8230;&#8203; . In the Image modal, make sure that Include a copy of my diagram is selected. Click Export to save the PNG file with the pattern [file].dio.png . Commit the exported PNG file to source control. Your diagram can now be managed in source control, added to your documentation source and edited using a diagrams.net desktop version. Note Specifying .dio (short for \" d raw io \") in the name will help you identify PNG files containing an embedded XML diagram source. // Please, replace #yourelement with a real element id on your webpage MarketplaceWidget.setupMarketplaceWidget('card', 15635, \"#myelement\"); "
},

{
    "id": 65,
    "uri": "015_tasks/03_task_generatePDF.html",
    "menu": "tasks",
    "title": "generatePDF",
    "text": " Table of Contents generatePDF About This Task Creating a Custom PDF Theme Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } generatePDF 2 minutes to read About This Task This task makes use of the asciidoctor-pdf plugin to render your documents as pretty PDF files. Files are written to build/pdf . The PDF is generated directly from your AsciiDoc sources. There is no need for an intermediate format or other tools. The result looks more like a nicely rendered book than a print-to-PDF HTML page. For a file to be rendered, it has to be configured in the doctoolchainConfig.groovy file. There you will find a section that looks like this: inputFiles = [ [file: 'manual.adoc', formats: ['html','pdf']], /** inputFiles **/ ] Add the files that you want to be rendered, along with the desired format. In this case pdf . Hint Why do you need to configure the files to be rendered? Asciidoctor renders all .adoc files by default. It doesn&#8217;t matter if they are the main documents or chapters you want to include. Most people only want to convert selected files to PDF, so that&#8217;s why you need to configure which ones. Creating a Custom PDF Theme If you want to change colors, fonts or page headers and footers, you can do so by creating a custom-theme.yml file. Copy the file src/docs/pdfTheme/custom-theme.yml from docToolchain to your project and reference it from your main .adoc`file by setting the `:pdf-themesdir: . In addition, set the :pdf-theme: to the name of your theme. In this case custom . For example, insert the following at the top of your document to reference custom-theme.yml from the /pdfTheme folder. :pdf-themesdir: ../pdfTheme :pdf-theme: custom Further Reading and Resources Learn how to modify a theme by reading asciidoctor-pdf theming guide . The Beyond HTML blog post is also an excellent resource if you want to dig a little deeper. Source Show source code of scripts/AsciiDocBasics.gradle or go directly to GitHub · docToolchain/scripts/AsciiDocBasics.gradle . scripts/AsciiDocBasics.gradle task generatePDF ( type: AsciidoctorTask, group: 'docToolchain', description: 'use pdf as asciidoc backend') { attributes ( 'plantUMLDir' : file(\"${docDir}/${config.outputPath}/pdf/images/plantUML/\").path, ) outputDir = file(targetDir + '/pdf/') attributes ( 'data-uri': 'true', 'plantUMLDir' : file(\"${docDir}/${config.outputPath}/images/\").path, 'imagesoutdir' : file(\"${docDir}/${config.outputPath}/images/\").path ) def sourceFilesPDF = findSourceFilesByType(['pdf']) // onlyIf { // sourceFilesPDF // } sources { sourceFilesPDF.each { include it.file logger.info it.file File useFile = new File(srcDir, it.file) if (!useFile.exists()) { throw new Exception (\"\"\" The file $useFile in PDF config does not exist! Please check the configuration 'inputFiles' in $mainConfigFile.\"\"\") } } } outputOptions { backends = ['pdf'] } doFirst { if (sourceFilesPDF.size()==0) { throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'pdf'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } } /** //check if a remote pdfTheme is defined def pdfTheme = System.getenv('DTC_PDFTHEME') def themeFolder = pdfTheme.md5() if (pdfTheme) { //check if it is already installed //TODO: finish this... } **/ } "
},

{
    "id": 66,
    "uri": "015_tasks/03_task_exportChangeLog.html",
    "menu": "tasks",
    "title": "exportChangeLog",
    "text": " Table of Contents exportChangeLog About This Task Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportChangeLog 2 minutes to read About This Task As the name suggests, this task exports the changelog to be referenced from within your documentation, if needed. The changelog is written to build/docs/changelog.adoc . This task can be configured to use a different source control system or a different directory. To configure this task, copy template_config/scripts/ChangelogConfig.groovy to your directory and modify to suit your needs. Then use -PchangelogConfigFile=&lt;your config file&gt; to add the path to your configuration file to the task. See the description inside the template for more details. By default, the source is the Git changelog for the path src/docs and only contains the commit messages for changes made to the documentation. All changes to the build or other sources in the repository will not show up. By default, the changelog contains changes made to date , author and commit message already formatted as AsciiDoc table content: | 09.04.2017 | Ralf D. Mueller | fix #24 template updated to V7.0 | 08.04.2017 | Ralf D. Mueller | fixed typo You simply include it like this: .Changes [options=\"header\",cols=\"1,2,6\"] |==== | Date | Author | Comment include::../../build/docs/changelog.adoc[] |==== By excluding the table definition, you can easily translate the table headings through different text snippets. Note In a future docToolchain release, you will have the ability to include only certain commit messages from the changelog and exclude others (starting with # or // ?). This feature is not available just yet. Further Reading and Resources The only constant in life is change blog post. Source Show source code of scripts/exportChangelog.gradle or go directly to GitHub · docToolchain/scripts/exportChangelog.gradle . scripts/exportChangelog.gradle task exportChangeLog( description: 'exports the change log from a git subpath', group: 'docToolchain' ) { doFirst { new File(targetDir).mkdirs() } doLast { logger.info(\"docToolchain&gt; docDir: \"+docDir) logger.info(\"docToolchain&gt; mainConfigFile: \"+mainConfigFile) def config = new ConfigSlurper().parse(new File(docDir, mainConfigFile).text) def cmd = \"${config.changelog.cmd} .\" def changes = cmd.execute(null, new File(docDir, config.changelog.dir)).text def changelog = new File(targetDir, 'changelog.adoc') logger.info \"&gt; changelog exported ${changelog.canonicalPath}\" changelog.write(changes) } } "
},

{
    "id": 67,
    "uri": "015_tasks/03_task_autobuildSite.html",
    "menu": "tasks",
    "title": "autobuildSite",
    "text": " Table of Contents autobuildSite About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } autobuildSite 1 minute to read About This Task This script starts an endless loop which checks for changes to your docs source then re-runs the generateSite -task whenever it detects changes. The output will be logged to build/generateSite.log . Source Show source code of bin/autobuildSite.bash or go directly to GitHub · docToolchain/bin/autobuildSite.bash . bin/autobuildSite.bash #!/bin/bash DIR_TO_WATCH='src/' #COMMAND='rm -r build || true &amp;&amp; mkdir -p build/microsite/output/images/ &amp;&amp; ./dtcw generateSite 2&gt;&amp;1 | tee build/generateSite.log' COMMAND='mkdir -p build/microsite/output/images/ &amp;&amp; ./dtcw generateSite 2&gt;&amp;1 | tee build/generateSite.log' #execute first time cp src/docs/images/ready.png build/microsite/output/images/status.png #eval $COMMAND #wait for changes and execute while true ; do watch --no-title --chgexit \"ls -lR ${DIR_TO_WATCH} | sha1sum\" cp src/docs/images/building.png build/microsite/output/images/status.png eval \"$COMMAND\" cp src/docs/images/ready.png build/microsite/output/images/status.png sleep 6 done "
},

{
    "id": 68,
    "uri": "015_tasks/150_task_createTask.html",
    "menu": "tasks",
    "title": "createTask",
    "text": " Table of Contents createTask About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } createTask 1 minute to read About This Task You miss a special task in the above list? Or maybe you want to change a task to better fit your needs? Why not create your own project specific task? Execute ./dtcw createTask and docToolchain will create and configure a custom gradle task for you in a folder scripts . To get started, take a look at all the other tasks to see how they solve problems. Copy and modify the code to your own task and start hacking. Source Show source code of scripts/customTasks.gradle or go directly to GitHub · docToolchain/scripts/customTasks.gradle . scripts/customTasks.gradle config.customTasks?.each { task -&gt; println \"include custom task $task\" apply from: docDir+'/'+task } task createTask( description: 'create a new Task as quick start', group: 'docToolchain' ) { doLast { def file = new File(docDir+'/scripts/customTask.gradle') new File(docDir+\"/scripts\").mkdirs() file.write(\"\"\"\\ task customTask ( description: 'a custom task', group: 'docToolchain' ) { doLast { println \"your own custom task\" } } \"\"\") def config = new File(docDir+'/'+mainConfigFile) config.write(config.text.replaceAll( \"/[*][*] customTasks [*][*]/\", \"'scripts/customTask.gradle',\\n\\t\\t/** customTasks **/\" )) println \"\"\" custom task ${file.canonicalPath} created and configured \"\"\" } } "
},

{
    "id": 69,
    "uri": "015_tasks/03_task_exportPPT.html",
    "menu": "tasks",
    "title": "exportPPT",
    "text": " Table of Contents exportPPT About This Task Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportPPT 1 minute to read About This Task This task lets you export a series of PowerPoint slides to be used within your AsciiDoc documentation. It is currently a Windows-only task. It exports the slides as .jpg files and the speaker notes as one .adoc file. The tag {slide} within the speaker notes will be replaced with the corresponding image reference. This will help you to get a stable result, even when you insert or delete slides. Use the tagged regions ( //tag::[ ) feature of asciidoctor] to include only certain slides or parts of your speaker notes. Further Reading and Resources Read the Do More with Slides blog post. Find more information about the Windows-only aspect of this task in this issue . Check out asciidoctorj-office-extension for another way to use PPT slides in your docs. Source Show source code of scripts/exportPPT.gradle or go directly to GitHub · docToolchain/scripts/exportPPT.gradle . scripts/exportPPT.gradle task exportPPT( dependsOn: [streamingExecute], description: 'exports all slides and some texts from PPT files', group: 'docToolchain' ) { doLast { File sourceDir = file(srcDir) logger.info(\"sourceDir: ${sourceDir}\") //make sure path for notes exists //and remove old notes new File(sourceDir, 'ppt').deleteDir() //also remove old diagrams new File(sourceDir, 'images/ppt').deleteDir() //create a readme to clarify things def readme = \"\"\"This folder contains exported slides or notes from .ppt presentations. Please note that these are generated files but reside in the `src`-folder in order to be versioned. This is to make sure that they can be used from environments other than windows. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradle exportPPT` to re-export files \"\"\" new File(sourceDir, 'images/ppt/.').mkdirs() new File(sourceDir, 'images/ppt/readme.ad').write(readme) new File(sourceDir, 'ppt/.').mkdirs() new File(sourceDir, 'ppt/readme.ad').write(readme) def searchPath = new File(sourceDir, 'ppt') //execute through cscript in order to make sure that we get WScript.echo right \"%SystemRoot%\\\\System32\\\\cscript.exe //nologo ${projectDir}/scripts/exportPPT.vbs -s ${sourceDir.absolutePath}\".executeCmd() } } Show source code of scripts/exportPPT.vbs or go directly to GitHub · docToolchain/scripts/exportPPT.vbs . scripts/exportPPT.vbs Const ForAppending = 8 Const ppPlaceholderBody = 2 ' Helper ' http://windowsitpro.com/windows/jsi-tip-10441-how-can-vbscript-create-multiple-folders-path-mkdir-command Function MakeDir (strPath) Dim strParentPath, objFSO Set objFSO = CreateObject(\"Scripting.FileSystemObject\") On Error Resume Next strParentPath = objFSO.GetParentFolderName(strPath) If Not objFSO.FolderExists(strParentPath) Then MakeDir strParentPath If Not objFSO.FolderExists(strPath) Then objFSO.CreateFolder strPath On Error Goto 0 MakeDir = objFSO.FolderExists(strPath) End Function Function SearchPresentations(path) For Each folder In path.SubFolders SearchPresentations folder Next For Each file In path.Files If (Left(fso.GetExtensionName (file.Path), 3) = \"ppt\") OR (Left(fso.GetExtensionName (file.Path), 3) = \"pps\") Then WScript.echo \"found \"&amp;file.path ExportSlides(file.Path) End If Next End Function Sub ExportSlides(sFile) Set objRegEx = CreateObject(\"VBScript.RegExp\") objRegEx.Global = True objRegEx.IgnoreCase = True objRegEx.MultiLine = True ' \".\" doesn't work for multiline in vbs, \"[\\s,\\S]\" does... objRegEx.Pattern = \"[\\s,\\S]*{adoc}\" ' http://www.pptfaq.com/FAQ00481_Export_the_notes_text_of_a_presentation.htm strFileName = fso.GetFIle(sFile).Name Err.Clear Set oPPT = CreateObject(\"PowerPoint.Application\") Set oPres = oPPT.Presentations.Open(sFile, True, False, False) ' Read Only, No Title, No Window On Error resume next Set oSlides = oPres.Slides WScript.echo \"number slides: \"&amp;oSlides.Count strNotesText = \"\" strImagePath = \"/images/ppt/\" &amp; strFileName &amp; \"/\" MakeDir(searchPath &amp; strImagePath) strNotesPath = \"/ppt/\" MakeDir(searchPath &amp; strNotesPath) For Each oSl In oSlides strSlideName = oSl.Name 'WScript.echo fso.GetAbsolutePathName(searchPath) &amp; strImagePath &amp; strSlideName &amp; \".jpg\" oSl.Export fso.GetAbsolutePathName(searchPath) &amp; strImagePath &amp; strSlideName &amp; \".jpg\", \".jpg\" For Each oSh In oSl.NotesPage.Shapes If oSh.PlaceholderFormat.Type = ppPlaceholderBody Then If oSh.HasTextFrame Then If oSh.TextFrame.HasText Then strCurrentNotes = oSh.TextFrame.TextRange.Text strCurrentNotes = Replace(strCurrentNotes,vbVerticalTab, vbCrLf) strCurrentNotes = Replace(strCurrentNotes,\"{slide}\",\"image::ppt/\"&amp;strFileName&amp;\"/\"&amp;strSlideName&amp;\".jpg[]\") ' remove speaker notes before marker \"{adoc}\" strCurrentNotes = objRegEx.Replace(strCurrentNotes,\"\") strNotesText = strNotesText &amp; vbCrLf &amp; strCurrentNotes &amp; vbCrLf &amp; vbCrLf End If End If End If Next Next ' WScript.echo fso.GetAbsolutePathName(\".\") &amp; strNotesPath&amp;\"\"&amp;strFileName&amp;\".ad\" ' http://stackoverflow.com/questions/2524703/save-text-file-utf-8-encoded-with-vba Set fsT = CreateObject(\"ADODB.Stream\") fsT.Type = 2 'Specify stream type - we want To save text/string data. fsT.Charset = \"utf-8\" 'Specify charset For the source text data. fsT.Open 'Open the stream And write binary data To the object fsT.WriteText \"ifndef::imagesdir[:imagesdir: ../../images]\"&amp;vbCrLf&amp;CStr(strNotesText) fsT.SaveToFile fso.GetAbsolutePathName(searchPath) &amp; strNotesPath&amp;\"\"&amp;strFileName&amp;\".ad\", 2 'Save binary data To disk oPres.Close() oPPT.Quit() If Err.Number &lt;&gt; 0 Then WScript.Echo \"Error: \" &amp; Err.Number WScript.Echo \"Error (Hex): \" &amp; Hex(Err.Number) WScript.Echo \"Source: \" &amp; Err.Source WScript.Echo \"Description: \" &amp; Err.Description Err.Clear ' Clear the Error End If End Sub set fso = CreateObject(\"Scripting.fileSystemObject\") WScript.echo \"Slide extractor\" Set objArguments = WScript.Arguments Dim argCount argCount = 0 While objArguments.Count &gt; argCount+1 Select Case objArguments(argCount) Case \"-s\" searchPath = objArguments(argCount+1) End Select argCount = argCount + 2 WEnd WScript.echo \"looking for .ppt files in \" &amp; fso.GetAbsolutePathName(searchPath) SearchPresentations fso.GetFolder(searchPath) WScript.echo \"finished exporting slides\" "
},

{
    "id": 70,
    "uri": "015_tasks/03_task_exportMetrics.html",
    "menu": "tasks",
    "title": "exportMetrics",
    "text": " Table of Contents exportMetrics .gravatar img { margin-left: 3px; border-radius: 4px; } exportMetrics 1 minute to read This task crawls through all Asciidoctor source files and extracts the total number of words in each file (word count), so you can check your writing progress. The output is displayed on the command line. "
},

{
    "id": 71,
    "uri": "015_tasks/03_task_exportMarkdown.html",
    "menu": "tasks",
    "title": "exportMarkdown",
    "text": " Table of Contents exportMarkdown About This Task Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportMarkdown 1 minute to read About This Task The exportMarkdown task can be used to include markdown files into the documentation. It scans the /src/docs directory for markdown ( *.md ) files and converts them into Asciidoc files. The converted files can then be referenced from within the /build -folder. Source Show source code of scripts/exportMarkdown.gradle or go directly to GitHub · docToolchain/scripts/exportMarkdown.gradle . scripts/exportMarkdown.gradle task exportMarkdown( description: 'exports all markdown files to AsciiDoc', group: 'docToolchain', type: Copy ) { from srcDir include(\"**/*.md\") //include only markdown files includeEmptyDirs = false rename(/(.+).md/, '$1.adoc') //rename all files from *.md to *.adoc filter(Markdown2AdocFilter) // convert the content of the files into targetDir } class Markdown2AdocFilter extends FilterReader { Markdown2AdocFilter(Reader input) { super(new StringReader(nl.jworks.markdown_to_asciidoc.Converter.convertMarkdownToAsciiDoc(input.text))) } } "
},

{
    "id": 72,
    "uri": "015_tasks/03_task_exportExcel.html",
    "menu": "tasks",
    "title": "exportExcel",
    "text": " Table of Contents exportExcel About This Task Further Reading and Resources Source .gravatar img { margin-left: 3px; border-radius: 4px; } exportExcel 2 minutes to read About This Task Sometimes you need to include tabular data in your documentation. Most likely, this data will be stored as a MS Excel spreadsheet, or you may like to use Excel to create and edit it. Either way, this task lets you export an Excel spreadsheet and include it directly in your docs. It searches for .xlsx files and exports each contained worksheet as .csv and as .adoc . Note that formulas contained in your spreadsheet are evaluated and exported statically. The generated files are written to src/excel/[filename]/[worksheet].(adoc|cvs) . The src folder is used instead of the build folder because a better history of worksheet changes is captured. The files can be included either as AsciiDoc: include::excel/Sample.xlsx/Numerical.adoc[] &#8230;&#8203;or as a CSV file: [options=\"header\",format=\"csv\"] |=== include::excel/Sample.xlsx/Numerical.csv[] |=== The AsciiDoc version gives you a bit more control because the following are preserved: Horizontal and vertical alignment. col-span and row-span. Line breaks. Column width relative to other columns. Background colors. Further Reading and Resources See asciidoctorj-office-extension to learn another way to use Excel spreadsheets in your docs. Source Show source code of scripts/exportExcel.gradle or go directly to GitHub · docToolchain/scripts/exportExcel.gradle . scripts/exportExcel.gradle task exportExcel( description: 'exports all excelsheets to csv and AsciiDoc', group: 'docToolchain' ) { doFirst { File sourceDir = file(srcDir) def tree = fileTree(srcDir).include('**/*.xlsx').exclude('**/~*') def exportFileDir = new File(sourceDir, 'excel') //make sure path for notes exists exportFileDir.deleteDir() //create a readme to clarify things def readme = \"\"\"This folder contains exported workbooks from Excel. Please note that these are generated files but reside in the `src`-folder in order to be versioned. This is to make sure that they can be used from environments other than windows. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradle exportExcel` to re-export files \"\"\" exportFileDir.mkdirs() new File(exportFileDir, '/readme.ad').write(readme) } doLast { File sourceDir = file(srcDir) def exportFileDir = new File(sourceDir, 'excel') def tree = fileTree(srcDir).include('**/*.xlsx').exclude('**/~*') def nl = System.getProperty(\"line.separator\") def export = { sheet, evaluator, targetFileName -&gt; def targetFileCSV = new File(targetFileName + '.csv') def targetFileAD = new File(targetFileName + '.adoc') def df = new org.apache.poi.ss.usermodel.DataFormatter(); def regions = [] sheet.numMergedRegions.times { regions &lt;&lt; sheet.getMergedRegion(it) } logger.debug \"sheet contains ${regions.size()} regions\" def color = '' def resetColor = false def numCols = 0 def headerCreated = false def emptyRows = 0 for (int rowNum=0; rowNum&lt;=sheet.lastRowNum; rowNum++) { def row = sheet.getRow(rowNum) if (row &amp;&amp; !headerCreated) { headerCreated = true // create AsciiDoc table header def width = [] numCols = row.lastCellNum numCols.times { columnIndex -&gt; width &lt;&lt; sheet.getColumnWidth((int) columnIndex) } //lets make those numbers nicer: width = width.collect { Math.round(100 * it / width.sum()) } targetFileAD.append('[options=\"header\",cols=\"' + width.join(',') + '\"]' + nl) targetFileAD.append('|===' + nl) } def data = [] def style = [] def colors = [] // For each row, iterate through each columns if (row &amp;&amp; (row?.lastCellNum!=-1)) { numCols.times { columnIndex -&gt; def cell = row.getCell(columnIndex) if (cell) { def cellValue = df.formatCellValue(cell, evaluator) if (cellValue.startsWith('*') &amp;&amp; cellValue.endsWith('\\u20AC')) { // Remove special characters at currency cellValue = cellValue.substring(1).trim(); } def cellStyle = '' def region = regions.find { it.isInRange(cell.rowIndex, cell.columnIndex) } def skipCell = false if (region) { //check if we are in the upper left corner of the region if (region.firstRow == cell.rowIndex &amp;&amp; region.firstColumn == cell.columnIndex) { def colspan = 1 + region.lastRow - region.firstRow def rowspan = 1 + region.lastColumn - region.firstColumn if (rowspan &gt; 1) { cellStyle += \"${rowspan}\" } if (colspan &gt; 1) { cellStyle += \".${colspan}\" } cellStyle += \"+\" } else { skipCell = true } } if (!skipCell) { switch (cell.cellStyle.getCellAlignment().getHorizontal().toString()) { case 'RIGHT': cellStyle += '&gt;' break case 'CENTER': cellStyle += '^' break } switch (cell.cellStyle.getCellAlignment().getVertical().toString()) { case 'BOTTOM': cellStyle += '.&gt;' break case 'CENTER': cellStyle += '.^' break } color = cell.cellStyle.fillForegroundXSSFColor?.RGB?.encodeHex() color = color != null ? nl + \"{set:cellbgcolor:#${color}}\" : '' data &lt;&lt; cellValue if (color == '' &amp;&amp; resetColor) { colors &lt;&lt; nl + \"{set:cellbgcolor!}\" resetColor = false } else { colors &lt;&lt; color } if (color != '') { resetColor = true } style &lt;&lt; cellStyle } else { data &lt;&lt; \"\" colors &lt;&lt; \"\" style &lt;&lt; \"skip\" } } else { data &lt;&lt; \"\" colors &lt;&lt; \"\" style &lt;&lt; \"\" } } emptyRows = 0 } else { if (emptyRows&lt;3) { //insert empty row numCols.times { data &lt;&lt; \"\" colors &lt;&lt; \"\" style &lt;&lt; \"\" } emptyRows++ } else { break } } targetFileCSV.append(data .collect { \"\\\"${it.replaceAll('\"', '\"\"')}\\\"\" } .join(',') + nl, 'UTF-8') // fix #1192 https://github.com/docToolchain/docToolchain/issues/1192 // remove unnecessary spans which break Asciidoctor rendering def prev = '' def removed = [] def useRemoved = true style.eachWithIndex { s, i -&gt; if (s!=\"skip\") { if (s.contains('+')) { def span = s.split('[+]')[0].split('[.]') def current = \"\" if (span.size()&gt;1) { current = span[1] } if (span[0] != '') { removed &lt;&lt; span[0] + '+' + s.split('[+]')[1] } else { removed &lt;&lt; s.split('[+]')[1] } if (i &gt; 0) { if (current != prev) { useRemoved = false } } prev = current } else { removed &lt;&lt; s useRemoved = false } } else { removed &lt;&lt; \"skip\" } } if (useRemoved) { style = removed } // fix #1192 https://github.com/docToolchain/docToolchain/issues/1192 targetFileAD.append(data .withIndex() .collect { value, index -&gt; if (style[index] == \"skip\") { \"\" } else { style[index] + \"| ${value.replaceAll('[|]', '{vbar}').replaceAll(\"\\n\", ' +$0') + colors[index]}\" } } .join(nl) + nl * 2, 'UTF-8') } targetFileAD.append('|===' + nl) // rewrite file to remove consecutive nl targetFileAD.write(targetFileAD.text.replaceAll(\"(?m)(\\\\r?\\\\n){2,}\", nl+nl)) } tree.each { File excel -&gt; println \"file: \" + excel def excelDir = new File(exportFileDir, excel.getName()) excelDir.mkdirs() InputStream inp inp = new FileInputStream(excel) def wb = org.apache.poi.ss.usermodel.WorkbookFactory.create(inp); def evaluator = wb.getCreationHelper().createFormulaEvaluator(); for (int wbi = 0; wbi &lt; wb.getNumberOfSheets(); wbi++) { def sheetName = wb.getSheetAt(wbi).getSheetName() println \" -- sheet: \" + sheetName def targetFile = new File(excelDir, sheetName) export(wb.getSheetAt(wbi), evaluator, targetFile.getAbsolutePath()) } inp.close(); } } } "
},

{
    "id": 73,
    "uri": "050_ADRs/ADR-2-separate-core-logic-from-gradle.html",
    "menu": "ADRs",
    "title": "ADR-02: Separate core logic from Gradle",
    "text": " Table of Contents ADR-02: Separate core logic from Gradle Status Problem and Context Decision Alternatives Consequences :gradle-submoduleshttps://docs.gradle.org/current/userguide/multi_project_builds.html#sec:adding_subprojects ADR-02: Separate core logic from Gradle Status This decision is currently under ongoing discussion. Problem and Context The structure of the docToolchain project, is historically grown and has been adapted to the needs of the project. The project is built with Gradle. Although Gradle is a powerful build tool that allows for a lot of flexibility, there are some recommendation on how to setup and structure a project, docToolchains setup is quite customized only follows few conventions. The project setup is not very well documented, which makes it difficult for new developers to understand the build process. Furthermore, the build scripts have become increasingly complex over time, which makes it difficult to maintain them. Apart from the aforementioned problems, docToolchain is currently very tightly coupled to Gradle, which in some scenarios leads to high startup times, e.g. when running tests. Decision There has been a vital discussion on GitHub around docToolchain v3, which has led to the decision to separate the core logic from Gradle. The core logic will be implemented in Groovy and will be used by Gradle. Gradle, as a first-class citizen, is then considered as a tool to provide a convenient way to use the core logic. The core logic will be implemented in a way that it is in the first steps completely isolated from Gradle. This paves the road for even further decoupling from Gradle in the future. This decision has several advantages: Developer experience is improved, as the core logic is easier to understand and to maintain. IDE support is improved, as the core logic is like any other Groovy project, no custom setup required. Encapsulating business logic into a dedicated submodule that does not know anything about Gradle or any other buildtool, opens the door for non-Gradle usage. Core logic is not splattered over scripts and Gradle task definitions, but is concentrated in a single place. Dependencies are easier to manage, as they are defined in a single place. Gradle buildscripts only have a single dependency to the core logic. Tests can be executed without Gradle, which leads to faster test execution. Alternatives Keep the current setup We could keep the current setup, but this would block to the aforementioned improvements. Separate core logic into Gradle&#8217;s buildSrc We could separate the core logic into Gradle&#8217;s buildSrc . While this would improve the situation, it would still not solve the problem of having the core logic tightly coupled to Gradle. Furthermore, it would not solve the problem of having a complex/ slow test setup, since there is still the need for Gradle runner. On top buildSrc is meant for complex build logic and not for business logic. See this PR for an example Separate core logic into a separate project We could separate the core logic into a separate project. This would solve the problem of having the core logic tightly coupled to Gradle. While a submodule in the first step is still part of the current project, it relieves the core logic from the need to know about Gradle. However, some tasks rely on Gradle plugins, this would make it difficult to execute them without Gradle. See this PR for an example Consequences As a result of this decision, the setup needs to be migrated to the new structure. This includes: Migrating the core logic into a separate submodule Revise current implementation Logic that solely depends on Gradle plugins should be kept as is to avoid unnecessary effort and reduce the overall scope of the migration Migrating the tests into the new submodule Adopt the buildscripts to use the new submodule New features should be implemented in the new submodule. Gradle Task should only be used to provide a convenient default way to use the core logic. "
},

{
    "id": 74,
    "uri": "10_about/20_what-is-doctoolchain.html",
    "menu": "about",
    "title": "What Is docToolchain?",
    "text": " Table of Contents What Is docToolchain? Introduction Docs as Code arc42 How docToolchain Brings Everything Together What You Get with docToolchain .gravatar img { margin-left: 3px; border-radius: 4px; } What Is docToolchain? 4 minutes to read Introduction docToolchain is a documentation generation tool that uses the Docs as Code approach as a basis for its architecture, plus some additional automation provided by the arc42 template . Docs as Code ‘Docs as code’ refers to a philosophy that you should write documentation using the same tools as you use to write code. If you need to write technical docs for your software project, why not use the same tools and processes as you use for your source code? There are so many benefits: You don’t have to learn a complicated docs management system. Developers feel more at home in the docs because they look and feel like code. You can manage docs using standard version control like GitHub. arc42 arc42 has been a part of docToolchain since the earliest version. But what is arc42? Dr. Gernot Starke and Peter Hruschka created the arc42 template as a standard for software architecture documentation. They used their experience of software architectures both in the template structure and the explanations that appear in each chapter to guide you when you’re writing your documentation. arc42 is available in well-known formats including MS Word, textile, and Confluence. All of these formats are automatically generated from a single golden master which is formatted in AsciiDoc . How docToolchain Brings Everything Together To follow a docs as code approach, you need a build script that automates steps like exporting diagrams and rendering Markdown (or AsciiDoc in the case of docToolchain) to the target format. Creating this type of build script is not easy (and even harder to maintain). There are also lots of questions to answer: “How do I create .docx?” and “Why doesn’t lib x work with lib y?” docToolchain is the result of one developer’s journey through the docs as code universe. The goal of docToolchain is to automate the creation of technical docs through an easy-to-use build script that only needs to be configured not modified, and that is nurtured and cared for by a diverse open source community . What You Get with docToolchain A Ready-Made Document Management System By using a version control system like Git , you get a perfect document management system for free. Git allows you to version your docs, branch them, and also leaves an audit trail. You can even check who wrote which part of the docs. Isn’t that great? And because your docs are simple plain text, it’s easy to do a diff and see exactly what has changed. Bonus: storing your docs in the same repo as your code means they’re always in sync! Built-In Collaboration and Review As a distributed version control system, Git comes with doc collaboration and review processes built in. People can fork the docs and send pull requests for the changes they make. You review the changes. Done! Most Git frontends like Bitbucket , GitLab and GitHub also allow you to reject pull requests with comments. Image References and Code Snippets Instead of pasting images into a binary document format, docToolchain lets you reference images. This ensures that your imagery is always up-to-date every time you rebuild your documents. You can also reference code snippets directly from your source code. You&#8217;ll save so much time because your docs and code will always be in sync and completely up to date! Compound and Stakeholder-Tailored Docs As if image refs and code snippets weren&#8217;t enough, docToolchain also lets you split docs into several sub-documents plus a master for greater cohesion. And you&#8217;re not restricted to one master. You can create master docs for different stakeholders that only contain the chapters they need. And So Much More&#8230;&#8203; If you can dream it, you can script it! Want to include a list of open issues from Jira? You can! Want to include a changelog from Git? Go for it! Want to use inline text-based diagrams? Knock yourself out! "
},

{
    "id": 75,
    "uri": "050_ADRs/ADR-1-Scripting-Languages.html",
    "menu": "ADRs",
    "title": "ADR-01: Scripting",
    "text": " Table of Contents ADR-01: Scripting Languages in docToolchain Status Problem and Context Decision Consequences ADR-01: Scripting Languages in docToolchain Status This decision is currently in effect. Problem and Context In the docToolchain project, we have a variety of scripts written in different languages. This has raised questions about the rationale behind the selection of different languages for different scripts, especially when it comes to managing and maintaining these scripts. Decision We have decided to primarily use Groovy for scripting tasks in the docToolchain project. This decision is based on the following reasons: Groovy is a language on the JVM, which is well-known and widely used in our team. Groovy is essentially Java on steroids, with 95% of Java code also being valid Groovy code, making it a versatile and powerful language for our needs. However, we also use other languages when necessary. For instance, we use Visual Basic when there are no suitable Java libraries for certain tasks, such as extracting PowerPoint slides or diagrams from Sparx Enterprise Architect. The interaction between scripts written in different languages is managed through a Gradle task, which is also written in Groovy. This task invokes the necessary scripts through the shell, using a \"streamingExecute\" helper to show the progress of long-running scripts on the console. Consequences As a result of this decision, most scripts are developed for a specific purpose at a given point in time and are updated only when necessary. Some scripts are updated on a regular basis due to their widespread use and the varying needs of users. Legacy scripts will be updated when there is a need for it. "
},

{
    "id": 76,
    "uri": "10_about/10_about-the-project.html",
    "menu": "about",
    "title": "About the Project",
    "text": " Table of Contents About the Project History How docToolchain Is Used Organisations Using It Open Source Projects Using It About the Project 2 minutes to read History docToolchain is an open source project dedicated to automating the creation of technical documentation. Before the project started, the founders had never heard of the term 'docs as code'. All they knew was that they were sick of keeping their architecture diagrams up to date by copying them from a UML tool to a word processor. Being lazy developers, they thought \"There must be a better way to do this!\". So they automated the diagram export, ditched their word processors, and started using a markup renderer. This enabled them to reference the diagrams from within the text and update them before rendering the document. And so, docToolchain was born. How docToolchain Is Used The main focus of docToolchain is technical documentation. It was traditionally used only for internal docs projects that were not visible to the public. From v2.0.0 we included a static site generator which means that open source projects and other organisations with public-facing docs can use it. Organisations Using It docToolchain is currently being used by the following organisations. If you&#8217;re also using it, please let us know! We love watching our user community grow, and your support keeps the project alive to fight the good docs fight! Open Source Projects Using It If your open source project is using docToochain, please let us know by sending a pull request: docToolchain ( source ) Html Sanity Check ( source ) DB Systel Tech Stories "
},

{
    "id": 77,
    "uri": "10_about/30_community.html",
    "menu": "about",
    "title": "Acknowledgements and Contributors",
    "text": " Table of Contents Acknowledgements and Contributors Why Contributions Matter Get Involved! Our Contributors Acknowledgements and Contributors 3 minutes to read Why Contributions Matter Without our amazing community of contributors, the docToolchain project wouldn’t exist in its current form. As an open source project, we depend on the skills and expertise of many to deliver a quality outcome. From developers to technical writers, many people have made valuable contributions to the code and the docs. We’re so grateful to them. We are also thankful for those in our community who take the time to give feedback, create issues, answer questions and send pull requests. Get Involved! There are so many technologies that support docToolchain, including AsciiDoc, AsciiDoctor, Gradle and arc42. We need all the help we can get to make improvements and keep our project humming. Simply create an issue and send a pull request. Our Contributors Please get in touch to update your entry or let us know if you have contributed in some way and we will add you to the list. Stefan Bodewig MoePad Niels wschaef Gernot Starke Jan Matèrne Alexander Schwartz Alexander Heusingfeld Dan Allen Stefan Pfeiffer isidorotrevino Jakub Jablonski Frank Pohl Ixchel Ruiz Schalk Cronjé Mario García Joe David M. Carr Fabian Nonnenmacher Christoph Stoettner Roman Funk ghp-dev Christoph Raaflaub Jorge Aguilera Stefan Bohn Jochen Kraushaar Luis Muniz Andreas Offenhaeuser Daniel Bast Sabatmonk Maarten Gribnau Michael Prieß Heiko Stehli Peter Stange Nils Mahlstädt @ hmmh Kevin Werner J. Staub Vladi Bjelakovic Daniel Kessel Björn Seebeck Txemanu Nikolay Orozov Andrea Macaluso Michael Roßner Jan Hendriks Daniel Kocot Alexander Schmitt Jérémie Bresson Jody Winter Aaron Collier Ifeanyi Benedict Iheagwara Jan-Niklas Vierheller Sebastian Schuetze David Schowalter Martin Fischer Stefan Boos Adrian Partl Siva Kalidasan Bjoern Kasteleiner Jan Küfner Gerd Aschemann Andreas Klemp Adi König Bence Hornák ZHENG Bote Miranda Boerlage Guido Sörmann Björn Erlwein Tulio Camminati Joachim Röttinger Pascal Euhus Max Hofer Sandra Parsick Johannes Thorn Stefan Rotman Kevin Latka Michael Roßner Jan Stückrath Timo Abele Patrizio Bonzani Lutz Ashauer Igor Gaiduk "
},

{
    "id": 78,
    "uri": "025_development/020_run_tests.html",
    "menu": "development",
    "title": "Running Tests",
    "text": " Table of Contents Running Tests Execute Tests Execute a specific test Workaround to Ensure Correct Proxy Settings for Tests Running Tests 2 minutes to read docToolchain uses Spock as Test-Framework. See http://spockframework.org/ for details. Execute Tests rm -r build &amp;&amp; ./gradlew test --info The rm command ensures that you have a clean test running. This is vital because if artifacts of an older test run still exist, Gradle will skip steps (‘Up-to-date’) and you might get false positives. Execute a specific test rm -r build &amp;&amp; ./gradlew test --info --tests=ExportStructurizrSpec Workaround to Ensure Correct Proxy Settings for Tests The docToolchain setup is based on the Gradle-Test-Kit and makes use of the Spock test execution framework . The Gradle test runner is started in its own test environment and its own JVM instance. As a result, the global proxy settings are ignored. To execute the test with the correct proxy settings, you must use a workaround. Copy the proxy settings from the gradle.properties file located in the user directory to the gradle.properties file located in the docToolchain folder itself. Note: The files downloaded by the Gradle test runner are placed in a different folder than the default Gradle cache. You will find them in the Tmp folder C:\\Users\\YOUR_USER_NAME\\AppData\\Local\\Temp\\.gradle-test-kit-YOUR_USER_NAME\\caches. "
},

{
    "id": 79,
    "uri": "025_development/010_setup_dev_env.html",
    "menu": "development",
    "title": "Setting Up a Dev Environment",
    "text": " Table of Contents Setting Up a Dev Environment Before You Begin Do a Local Install for Docker and SDKMAN! Create Gradle-Independent Tasks Create or Change a Theme Special Functionality for Themes (Config Fragments) Setting Up a Dev Environment 4 minutes to read Before You Begin When you install docToolchain, all the code is hidden. The information on this page explains how to get access to the code, so you can customise the setup in your dev environment. Do a Local Install for Docker and SDKMAN! You need a local installation of docToolchain for development. Docker and SDKMAN! are derived from it. Docker simply contains a local install, and SDKMAN! installs docToolchain locally, but the location is controlled by SDKMAN! not docToolchain. The docToolchain-Wrapper installs docToolchain locally to $HOME/.doctoolchain/docToolchain-$v2.6.7/ . All task invocations through the docToolchain-Wrapper dtcw are redirected to $HOME/.doctoolchain/docToolchain-$v2.6.7/bin/doctoolchain . This shell script calls the Gradle-Wrapper for most tasks. What you need to do is: Create a local install which is connected to your GitHub fork of docToolchain. Create a folder called $HOME/.doctoolchain/docToolchain-2.0.0-dev/ . Check out the ng-branch of your fork to this folder. To use this version in your test project, edit the version at the start of your dtcw script to 2.0.0-dev . You now have the full repo locally cloned. To save memory, some parts of the repo are zipped. If you have problems, check out the prepareDist-Task . Create Gradle-Independent Tasks All tasks currently use Gradle to run. You can bypass Gradle for tasks where it doesn’t add any value (and make docToolchain run faster as a result!). To do this, use the bin/doctoolchain scripts and create a switch. Create or Change a Theme It’s not just the docToolchain code that is hidden. The themes for the static site generator jBake are also hidden. Follow these procedures to customise themes. How to Overwrite a Project Theme When docToolchain builds a static website, it first copies an internal theme to a temp folder, then copies an external theme (if defined) over it. Finally, it copies the project theme over the top. This gives you the opportunity to overwrite some parts of the theme on a per-project basis. To do this: Run the copyThemes task to copy the internal and external themes to the microsite.siteFolder . Check the files (take a look at jbake.org to get a better understanding). Modify the relevant files and delete all the other files. How to Modify an Existing Theme or Create a Theme from Scratch As we have already mentioned, an external theme is simply a zipped copy of the 'microsite.siteFolder'. All themes are downloaded when referenced from a dtcw configuration, and are stored in $HOME/.doctoolchain/themes/[hash of url] . To modify an existing theme, go to its folder and check out the theme’s project instead of the downloaded copy. This will create a connection back to the GitHub repo so that you can modify the theme directly in $HOME/.doctoolchain/themes/[hash of url] . To create a new theme from scratch, use a simple md5 hash. For example, if you configure your new theme as \"myTheme\" then \"myTheme\".md5() will be the hash. Special Functionality for Themes (Config Fragments) It’s likely that you will need a new config item for your self-generated theme. And you can also prompt users to set a value for this new config item when they install the theme for the first time. To do this, create a file called configFragment.groovy in the site folder of your theme. For example: // the title of the microsite, displayed in the upper-left corner // Example: my new site title = '##site-title##' The first line is the message that will be shown to the user (can be over several lines). The second line (starting with Example :) is the default value for the prompt. The third line is the config item itself. If the value is surrounded by ## , the user will be prompted for this value and it will be replaced with the user’s input. Otherwise, the config item will be added without a prompt to the user’s current docToochainConfig.groovy . "
},

{
    "id": 80,
    "uri": "025_development/005_contributing_to_docs.html",
    "menu": "development",
    "title": "Contributing to Docs",
    "text": " Table of Contents Contributing to Docs Prerequisites Go to page you want to edit or fix Fork the Repository Edit the Page Commit the Changes Comparing changes Contributing to Docs 5 minutes to read The easiest way to contribute to this project is to contribute to the documentation. Here is a quick step-by-step guide on how to fix something on a documentation page. Prerequisites You need a github.com account. If you don&#8217;t have one, you can create one here: https://github.com/signup It might help if you go through the Github Hello World tutorial before you continue, but it is not necessary. Go to page you want to edit or fix You already found this tutorial, so you already know how to go to the page you want to edit or fix. All documentation can be found at http://doctoolchain.org/ . The source code of each page is available at https://github.com/doctoolchain/doctoolchain/ in the /src/docs/ folder. But there is an easier way to find the exact source. The documentation pages all look something like this: In the upper right corner you can see the Improve this doc link: This will take you directly to the source of the page, already in edit mode. If you are not logged in, GitHub will ask you to do so. The Create an issue link will be helpful if you want to report a bug or request a feature for a page. It takes you directly to the issue tracker with a pre-filled issue. For now, let&#8217;s click on the Improve this doc link. Fork the Repository If you click the link for the first time, you will be asked to fork the repository. A fork is a copy of the repository. Maybe you are used to working on the main repository or a branch within the main repository. This is not possible in this case, because you don&#8217;t have write access, only read access. The solution is to fork the repository. This way, you create a copy in your own space, and you will have write access to it. Edit the Page You will now be taken to the page you want to edit already in edit mode. What you see is asciidoctor markup. Check out the {url-asciidoc-quick-reference}[AsciiDoc quick reference] for more information. The blue box on top tells you what you already know: a copy has been created for you and you are editing it. Important since you work on your own copy of the docs, you can&#8217;t break anything. You even don&#8217;t have write access to the main repository. So feel free to edit the page as you like. Use the Preview button to see what your edits will look like. Since this is only a preview and GitHub doesn&#8217;t know about docToolchain, this preview will only show you if your AsciiDoc syntax is correct. Some other features like the TOC or include statements will not be available in the preview. Do your edit and then Commit the Changes Below the editor, there is a small Propose Changes form. Enter a headline and a description of the changes you made and click Propose changes . This will save your changes to your fork of the repository. Note Git works with diffs - it only saves the changes you made, not a full copy of the new page. This is important to know if you want to understand the inner workings of Git. After you&#8217;ve clicked the button, you will be taken to a page which shows you what you changed. Comparing changes This view lets you review your changes. These diffs are not easy to read, but I promise that over time you get used to it. Red lines are deletions, green lines are additions. As you can see in the screenshot, I added an empty space in line 17. Line 17 has been deleted (red line) and replaced with a new line (green line). Line 1 looks mysterious, because it seems that it has been replaced with an identical copy. This is because the line ending changed but is not visible in the diff. The grey box on top shows you It is quite likely that you still know what you did a minute ago, so let&#8217;s click on the Create pull request button. "
},

{
    "id": 81,
    "uri": "025_development/040_debugging.html",
    "menu": "development",
    "title": "Debugging",
    "text": " Table of Contents Debugging Environment Gradle jBake Templates Theming, Menu and Images Script Execution Debugging Debugging 2 minutes to read Things not working as you expected? Here are some tips that might help you. Environment To get the best out of docToolchain, we recommend that you set up a development environment. This way you get to see the inner workings and you also get to add extra debug output to the tasks that you want to inspect. Gradle You get more hints about what is going on with Gradle when you add the --info flag to your ./dtcw generateSite command: ./dtcw generateSite --info This outputs all config settings as seen by docToolchain along with many other internal settings. jBake Templates If something goes wrong with a template, you typically don’t receive much information about the problem. Take a look at menu.gsp to see how you can use try/catch blocks to get an error message. But to find out where the problem is occurring, you’ll need to use the poor man’s debugger and add some System.out.println statements. Make sure that you use the full System.out.println statement and not only println otherwise you won’t see any output. Theming, Menu and Images How the system creates the menu entries might seem like magic, but sometimes you cannot work out why an image is not shown. Remember, there is a way that you can check the generated files. Check the build/microsite/tmp folder to see the folder that is fed into jBake. In this folder, all files will have additional jbake attributes which are used to build the menu. They are generated from the original attributes of the file and folder/filename information. Now check the build/microsite/output folder to see the generated result. This often helps you find out where an image actually is located. Script Execution Debugging The execution of the ../../../bin/doctoolchain bash script may be traced by setting the environment variable DTC_BASH_OPTS to, e.g., -vx . "
},

{
    "id": 82,
    "uri": "025_development/030_create_new_release.html",
    "menu": "development",
    "title": "Creating a New Release",
    "text": " Table of Contents Creating a New Release Before You Begin GitHub Docker Hub Blog Post docToolchain-Wrapper (dtcw) SDKMAN! Creating a New Release 2 minutes to read Before You Begin We use semantic versioning and we also keep a changelog . All of this is done on a best-efforts basis. A release consists of five parts, each explained below. GitHub run docker run -it -e BATS_LIB_PATH=/usr/lib/bats -v \"${PWD}/dtcw:/code/dtcw\" -v \"${PWD}/test:/code/test\" maxh/bats:latest test to test dtcw Update the version in gradle.properties . Update the version in dtcw and dtcw.ps1 . dtcw.bat will be generated Update the changelog. Create a section for the version. Copy to the new section all unreleased features which will be in the release. Commit and push the new version. Draft a new release . Copy the contents of the changelog for this version to the description then submit. Set the version as v X.Y.Z. Run ./gradlew createDist to zip the source in build (the distribution file). Add the zipped file and submit the new release. Docker Hub Standard Image Update the GitHub workflows to reflect the new version. run github action to build and deploy the image do the same for the other images Blog Post Create a blog post to announce the new release. The SDKMAN! announcement will reference it. docToolchain-Wrapper (dtcw) Everything went well? Great! Now let’s update the wrapper. Navigate to https://github.com/docToolchain/doctoolchain.github.io/actions/workflows/update-dtcw.yml and trigger the action. SDKMAN! A GitHub action sdkman deploy has been created to deploy to SDKMAN! Set the version to the same as for the other releases, but without the prepended v: X.Y.Z. Use as a download link the link to the docToolchain-dist.zip from the GitHub release. Tip: the link looks like https://github.com/docToolchain/docToolchain/releases/download/v1.3.1/docToolchain-dist.zip . "
},

{
    "id": 83,
    "uri": "025_development/050_who-uses-dtc.html",
    "menu": "-",
    "title": "moved",
    "text": " document.location.href = '../10_about/10_about-the-project.html'; "
},

{
    "id": 84,
    "uri": "020_tutorial/050_multipleRepositories.html",
    "menu": "tutorial",
    "title": "Multi-Repo",
    "text": " Table of Contents How to generate docs from multiple repositories git clone solution git submodule solution artifact solution Use Antora integration How to generate docs from multiple repositories Some static site generators sell multi-repository functionality as a feature. This feature is mainly achieved through a built-in git client. Since we almost always work on systems which already have git installed, docToolchain does not come with its own git client. The solution we propose instead is just a simple bash script which does the magic for you. Here is how. Imagine you have a documentation repository set up with the docToolchain wrapper dtcw and some code documents. Now you would like to include the documents from another repository. git clone solution To get the contents of the other repository, one way is to do a git clone of it right to the build folder of your own repository. Let&#8217;s call the script in which we store this command clonerefs.sh , because we clone a reference to the remote documentation. clonerefs.sh #!/usr/bin/env bash git clone git@github.com:docToolchain/docToolchain.git build/refs/docToolchain this works fine if you execute it once, but the second time it will complain that the folder build/refs/docToolchain is not empty. So let&#8217;s create a cloneOrPull function which tries first to clone the repo and pulls an update if the clone fails. clonerefs.sh #!/usr/bin/env bash function cloneOrPull { echo \"\" echo $1 (git clone \"$1\" \"$2\" 2&gt; /dev/null &amp;&amp; echo \"cloned repo\" )|| git -C \"$2\" pull } cloneOrPull git@github.com:docToolchain/docToolchain.git build/refs/docToolchain That&#8217;s better. We can now include the docs from our main docs. To do so, we still need a little Trick. We need to reference the docs in the build folder. We could do something like include::../../../build/refs/docToolchain/somefile.adoc[] but this will break. For this, docToolchain sets the attribute projectRootDir . With this, we can write the include as include::/home/runner/work/docToolchain/docToolchain/build/refs/docToolchain/somefile.adoc[] . In order to get projectRootDir also in your local preview, create a file called .asciidoctorconfig in the root folder of your project and add :projectRootDir: {asciidoctorconfigdir} as content. But what if we don&#8217;t want to include them but just let them render? We could clone the repository directly to our src/docs folder. But that would require that it only contains docs and no src/docs folder itself. So we have to copy it over to our src/docs folder. clonerefs.sh #!/usr/bin/env bash function cloneOrPull { echo \"\" echo $1 (git clone \"$1\" \"$2\" 2&gt; /dev/null &amp;&amp; echo \"cloned repo\" )|| git -C \"$2\" pull } cloneOrPull git@github.com:docToolchain/docToolchain.git build/refs/docToolchain cp build/refs/docToolchain/src/docs/manual src/docs/. But we don&#8217;t want to add these folders to our main repository, so let&#8217;s add it to the .gitignore file. .gitignore [...] src/docs/manual [...] There is one more thing we can optimize. Currently, the script clones the repository with the full history. This is far too much traffic if you only want to use the latest version of your docs. Let&#8217;s add --depth 1 to the `git clone`command to only fetch the latest version. clonerefs.sh #!/usr/bin/env bash function cloneOrPull { echo \"\" echo $1 (git clone --depth 1 \"$1\" \"$2\" 2&gt; /dev/null &amp;&amp; echo \"cloned repo\" )|| git -C \"$2\" pull } cloneOrPull git@github.com:docToolchain/docToolchain.git build/refs/docToolchain cp build/refs/docToolchain/src/docs/manual src/docs/. This script will now let you clone remote repositories and merge them with your main documentation before building. git submodule solution Another solution is to reference your sub-repositories as git submodules . Git submodules are pointers in your main repository to a certain version of another repository. Most CI/CD systems clone your repository together with all the configured submodules. This makes this approach quite convenient. A drawback is that submodules are not often used and thus developers are not used to them. artifact solution A third solution could be that sub-repositories publish their docs as zip file somewhere. Maybe to an artifactory instance. Your main repository could fetch the published artifacts and use them in the build process. That would be exactly what you do with code. Use Antora integration The Antora integration is currently in beta and we are happy to get your feedback. If you use Antora to build your docs, docToolchain provides a special Antora integration. Essentially docToolchains task downloadTemplate is now capable to set up your project as Antora module and still leverage the various docToolchain features. This enables you to register your docToolchain project to an existing Antora playbook. The Antora integration currently supports arc42 and req42 templates out of the box. If you want to use your own template, you need to ensure the directory follows the default Antora structure. Docs are currently expected to be in ${inputPath}/modules/ROOT/ . Include content Antora comes along with some custom behaviour and non-standard asciidoc syntax. Read the following sections to learn how to include content. Images Images are expected to be within assets/images . Other files In order to include other files, e.g. generated output from docToolchain tasks like collectIncludes , you must ensure there is a symlink from the docToolchain output directory to ${inputPath}/modules/ROOT/examples/&lt;outputFile/folder&gt; . "
},

{
    "id": 85,
    "uri": "020_tutorial/030_generateHTML.html",
    "menu": "tutorial",
    "title": "generateHTML &amp; generatePDF",
    "text": " Table of Contents generateHTML &amp; generatePDF Configuration generateHTML &amp; generatePDF generateHTML and generatePDF are basic tasks which invoke Asciidoctor to generate the output you want. Linux / WSL2 with bash ./dtcw generateHTML Windows with Powershell ./dtcw.ps1 generateHTML output of generateHTML $ ./dtcw generateHTML dtcw - docToolchain wrapper V0.23 docToolchain V2.0.0 Bash is running on WSL this might cause problems with plantUML see https://doctoolchain.github.io/docToolchain/#wsl for more details Java Version 11 docker available home folder exists use local homefolder install /home/rdmueller/.doctoolchain/ Starting a Gradle Daemon, 22 busy Daemons could not be reused, use --status for details &gt; Configure project : arc42/arc42.adoc &gt; Task :generateHTML Converting /c/Users/ralfd/projects/dtc-tests/wsl/src/docs/arc42/arc42.adoc BUILD SUCCESSFUL in 26s 1 actionable task: 1 executed The output is written to build/html5/arc42/arc42.html and build/pdf/arc42/Arc42.pdf . Figure 1. generated output of generateHTML task As you can see in Figure 1 , HTML output is rendered as a single page with a table of contents (TOC) on the left. If using the withhelp version, help appears behind question mark icons on the right side of the page. When readers hold their mouse over each icon, help appears. Figure 2. generated output of generatePDF task Figure 2 shows you the PDF output. There is a TOC available on the first pages, and a TOC also appears on the left, helping readers navigate the document. Both HTML and PDF outputs can be styled to suit your needs. Configuration Files to convert For both tasks, the most important configuration is inputFiles -list at the start of your docToolchainConfig.groovy inputFiles = [ //[file: 'doctoolchain_demo.adoc', formats: ['html','pdf']], //[file: 'arc42-template.adoc', formats: ['html','pdf']], /** inputFiles **/ ] Normally, Asciidoctor converts all files it can find. For documents structured using includes, to create a full document (and avoid each chapter being converted to an individual PDF) you&#8217;ll need a main AsciiDoc file that includes all chapters. The inputFiles -map lists all of the main files as well as a list of formats applicable to each. For example, this lets you specify which files should be converted to HTML but not to PDF. You will need to configure this list manually. If docToolchain converts an unexpected list of files, this is the first place to look when troubleshooting problems. Working with the PDF style First, execute ./dtcw copyTheme to copy a simple pdfTheme to your own project. Find it in /src/docs/pdfTheme . Currently, docToolchain uses the asciidoctor-pdf library. The documentation contains a good theming guide . To activate the new style, you have to tell Asciidoctor where to find it. For maximum flexibility, specify the location and other PDF-related attributes in the file that you want to convert. The most important ones are: :pdf-themessdir: ../pdfTheme :pdf-theme: custom // only needed when you specify your own fonts :pdf-fontsdir: ../pdfTheme/fonts For this tutorial, navigate to src/docs/arc42/arc42.adoc then add the following to the top of the document: :pdf-themesdir: ../pdfTheme :pdf-theme: custom This will specify that AsciiDoc will find the pdfTheme relative to the document location in ../pdfTheme which will result in src/docs/arc42/../pdfTheme which is equal to src/docs/pdfTheme . You can also make use of the attribute {projectRootDir} which will contain the absolute path to your project directory. For example :pdf-themessdir: {projectRootDir}/src/docs/pdfTheme will search in /home/myname/projects/demo /src/docs/pdfTheme for the theme. If you want to use the {projectRootDir} in your editor preview, you must define it as a relative path: ifndef:projectRootDir[:projectRootDir: ../../..] When added to the top of your arc42.adoc tutorial file, this will set the projectRootDir to the correct folder. Working with the HTML style The easiest way to modify the HTML style is to add a pass-through block with the required CSS styles. ++++ &lt;style&gt; h2 { color: green; } &lt;/style&gt; ++++ For the generate Site task, there is a different mechanism to change the styles if the generated microsite. "
},

{
    "id": 86,
    "uri": "020_tutorial/070_publishToConfluence.html",
    "menu": "tutorial",
    "title": "publishToConfluence",
    "text": " Table of Contents Publish Your Docs to Confluence Step 1. Set Up docToolchain Step 2. Configure Publication to Confluence Step 3: Verify Your Configuration Step 4: Publish Your Pages div.center { text-align: center;} img { box-shadow: 5px 5px 5px grey;} Publish Your Docs to Confluence There are times when you&#8217;ll want to publish your docs to Confluence, such as when you work in a team where not everyone wants to work with Git. docToolchain lets you publish your Git-based docs to Confluence alongside manually edited Confluence pages. Another situation is when you want to work with the arc42 template in Confluence. There are several ways to import the template, but most of them require admin access. To get around this, you can set up a fresh copy of the arc42 template in docToolchain and publish it to your Confluence instance. In this tutorial, you&#8217;ll learn how to publish the arc42 template to a Confluence cloud instance. Step 1. Set Up docToolchain If you have completed instructions install docToolchain and get the arc42 template you can skip this part. For this tutorial, we assume that you work with a macOS/Linux-based system. In the Terminal, type the following: $ mkdir publishToConfluenceDemo $ cd publishToConfluenceDemo $ curl -Lo dtcw doctoolchain.org/dtcw Show output gitpod /workspace/publishToConfluenceDemo (main) $ curl -Lo dtcw doctoolchain.org/dtcw % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 162 100 162 0 0 1306 0 --:--:-- --:--:-- --:--:-- 1317 100 10724 100 10724 0 0 25903 0 --:--:-- --:--:-- --:--:-- 25903 Next, make the file dtcw executable. $ chmod +x dtcw If you do not have docToolchain as a Docker image, type $ ./dtcw getJava Show output ./dtcw: line 28: !false: command not found dtcw - docToolchain wrapper V0.31 docToolchain V2.0.5 docker available this script assumes that you have linux as operating system (x64 / linux) it now tries to install Java for you downloading JDK Temurin 11 from adoptiom to /home/gitpod/.doctoolchain/jdk.tar.gz WARNING: combining -O with -r or -p will mean that all downloaded content will be placed in the single file you specified. --2022-08-25 20:07:11-- https://api.adoptium.net/v3/binary/latest/11/ga/linux/x64/jdk/hotspot/normal/eclipse?project=jdk Resolving api.adoptium.net (api.adoptium.net)... 20.62.244.126 Connecting to api.adoptium.net (api.adoptium.net)|20.62.244.126|:443... connected. HTTP request sent, awaiting response... 307 Temporary Redirect Location: https://github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.16.1%2B1/OpenJDK11U-jdk_x64_linux_hotspot_11.0.16.1_1.tar.gz [following] --2022-08-25 20:07:12-- https://github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.16.1%2B1/OpenJDK11U-jdk_x64_linux_hotspot_11.0.16.1_1.tar.gz Resolving github.com (github.com)... 140.82.121.3 Connecting to github.com (github.com)|140.82.121.3|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/372924883/70b80b22-3dc5-4824-bb2d-d0158a3b9b57?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220825%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20220825T200712Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=887a715fcbd2e2d6bf24496f57b168ba2204f0f81794a66615ab53a7b153ed37&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;key_id=0&amp;repo_id=372924883&amp;response-content-disposition=attachment%3B%20filename%3DOpenJDK11U-jdk_x64_linux_hotspot_11.0.16.1_1.tar.gz&amp;response-content-type=application%2Foctet-stream [following] --2022-08-25 20:07:12-- https://objects.githubusercontent.com/github-production-release-asset-2e65be/372924883/70b80b22-3dc5-4824-bb2d-d0158a3b9b57?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220825%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20220825T200712Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=887a715fcbd2e2d6bf24496f57b168ba2204f0f81794a66615ab53a7b153ed37&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;key_id=0&amp;repo_id=372924883&amp;response-content-disposition=attachment%3B%20filename%3DOpenJDK11U-jdk_x64_linux_hotspot_11.0.16.1_1.tar.gz&amp;response-content-type=application%2Foctet-stream Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ... Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 193754645 (185M) [application/octet-stream] Saving to: ‘/home/gitpod/.doctoolchain/jdk/jdk.tar.gz’ /home/gitpod/.doctoolchain/jdk 100%[====================================================&gt;] 184.78M 310MB/s in 0.6s 2022-08-25 20:07:13 (310 MB/s) - ‘/home/gitpod/.doctoolchain/jdk/jdk.tar.gz’ saved [193754645/193754645] FINISHED --2022-08-25 20:07:13-- Total wall clock time: 1.7s Downloaded: 1 files, 185M in 0.6s (310 MB/s) expanding JDK Answer the questions that appear during installation. You will see lots of .jar files getting downloaded. Initialise docToolchain by running your first task. $ ./dtcw tasks Show output dtcw - docToolchain wrapper V0.31 docToolchain V2.0.5 local java JDK found use /home/gitpod/.doctoolchain/jdk as JDK docker available force use of local install docToolchain not installed. sdkman not found Do you wish to install doctoolchain to /home/gitpod/.doctoolchain? 1) Yes 2) No #? 1 installing doctoolchain mkdir: cannot create directory ‘/home/gitpod/.doctoolchain’: File exists % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 100 1783k 100 1783k 0 0 2857k 0 --:--:-- --:--:-- --:--:-- 2857k Archive: /home/gitpod/.doctoolchain/source.zip creating: /home/gitpod/.doctoolchain/./docToolchain-2.0.5/ creating: /home/gitpod/.doctoolchain/./docToolchain-2.0.5/bin/ inflating: /home/gitpod/.doctoolchain/./docToolchain-2.0.5/bin/autobuildSite.bash inflating: /home/gitpod/.doctoolchain/./docToolchain-2.0.5/bin/doctoolchain [152 lines omitted] inflating: /home/gitpod/.doctoolchain/./docToolchain-2.0.5/template_config/pdfTheme/custom-theme.yml creating: /home/gitpod/.doctoolchain/./docToolchain-2.0.5/resources/ creating: /home/gitpod/.doctoolchain/./docToolchain-2.0.5/resources/asciidoctor-reveal.js/ creating: /home/gitpod/.doctoolchain/./docToolchain-2.0.5/resources/reveal.js/ Picked up JAVA_TOOL_OPTIONS: -Xmx3489m Downloading https://services.gradle.org/distributions/gradle-6.9.2-bin.zip ..........10%..........20%..........30%...........40%..........50%..........60%..........70%...........80%..........90%..........100% Welcome to Gradle 6.9.2! Here are the highlights of this release: - This is a small backport release. - Java 16 can be used to compile when used with Java toolchains - Dynamic versions can be used within plugin declarations - Native support for Apple Silicon processors For more details see https://docs.gradle.org/6.9.2/release-notes.html To honour the JVM settings for this build a single-use Daemon process will be forked. See https://docs.gradle.org/6.9.2/userguide/gradle_daemon.html#sec:disabling_the_daemon. Daemon will be stopped at the end of the build &gt; Configure project : Config file '/workspace/publishToConfluenceDemo/docToolchainConfig.groovy' does not exist' [ant:input] [ant:input] do you want me to create a default one for you? (y, n) &lt;&lt;-------------&gt; 0% CONFIGURING [2m 55s] &gt; Task :help Welcome to Gradle 6.9.2. To run a build, run gradlew &lt;task&gt; ... To see a list of available tasks, run gradlew tasks To see a list of command-line options, run gradlew --help To see more detail about a task, run gradlew help --task &lt;task&gt; For troubleshooting, visit https://help.gradle.org BUILD SUCCESSFUL in 3m 29s 1 actionable task: 1 executed Next download the arc42 template $ ./dtcw downloadTemplate Show output dtcw - docToolchain wrapper V0.31 docToolchain V2.0.5 local java JDK found use /home/gitpod/.doctoolchain/jdk as JDK docker available home folder exists use local homefolder install /home/gitpod/.doctoolchain/ Picked up JAVA_TOOL_OPTIONS: -Xmx3489m To honour the JVM settings for this build a single-use Daemon process will be forked. See https://docs.gradle.org/6.9.2/userguide/gradle_daemon.html#sec:disabling_the_daemon. Daemon will be stopped at the end of the build &gt; Task :downloadTemplate Install arc42 documentation template. For more information about arc42 see https://arc42.org [ant:input] Which language do you want to install? (EN, DE, ES, RU) &lt;-&lt;-------------&gt; 0% EXECUTING [11s] [ant:input] Do you want the template with or without help? (withhelp, plain) &lt;-&lt;&lt;-&lt;--&lt;-------------&gt; 0% EXECUTING [17s] Download https://github.com/arc42/arc42-template/raw/master/dist/arc42-template-EN-withhelp-asciidoc.zip arc42 template unpacked into /workspace/publishToConfluenceDemo/src/docs/arc42 added template to docToolchainConfig.groovy use 'generateHTML', 'generatePDF' or 'generateSite' to convert the template BUILD SUCCESSFUL in 22s 1 actionable task: 1 executed You should now have the following folder structure in your project: Project Folder Structure . ├── docToolchainConfig.groovy ├── dtcw └── src └── docs ├── arc42 │ ├── arc42.adoc │ └── chapters │ ├── 01_introduction_and_goals.adoc │ ├── 02_architecture_constraints.adoc │ ├── 03_system_scope_and_context.adoc │ ├── 04_solution_strategy.adoc │ ├── 05_building_block_view.adoc │ ├── 06_runtime_view.adoc │ ├── 07_deployment_view.adoc │ ├── 08_concepts.adoc │ ├── 09_architecture_decisions.adoc │ ├── 10_quality_requirements.adoc │ ├── 11_technical_risks.adoc │ ├── 12_glossary.adoc │ ├── about-arc42.adoc │ └── config.adoc └── images ├── 01_2_iso-25010-topics-EN.png ├── 05_building_blocks-EN.png ├── 08-Crosscutting-Concepts-Structure-EN.png └── arc42-logo.png 5 directories, 21 files Step 2. Configure Publication to Confluence To configure authentication through the Confluence API, do the following. In the root of your project foler, open the file docToolchainConfig.groovy . Find the text confluence.with . This is the start of the section where you configure publication to Confluence. As you can see, docToolchain is preconfigured to publish sample input (the arc42 template) to Confluence. The input for the publishToConfluence task is the output of the generateHTML task. You should see this: input = [ [ file: \"build/html5/arc42/arc42.html\" ], ] This corresponds to the following snippet from the start of the file inputFiles = [ //[file: 'doctoolchain_demo.adoc', formats: ['html','pdf']], [file: 'arc42-template.adoc', formats: ['html','pdf']], /** inputFiles **/ ] the inputFiles section tells the generateHTML command to render the file as HTML, the confluence.input section tells the publishToConfluence command which file to publish. Set up the API endpoint. Get your Atlassian Confluence URL, such as https://arc42-template.atlassian.net . Endpoint Syntax api = 'https://[yourServer]/[context]' In this case, the correct endpoint is https://arc42-template.atlassian.net/wiki . The context is optional, unless it is something other that \"wiki\". If you would like to enforce a URL that has no context (only valid if you specified useV1Api = true ) for Confluence Server you should specify the full API URL, like https://confluence.example.com/rest/api . In docToolchainConfig.groovy , add the space-key, such as 8FE . spaceKey = '8FE' Step 2.1. Configure Confluence Authentication Step 2.1a. CLI Authentication with username and password (insecure) This method is not recommended. Instead of passing your password, you can use a Personal Access Token, which can easily be revoked on the event of a compromise. See Authentication with Personal Access Token . In the Terminal, type the following: $ ./dtcw publishToConfluence -PconfluenceUser=&lt;your username&gt; -PconfluencePass=&lt;your password&gt; Step 2.1b: CLI Authentication with username and API token This method only works for Confluence Cloud. I can use an API token. The key has to be generated from the central Atlassian account. Navigate to your central Atlassian profile. Go to Manage your Account . Click Security &gt; API token &gt; Create and manage API tokens . Here is the shortcut to this page. Now, click Create API token . Store your API token in a safe location. Add your API token e-mail address as username and password to the ./dtcw command. $ ./dtcw publishToConfluence -PconfluenceUser=&lt;your email&gt; -PconfluencePass=&lt;your api-token&gt; Step 2.1c: CLI Authentication with Personal Access Token If you do not want to pass your password and you are not an admin of your Confluence instance, you can use a Personal Access Token (PAT). Follow the Confluence documentation to generate one. In the Terminal, type the following to publish to Confluence with your PAT: $ ./dtcw publishToConfluence -PconfluenceBearerToken=&lt;your personal access token&gt; Step 3: Verify Your Configuration To verify your configuration execute ./dtcw verifyConfluenceApiAccess and pass the credentials to the task, depending on the setup you chose in the steps before. An example would be $ ./dtcw verifyConfluenceApiAccess -PconfluenceUser=&lt;your email&gt; -PconfluencePass=&lt;your api-token&gt; If the API is accessible, the task will succeed and print the API version that is used. Otherwise, an error will be printed. ... Daemon will be stopped at the end of the build &gt; Task :verifyConfluenceApiAccess Using Confluence API V1 BUILD SUCCESSFUL in 15s 3 actionable tasks: 3 executed Step 4: Publish Your Pages To publish your pages to Confluence, type: $ ./dtcw publishToConfluence &lt;extra arguments&gt; Show output dtcw - docToolchain wrapper V0.31 docToolchain V2.0.5 local java JDK found use /home/gitpod/.doctoolchain/jdk as JDK docker available home folder exists use local homefolder install /home/gitpod/.doctoolchain/ Picked up JAVA_TOOL_OPTIONS: -Xmx3489m To honour the JVM settings for this build a single-use Daemon process will be forked. See https://docs.gradle.org/6.9.2/userguide/gradle_daemon.html#sec:disabling_the_daemon. Daemon will be stopped at the end of the build &gt; Task :publishToConfluence publish /workspace/publishToConfluenceDemo/build/html5/arc42/arc42.html arc42 Start getting headers &gt; created page 2033844225 1. Introduction and Goals Start getting headers image: ../images/01_2_iso-25010-topics-EN.png allPages already retrieved &gt; created page 2033909761 Start getting headers 2. Architecture Constraints Start getting headers allPages already retrieved &gt; created page 2033975297 3. System Scope and Context Start getting headers allPages already retrieved &gt; created page 2034008065 4. Solution Strategy Start getting headers allPages already retrieved &gt; created page 2034040833 5. Building Block View Start getting headers image: ../images/05_building_blocks-EN.png allPages already retrieved &gt; created page 2034073601 Start getting headers 6. Runtime View Start getting headers allPages already retrieved &gt; created page 2034139137 7. Deployment View Start getting headers allPages already retrieved &gt; created page 2034106374 8. Cross-cutting Concepts Start getting headers image: ../images/08-Crosscutting-Concepts-Structure-EN.png allPages already retrieved &gt; created page 2034139152 Start getting headers 9. Architecture Decisions Start getting headers allPages already retrieved &gt; created page 2034040848 10. Quality Requirements Start getting headers This command will first run the task generateHTML and then create one Confluence page for each arc42-chapter. "
},

{
    "id": 87,
    "uri": "020_tutorial/990_Tutorial.html",
    "menu": "tutorial",
    "title": "How to create a Tutorial",
    "text": " Table of Contents How to create a Tutorial Prepare your Tutorial Preview your work Submit your Pull-Request How to create a Tutorial Since docToolchain is a community project, it also lives from the content created by the community. This little tutorial will explain how you&#8201;&#8212;&#8201;as a member of the community&#8201;&#8212;&#8201;can create your own tutorial. Prerequisites: you know how to use Git ( https://www.gitbook.com/ ), how to fork and create a pull request on github and how to write in AsciiDoc. The docToolchain website is build with docToolchain itself. So, the code of docToolchain and the documentation reside both in the same repository. (The way as it should be with the docs-as-code approach!) Navigate to https://github.com/docToolchain/docToolchain/tree/ng/src/docs/020_tutorial to find the source of the already existing tutorials. As you can see, the files are numbered in steps of 10. The numbers are the order of appearance within the left navigation. They can be overwritten by a :jbake-order: x -statement within the .adoc file. The order is specified in steps of 10 just to be able to insert files in between if necessary. Prepare your Tutorial To create a new Tutorial, fork the project and create a new file in the folder src/docs with an appropriate name and number. Add the following content to your file: :jbake-title: Your Navigation-Entry :source-highlighter: highlightjs :highlightjs-theme: monokai-sublime :imagesdir: images :icons: font == Your Headline The :jbake-title: Your Navigation-Entry tell jBake (the renderer used by docToolchain) the text for the navigation link in left navigation pane. If this is missing, it will use the first Headline in your document. If this is also missing, it will use the filename. You might wonder why you should specify the title if you already have named your tutorial via the first headline. The headline is often quite long and :jbake-title: gives you the opportunity to shorten it for the navigation pane. The include:: -statement mainly sets the location of the imagesdir so that you don&#8217;t have to worry about it. Take a look at the file to see what else it does! Your first headline should always start with == and not = , sind a single = is the document name like a book title. docToolchain expects for the chapters of the documentation headline level == as starting headline. That&#8217;s it. Now you can start to write your tutorial. Preview your work To edit your file, use an editor which gives you a preview of your .adoc file like IntelliJ or VS Code. This already gives you a good preview of the structure and formatting of your document. Want to see how it looks on a web page? There are two ways to render the full page. One create a pull request (PR) and mark it as draft. As soon as the PR is submitted, netlify will start to render a preview. You will see some tasks running on the PR-page and the last one will give you a link to the preview-site. Two you can render the page locally through docToolchain. Execute ./dtcw generateSite locally and you will find the result in build/microsite/output/index.html Submit your Pull-Request As soon as you think your tutorial is ready for production, remove the draft status from your PR and we will start a short review process. As soon as we are through with the review, we will merge the PR and your tutorial will be live. Any questions? Feel free to open a new Discussion ! "
},

{
    "id": 88,
    "uri": "020_tutorial/150_multiRepoMicrositeTipsAndTricks.html",
    "menu": "tutorial",
    "title": "Building a microsite from multiple repositories",
    "text": " Table of Contents Multiple Repositories Backlinks to the repositories Multiple Repositories Modern software development teams maintain several git repositories. If they commit to having documentation close to the code, they will inevitably have documentation spread over several repositories. DocToolchain supports building documentation such as a microsite from several repositories precisely by not supporting it in any particular way. You can just checkout all repositories you need, and extract and arrange the content of their docs folders as you need before you build the documentation. Backlinks to the repositories DocToolchain offers two helpful links in the top right corner of every page: Improve this doc Opens a new tab to directly edit the respective page on e.g. GitHub Create an issue Lets you create a new issue in a defined git repository. The URLs for both activities can be specified in docToolchainConfig.groovy , in the fields issueUrl and gitRepoUrl . However, if you build your documentation from several repos, you&#8217;ll want to link to different repos. A simple fix is to do a postprocessing step with sed and replace the default URLs with the correct ones. If your way of arranging the documentation folders from the different repos is simple enough, you can simply run sed with a different URL on each of the different generated folders. If your arrangement is more complicated, e.g. because you merge all repos ADRs into one folder, you can do a preprocessing step in advance. In each repo, automatically set the :filename: tag and prefix the value with a unique identifier for the repository. Move your adoc files to the desired target folders. run generateSite In the generated HTML files, replace the repository in the backlinks. By including the prefix in your query, you can make sure to target the correct repository. "
},

{
    "id": 89,
    "uri": "020_tutorial/140_Dropdown_Menu.html",
    "menu": "tutorial",
    "title": "How to create a Dropdown Menu",
    "text": " Table of Contents How to set up a Dropdown Menu for a Microsite Folder Structure Markers Menu Generation Caveats How to set up a Dropdown Menu for a Microsite If you don&#8217;t need to understand what&#8217;s going on, there is a shortcut: Just look at the commits in this PR ( preview ) The microsite generated by docToolchain groups your documentation along two axes: the top menu and the left sidebar. The top menu lists several menu items that each correspond to a different asciidoc page . And each page comprises several chapters that you can navigate in the left sidebar. If you want to group several pages you need an intermediary axis. This axis can be realized with a dropdown menu. There is no syntax within docToolchain to create a dropdown and assign (several) pages to menu items, but we can tweak the html generation to create a dropdown for us. The result will look like this: In the following we will use this terminology: menu item Entries (or their String values) on the blue top menu bar (e.g. 'backend') dropdown item Entries in a dropdown list, e.g. 'business', 'arc42', 'how-to' in the picture above Folder Structure The folders are arranged as usual: one folder per page. We use prefixes (e.g. general_ ) to group pages that should end up in the same dropdown, but this is not technically required, it just helps us to stay on top of things. . ├── docToolchainConfig.groovy ├── dtcw └── src └── docs ├── general_arc42 │ ├── page1.adoc │ ... ├── general_business ├── general_how_to ├── backend_arc42 ├── backend_business ├── backend_how_to ... Markers By default, the menu field in docToolchainConfig.groovy maps folder names to item names. It also implicitly encodes the order in which menu items are displayed the actual value that is displayed in the top menu Here, it will additionally encode the menu entry a page belongs to the order of a page within a dropdown In order to accomplish that, we&#8217;ll put both the menu item and the dropdown item in every right side value. The format for that is \"&lt;menu item name&gt;: &lt;dropdown item name&gt;\" . If a value does not contain \": \" it will be interpreted as a regular menu item linked to one page. This means that your menu (or dropdown) items cannot contain \": \" in their name. If you need \": \" as part of the menu or dropdown item, you can use a different separator. Look at the following example. The first three entries will create a menu item \"general\" with three dropdown items \"arc42\", \"business\" and \"how-to\" (in that order). The last entry \"blog\" will create a regular menu item with no dropdown. menu = [ general_arc42: 'general: arc42', general_business: 'general: business', general_how_to: 'general: how-to', backend_arc42: 'backend: arc42', backend_business: 'backend: business', backend_how_to: 'backend: how-to', // ... blog: 'blog' ] Menu Generation To make docToolchain create the dropdown for us, we need to apply some changes to the default theme. So, if not done already, we need to download the site folder with dtcw copyThemes . default menu generation &lt;% content.newEntries.each { entry -&gt; %&gt; &lt;li class=\"nav-item mr-4 mb-2 mb-lg-0\"&gt; &lt;a class=\"nav-link ${entry.isActive}\" href=\"${entry.href}\"&gt;&lt;span&gt;${entry.title}&lt;/span&gt;&lt;/a&gt; &lt;/li&gt; &lt;% } %&gt; In the example above &lt;% &#8230;&#8203; %&gt; are used to embed groovy code into pages that are otherwise html. Here a for-each loop is embedded to generate a list item element for every element in content.newEntries . The content.newEntries field has the information from the menu field where earlier we added the information about which menu item each page should go under. Now we need to extract the information about which dropdowns there are and which pages go where. First, we&#8217;ll add some imports that we&#8217;ll need later. import static java.util.stream.Collectors.groupingBy import static java.util.stream.Collectors.mapping import static java.util.stream.Collectors.toList Then, we&#8217;ll assert that our assumption still holds: content.newEntries is an ArrayList of LinkedHashMap s. assert content.newEntries instanceof java.util.ArrayList assert (content.newEntries.size() == 0) || content.newEntries[0] instanceof java.util.LinkedHashMap After verifying the type of the input, let&#8217;s transform it to a class that we define, Item . Having their definition in view will make it easier to work with them later on. We&#8217;ll also define a transformation from a LinkedHashMap to our Item that drops the menu item from combined titles where we had added them before. //a custom class for dropdown items class Item { boolean isActive String href String title Item(isActive, href, title) { this.isActive = isActive this.href = href this.title = title } }; //Transform a LinkedHashMap to an Item. //if the title is a combination of menu item and dropdown item, drop the menu item. def transform(e) { var title = e.title.contains(\": \") ? e.title.split(\": \")[1] : e.title new Item(e.isActive, e.href, title) } There are some newer groovy (server pages) features around like &lt;g:each &#8230;&#8203;&gt; elements and records . I could not make them work [ 1 ] and ended up using the old concepts. If you find a way to apply them feel free to verify it by building on this PR and update this tutorial! In order to group pages by menu item, we need to define a key function. The key function should always return the menu item. So, from a combined title, just the menu item should be returned and the dropdown item be dropped. And from a regular item the whole title should be returned. But we still want to preserve the information about whether to create a dropdown. Thus, we add a marker prefix in front of the key for dropdown items. (Instead of the marker prefix we could also just interpret map entries where the value is a one element list as not-a-dropdown. But then we couldn&#8217;t support dropdowns with exactly one element and somebody might want that.) MARKER_DROPDOWN = \"dropdownmenuitem_\" //get the menu item from a combined title. If there is no separator get the full title. def getMenuItem(e) { e.title.contains(\": \") ? MARKER_DROPDOWN + e.title.split(\": \")[0] : e.title } Now we can group the pages to a map where the key is the menu item (plus an indicator prefix iff // == \"if and only if\" a dropdown should be created) and the value is a list of Items . var LinkedHashMap&lt;String, List&lt;Item&gt;&gt; itemGroups itemGroups = content.newEntries.stream() .collect( groupingBy( this::getMenuItem, LinkedHashMap::new, mapping(this::transform, toList()) ) ) After enriching the original content.newEntries map with dropdown information and making that information accessible, we can now generate the menu from it. So we&#8217;ll add an if to the existing for-each loop, that distinguishes between regular menu items and those with a dropdown. For a dropdown, we place a button (so one can click on it and have the dropdown items displayed) and a div with all the dropdown items. For a regular menu item, everything stays the same. itemGroups.each { key, val -&gt; if (key.startsWith(MARKER_DROPDOWN)) { //dropdown %&gt; &lt;li class=\"nav-item mr-4 mb-2 mb-lg-0\"&gt; &lt;div class=\"dropdown\"&gt; &lt;button class=\"dropbtn\"&gt;&lt;span&gt;${key.minus(MARKER_DROPDOWN)}&lt;/span&gt;&lt;/button&gt; &lt;div class=\"dropdown-content\"&gt; &lt;% val.each { item -&gt; %&gt; &lt;a href=\"${item.href}\"&gt;${item.title}&lt;/a&gt; &lt;% } %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/li&gt; &lt;% } else { //there is no dropdown, take the only element entry = val.get(0) %&gt; &lt;li class=\"nav-item mr-4 mb-2 mb-lg-0\"&gt; &lt;a class=\"nav-link ${entry.isActive}\" href=\"${entry.href}\"&gt;&lt;span&gt;${entry.title}&lt;/span&gt;&lt;/a&gt; &lt;/li&gt; &lt;% } } %&gt; Now we have all the structural information, and if we generate a microsite now, we can see all the dropdown items. But, we only want to see them on a mouse over, so we&#8217;ll have to add some CSS as well. For that we&#8217;ll just add another style element to header.gsp . For basic functionality, we just need to set display to none unless there is a mouseover. &lt;!-- dropdown menu --&gt; &lt;style&gt; /* Dropdown Content (Hidden by Default) */ .dropdown-content { display: none; position: absolute; background-color: #f1f1f1; min-width: 160px; box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2); z-index: 1; } /* Show the dropdown menu on hover */ .dropdown:hover .dropdown-content {display: block;} Now all that&#8217;s left is some styling to seamlessly integrate the dropdown to the rest of the page. /* The container &lt;div&gt; - needed to position the dropdown content */ .dropdown { position: relative; display: inline-block; } /* Dropdown Button */ .dropbtn { background-color: #30638E; color: white; padding: 10px; font-size: 16px; border: none; } /* Links inside the dropdown */ .dropdown-content a { color: black; padding: 12px 16px; text-decoration: none; display: block; } /* analogous to the `.td-navbar .nav-link` block*/ .td-navbar .dropbtn { text-transform:none; font-weight:700; } /* Change color of dropdown links on hover */ .dropdown-content a:hover {background-color: #ddd;} /* Change the background color of the dropdown button when the dropdown content is shown */ .dropdown:hover .dropbtn {background-color: #5579ae;} &lt;/style&gt; With that, we have added a dropdown to the top menu and didn&#8217;t have to add any new features to docToolchain. Caveats The fact that there is no structural support [ 2 ] for dropdowns in docToolchain is noticeable in some places. The folder structure (in docs ) is flat, folders of dropdown and menu items are on the same level. The URLs in turn are not as one might expect &#8230;&#8203;/menu_item/dropdown_item/page but &#8230;&#8203;/menu_item_dropdown_item/page . For regular pages the top entry in the left sidebar is the name of the menu item, but for pages of dropdowns the top entry on the left is the value specified in menu.gsp in the field menu : &lt;menu item&gt;: &lt;dropdown item&gt; . (This behaviour can in all likelihood be changed by adding a command in the right .gsp file) These points are probably not an issue for most people, but for transparency they are listed here. 1 . 1) &lt;g:xy&gt; elements are not recognized, I guess the 'g' namespace isn&#8217;t. 2a) record Point(int x, int y, String color) { } gives Unexpected input: '(' 2b) @RecordType class gives SimpleTemplateScript &#8230;&#8203; unable to resolve annotation RecordType 2 . we are basically telling docToolchain to treat some menu items, which we labeled as dropdown items, differently from the rest. "
},

{
    "id": 90,
    "uri": "020_tutorial/120_self-contained-dtc.html",
    "menu": "tutorial",
    "title": "Self-Contained docToolchain",
    "text": " Table of Contents Self-Contained docToolchain Docker Solution Local Solution Self-Contained docToolchain When you work in a restricted environment where you don&#8217;t have direct access to the internet, you might need a self-contained version of docToolchain. A version which does not need to download dependencies but already has them on board. Docker Solution If you have docker available, then this might already be the solution. The docker image already contains all dependencies and the docToolchain wrapper ( dtcw ) already checks if docker is available and running and thus will use docker in this case. In order to fetch the docker image from your local docker proxy, please check the source of dtcw and update the docker image reference . Local Solution If you don&#8217;t have Docker available, you need a local, self-contained install. Download wrapper Start on an unrestricted system and download the docToolchain wrapper: mkdir dtc-self-contained cd dtc-self-contained curl -Lo dtcw doctoolchain.org/dtcw chmod +x dtcw Check and install correct Java Development Kit (JDK) We start with ensuring that we have the correct Java Development Kit (JDK) installed. Execute ./dtcw local install java to fetch and install the correct JDK. It will be installed to $HOME/.doctoolchain/jdk . Start first tasks to install docToolchain locally Now, let&#8217;s start a simple task to download and install docToolchain locally: ./dtcw local tasks local will ensure that docker is ignored, even when docker is up and running. tasks is a simple task which just shows all available tasks. When you run this command, docToolchain will ask if it is allowed to install itself to $HOME/.doctoolchain and if it should create a simple config file. It will also fetch some first dependencies in order to execute the task. These dependencies will be downloaded to $HOME/.doctoolchain/.gradle . Fetch remaining dependencies To fetch the remaining dependencies, execute ./dtcw downloadDependencies this will fetch the remaining dependencies and download them to $HOME/.doctoolchain/.gradle Get an offline gradle binary The last needed step is to download an offline version of gradle for docToolchain to use. This was inspired by https://chengl.com/gradle-offline-build/ . Steps download a gradle binary-zip from https://services.gradle.org/distributions/ place it in the folder .doctoolchain/docToolchain-$VERSION/gradle/wrapper (replace $VERSION with current docToolchain version that you installed) go to folder .doctoolchain/docToolchain-$VERSION/gradle/wrapper and open the file gradle-wrapper.properties change the distributionUrl to distributionUrl=gradle-$GRADLEVERSION-bin.zip (replace $GRADLEVERSION with the version of the binary-zip you just downloaded) docToolchain now uses an offline version of Gradle. Finalize As a result, we now have docToolchain, a JDK, gradle and all dependencies installed to $HOME/.doctoolchain . You can now zip this folder and copy it to your restricted environment to the $HOME/.doctoolchain folder. The wrapper of your project will recognize it as local installation and use it. the installed JDK is for one specific PU architecture. So, if your team works with different Systems (Windows, Mac, Linux), you have to create several versions. "
},

{
    "id": 91,
    "uri": "020_tutorial/110_presentations_with_revealjs.html",
    "menu": "tutorial",
    "title": "Presentations with reveal.js",
    "text": " Table of Contents Presentations with reveal.js Precondition Create the Slide Deck Repository Create a minimal AsciiDoctor Reveal.js Presentation References Presentations with reveal.js reveal.js is an open source HTML presentation framework. It&#8217;s a tool that enables anyone with a web browser to create fully-featured and beautiful presentations for free. Instead of creating your reveal.js presentations in HTML markup (or markdown) you may prefer to use AsciiDoc instead. docToolchain uses Asciidoctor reveal.js to transform your AsciiDoc document into an HTML5 presentation designed to be executed by the reveal.js presentation framework. This tutorial shows how easy it is to create a reveal.js slide deck with docToolchain . It was written for a Bash environment (Linux or macOS). The adoption to MS Powershell should be trivial. Precondition To follow the tutorial you either need to have docToolchain installed locally or a running docker environment. In the later case the first call to docToolchain will pull the container image which may take some time. Create the Slide Deck Repository Create a project directory $ mkdir my-presentation $ cd my-presentation Download the docToolchain wrapper and set the executable permissions $ curl -sLo dtcw doctoolchain.github.io/dtc $ chmod +x dtcw Initialize the git repository with the minimal files $ git init # Ignore generated files in your git repository $ echo \".gradle\" &gt; .gitignore $ echo \"build\" &gt;&gt; .gitignore $ git add .gitignore $ git commit -m \"Initial commit for my reveal.js slide deck\" Create a minimal AsciiDoctor Reveal.js Presentation Create a presentation.adoc file with an image $ mkdir -p src/images $ cat &lt;&lt; EOF &gt;&gt; src/presentation.adoc = Title Slide == Slide 1 * This is the first slide == Slide 2 * This is the second slide == Slide with Image * The Debian Logo image::debian.svg[] EOF $ curl -Lo src/images/debian-logo.svg https://www.debian.org/logos/openlogo.svg Create the docToolchain configuration file docToolchainConfig.groovy $ cat &lt;&lt; EOF &gt;&gt; docToolchainConfig.groovy // Path where docToolchain creates its artifacts. outputPath = 'build' // Path where the docToolchain will search for the input files. inputPath = 'src'; // Define which formats should be processed. inputFiles = [ [file: 'presentation.adoc', formats: ['revealjs']], ] EOF As an alternative we could create the configuration by invoking ./dtcw tasks . If docToolchain doesn&#8217;t find a configuration file it will ask to create a new one. The generated configuration file contains the configuration for all tasks provided by docToolchain , which may be overwhelming. Generate the slide deck $ ./dtcw generateDeck Find your slide deck at build/decks/presentation.html and open it in your browser. Add the newly created files to you git project $ git add docToolchainConfig.groovy src $ git commit -m \"Add my first reveal.js slide deck\" Congratulations on creating your first reveal.js slide deck. References docToolchain Asciidoctor reveal.js AsciiDoc reveal.js "
},

{
    "id": 92,
    "uri": "020_tutorial/010_Install.html",
    "menu": "tutorial",
    "title": "Install docToolchain",
    "text": " Table of Contents Welcome! Install docToolchain Installation Overview Install dtcw in your project directory Run docToolchain in a container Install docToolchain with dtcw Install docToolchain with SDKMAN! Run your First Command Problems &amp; solutions Welcome! Nice to meet you. Glad that you want to learn more about using docToolchain. Start by installing what you need. The following steps are the same as described in the User Docs. Please follow them step by step. You are prompted to install everything you need for each step. If you encounter problems, create a GitHub issue and the community will help you. Install docToolchain 11 minutes to read Installation Overview docToolchain is composed of two parts: doctoolchain which is the toolchain used to create your documentation the docToolchain shell wrapper script installed in your project which calls the toolchain The use of this setup has the following advantages: It&#8217;s easy to build your documentation within your project folder. Ensures that everyone in the project uses the same docToolchain version. Keeps all docToolchain technology out of your project repository. Facilitates the installation of the docToolchain if not installed. Makes it easier to upgrade to newer versions of docToolchain. Install dtcw in your project directory The docToolchain wrapper script dtcw , respective dtcw.ps1 or dtcw.bat for MS Windows, is meant to be installed in your project root directory. The wrapper script simplifies calls to the docToolchain. Even if you are going to use docToolchain in multiple projects, the toolchain will only be installed once on your system. Steps for MacOS/Linux/WSL2 with bash If you have an Apple Silicon (M1/M2) Mac, make sure that you have docker up and running and type the following commands in the Terminal: `arch -x86_64 /bin/bash` Now, download dtcw into your project directory and make the script executable with the following commands: cd &lt;your project&gt; curl -Lo dtcw https://doctoolchain.org/dtcw chmod +x dtcw If you don&#8217;t have curl installed, you can also use wget : cd &lt;your project&gt; wget doctoolchain.org/dtcw chmod +x dtcw Windows with Powershell cd &lt;your project&gt; Invoke-WebRequest doctoolchain.org/dtcw.ps1 -Outfile dtcw.ps1 Got an error message that you are not allowed to execute powershell scripts? Try to switch to an unrestricted powershell by executing powershell.exe -ExecutionPolicy Unrestricted . Windows with cmd.exe cd &lt;your project&gt; curl -Lo dtcw.bat doctoolchain.org/dtcw.bat dtcw.bat wraps the dtcw.ps1 script and executes it in powershell. This might be easier to use if you haven&#8217;t yet configured your powershell as a developer. In case your development team uses different operating systems, put the wrapper scripts for the desired operating systems ( dtcw , dtcw.ps1 , and dtcw.bat ) into your project. Once the docToolchain wrapper is installed in your project directory you have to decide how to install the toolchain: Run docToolchain in a container with the docToolchain container image or Use your custom docker image . Install docToolchain with dtcw in the users home directory $HOME/.doctoolchain Install docToolchain with SDKMAN! a tool for managing parallel versions of multiple Software Development Kits. docToolchain depends on Java 11 (Java 11, 14, and 17 are also supported) If you don&#8217;t use the docToolchain container image you have to install Java on your system. In case you have Java already installed, make sure JAVA_HOME is set. You may use dtcw to install the correct Java version, as shown in the next steps. Run docToolchain in a container The docToolchain project provides a container image of approximately 900 MB from the Docker Hub container registry. The Dockerfile from which the image is created may be found at https://github.com/docToolchain/docker-image . To run docToolchain in a container you need an installed container engine. The best known container engine is Docker . If the container engine is installed you can Run your First Command . The docToolchain wrapper script in your project directory will detect the container engine and pull the docToolchain image on the first invocation. Use your custom docker image Some might need to create their own docker image to add additional tooling or configurations, e.g. proxy settings. In this case you can pass the image name via parameter image directly after docker : ./dtcw docker image &lt;image_name&gt; generateHTML .\\dtcw.ps1 docker image &lt;image_name&gt; generateHTML .\\dtcw.bat docker image &lt;image_name&gt; generateHTML Pass environment variables to docker containers To pass any environment variable to the docker container you can make use of an environment file . The environment file must have the name dtcw_docker.env and must be located in the same folder as dtcw . An example content is e.g.: # set environment variables for docToolchain docker container PROJECT=TEST_PROJECT TEAM=TEST_TEAM Pass additional parameter to docker containers To pass additional parameters to the docker container you can make use of the parameter extra_arguments followed by a string with the additional parameters. One usecase is to enable you to set environment variables to dynamic values. ./dtcw docker image &lt;image_name&gt; extra_arguments \"--env USER=${USERNAME} --env REPO_LOCATION=`git config remote.origin.url`\" generateHTML Install docToolchain with dtcw Steps for MacOS/Linux/WSL2 with bash To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw install doctoolchain In case you have no Java installed you may use dtcw to install Java in a subdirectory of $HOME/.doctoolchain . ./dtcw install java Unable to locate Java Runtime - check your Bash environment If dtcw complains about not being able to locate a Java Runtime, make sure Java is found in your Bash shell, the shell used by dtcw . If you use dtcw from another shell like zsh , it may be that your shell finds the supported Java version but your bash setup doesn&#8217;t. In that case, please switch to bash and make sure that a supported Java version is found. Afterwards, you can switch back to your shell. Windows with Powershell To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw.ps1 install doctoolchain In case you have no Java installed you can use dtcw.ps1 to install Java: .\\dtcw.ps1 install java Windows with cmd.exe To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw.bat install doctoolchain In case you have no Java installed you can use dtcw.ps1 to install Java: .\\dtcw.bat install java If the docToolchain installation finished successfully, you are ready to Run your First Command . Install docToolchain with SDKMAN! TODO: description how to install docToolchain with SDKMAN! . Run your First Command Call the docToolchain wrapper with tasks --group doctoolchain to show all tasks provided by docToolchain. Those tasks may be used when invoking the docToolchain wrapper script. The first time docToolchain is called, it downloads all necessary dependencies. Therefore, the execution of the command may take some time. Subsequent calls to docToolchain will be faster. ./dtcw tasks --group=doctoolchain dtcw 0.50 - 8061694f docToolchain 2.3.0 Available docToolchain environments: local (1) Environments with docToolchain [2.3.0]: local (2) Using environment: local (3) Using Java 17.0.6 [/home/john_doe/.doctoolchain/jdk/bin/java] (4) Downloading https://services.gradle.org/distributions/gradle-7.5.1-bin.zip (5) ..........10%..........20%..........30%...........40%..........50%..........60%..........70%...........80%..........90%..........100% Welcome to Gradle 7.5.1! Here are the highlights of this release: - Support for Java 18 - Support for building with Groovy 4 - Much more responsive continuous builds - Improved diagnostics for dependency resolution For more details see https://docs.gradle.org/7.5.1/release-notes.html To honour the JVM settings for this build a single-use Daemon process will be forked. See https://docs.gradle.org/7.5.1/userguide/gradle_daemon.html#sec:disabling_the_daemon. Daemon will be stopped at the end of the build &gt; Configure project : Config file '/code/docToolchainConfig.groovy' does not exist' (6) [ant:input] [ant:input] do you want me to create a default one for you? (y, n) y 1 List of available docToolchain environments. The output may vary depending on your system. In our example only the local environment is available since neither sdk nor docker was found. 2 Environments in which docToolchain s available. The output may vary depending on how you installed docToolchain. In our example docToolchain was found in the user&#8217;s local environment in $HOME/.doctoolchain . 3 Shows the used docToolchain environment. In case docToolchain is installed in more than one environment the wrapper script picks the environment in the following order: local , sdk , and then docker . 4 Location of the used Java. In our example Java was installed in the local environment with the docToolchain wrapper script. 5 docToolchain was invoked the first time, thus it is downloading its dependencies. 6 The docToolchain configuration file docToolchainConfig.groovy wasn&#8217;t found in the project repository. docToolchain asks if it should create a new one. .\\dtcw.ps1 tasks --group=doctoolchain dtcw.bat tasks --group=doctoolchain If you are behind a corporate proxy, you might need to consider build-script dependencies are fetched from a repository referenced by the property mavenRepository . By default, the value https://plugins.gradle.org/m2/ is used. When a repository requiring credentials is used the properties mavenUsername and mavenPassword can be set as well. Example command passing a custom maven repository with credentials from the command line DTC_OPTS=\"-PmavenRepository=your_maven_repo -PmavenUsername=your_username -PmavenPassword=your_pw\" ./dtcw tasks --group=doctoolchain --info Problems &amp; solutions dtcw doesn&#8217;t run You might get an error similar to this one: ./dtcw local tasks --group=doctoolchain ./dtcw: line 1: syntax error near unexpected token `newline' ./dtcw: line 1: `&lt;!DOCTYPE html&gt;' If you see that, it&#8217;s likely that the wrapper didn&#8217;t download correctly. You can expect that an HTML page was downloaded instead of the wrapper. Please try to redownload the wrapper. docker throws and error with dtcw On windows you might get the following error Error response from daemon: user declined directory sharing C:\\Users\\path_to_my_folder This means that docker wanted to share the named folder (possibly the repo) but didn&#8217;t have the rights. This means you have to share the folder yourself on docker. Go to docker dashboard &#8594; settings &#8594; Resources &#8594; FileSharing. Add required folder and hit Apply &amp; Restart. Incompatible Java version You may see that docToolchain starts but crashes with a stacktrace that starts like this: * What went wrong: Could not compile settings file '/Users/falk/.doctoolchain/docToolchain-2.0.0/settings.gradle'. &gt; startup failed: General error during semantic analysis: Unsupported class file major version 61 java.lang.IllegalArgumentException: Unsupported class file major version 61 In this case, you&#8217;ve got an incompatible version of Java. dtcw tries to check the Java version up front by running java --version , but Gradle sometimes picks up a different version. If you get a similar error, try reinstalling a compatible Java version. "
},

{
    "id": 93,
    "uri": "020_tutorial/160_EnterpriseTipsAndTricks.html",
    "menu": "tutorial",
    "title": "Enterprise docToolchain",
    "text": " Table of Contents Some Tips on how to use docToolchain in an Enterprise Environment Corporate Identity CI/CD Pipelines Dependencies Some Tips on how to use docToolchain in an Enterprise Environment Some things are different when you use them at a larger scale. That&#8217;s why I would like to share my experience with docToolchain in an Enterprise Environment. Corporate Identity When you change the design of your microsite, you give your employees the chance to better identify with the documentation. The documentation will feel more \"official\". Take a look at 040_microsite/130_theming.html to see how you change the look and feel. CI/CD Pipelines To automatically build your documentation on change and deploy it to GitHub Pages or GitLab Pages, please take a look at this demo project: ci-cd-demo . It contains a GitHub workflow and a .gitlab-ci.yml which you can use as a starter for your own setup. Both systems, GitHub and GitLab, only provide one static page for each repository. So, if you build the docs in a feature branch, the main docs will be updated. To avoid this, you should restrict the pipeline to your main or default branch. Since all links of the generated docs are relative, you can use the generated artifacts from a PR-Pipeline to get a preview. Dependencies The 2.2.1 docker image of docToolchain should be self-contained. Dependency resolution shouldn&#8217;t be a problem with this image. You should run your build pipeline directly on this image. dtcw will notice it is running within the image and use the dependencies. When you need to use another version or create a local build, it might be that the sources for needed dependencies are unavailable ( https://jfrog.com/blog/jcenter-sunset/ ). To be prepared for such a case, you can specify your own corporate repository proxies. Create a file init.gradle with content like the following: allprojects { buildscript { repositories { maven { url = \"&lt;your maven proxy repository for maven central&gt;\" } } } repositories { maven { url = \"&lt;your maven proxy repository for gradle plugins&gt;\" } } } println \"&gt;&gt;&gt; repository locations initialized via init.gradle\" and reference the file when you execute a dtcw command like this: ./dtcw -I $(pwd)/init.gradle &lt;task&gt; See https://docs.gradle.org/current/userguide/init_scripts.html for more details on this approach. "
},

{
    "id": 94,
    "uri": "020_tutorial/040_microsite/040_generateSite.html",
    "menu": "tutorial",
    "title": "generateSite",
    "text": " Table of Contents generateSite generateSite The generateSite task is more advanced. In many cases, your goal will not be to create a single HTML document but a whole documentation website. This is where generateSite shines. It uses a static site generator to turn your document into a nice looking microsite with landing-page, local search and edit links. Linux / WSL2 with bash ./dtcw generateSite Windows with Powershell ./dtcw.ps1 generateSite output of generateSite $ ./dtcw docker generateSite dtcw - docToolchain wrapper V0.24 docToolchain V2.0.0 Bash is running on WSL this might cause problems with plantUML see https://doctoolchain.github.io/docToolchain/#wsl for more details Java Version 11 docker available home folder exists force use of docker /usr/bin/docker use docker installation Starting a Gradle Daemon (subsequent builds will be faster) &gt; Configure project : arc42/arc42.adoc &gt; Task :generateSite created /project/build/microsite/tmp copy internal theme /home/dtcuser/docToolchain/src/site copy project theme /project/src/site &gt; Task :copyImages &gt; Task :bake Warning: Nashorn engine is planned to be removed from a future JDK release BUILD SUCCESSFUL in 1m 15s 3 actionable tasks: 3 executed The output is written to build/microsite/output/index.html . You can open this file in your browser and view the results. But you will notice that some features which rely on javascript will be broken. To avoid this, use the task previewSite to start a little webserver which presents you the site without flaws. Figure 1. generated output of generateSite task "
},

{
    "id": 95,
    "uri": "020_tutorial/020_arc42.html",
    "menu": "tutorial",
    "title": "arc42 Template",
    "text": " Table of Contents Get the arc42 Template Get the arc42 Template To work with docToolchain, you first need some documents. So let&#8217;s fetch the arc42 template for software architecture documentation. docToolchain comes with a task called downloadTemplate . Let&#8217;s invoke it and see what happens. Linux / WSL2 with bash ./dtcw downloadTemplate Windows with Powershell ./dtcw.ps1 downloadTemplate There is an interesting bug with the german version of the arc42 template in conjunction with running docToolchain in powershell: The encoding of the files will be wrong. To fix that, just run ./dtcw.ps1 fixEncoding . Result of downloadTemplate-Task $ ./dtcw downloadTemplate dtcw - docToolchain wrapper V0.24 docToolchain V2.0.0 Bash is running on WSL this might cause problems with plantUML see https://doctoolchain.github.io/docToolchain/#wsl for more details Java Version 11 docker available home folder exists use local homefolder install /home/rdmueller/.doctoolchain/ &gt; Configure project : arc42/arc42.adoc &gt; Task :downloadTemplate Install arc42 documentation template. For more information about arc42 see https://arc42.org [ant:input] Which language do you want to install? (EN, DE, ES, RU) &lt;-------------&gt; 0% EXECUTING [6s] [ant:input] Do you want the template with or without help? (withhelp, plain) &lt;-----&lt;-------------&gt; 0% EXECUTING [10s] Download https://github.com/arc42/arc42-template/raw/master/dist/arc42-template-DE-withhelp-asciidoc.zip arc42 template unpacked into /c/Users/ralfd/projects/dtc-tests/wsl/src/docs/arc42 added template to docToolchainConfig.groovy use 'generateHTML', 'generatePDF' or 'generateSite' to convert the template BUILD SUCCESSFUL in 15s 1 actionable task: 1 executed Out of the box, docToolchain only knows the open source arc42 template for software architecture. That&#8217;s why it doesn&#8217;t ask which template to install. Since the template exists in four different languages and with or without help on how to use it, docToolchain asks you for these two parameters. It then downloads the template right from the source, unzips it and reformats it a little bit to fit the needs of docToolchain. It also adds the template to your configuration file. That&#8217;s it. You have now docToolchain with the arc42 template installed. Let&#8217;s render is as HTML, PDF or Microsite in the next steps. "
},

{
    "id": 96,
    "uri": "020_tutorial/100_diagrams.net.html",
    "menu": "tutorial",
    "title": "Diagrams: Diagrams.net",
    "text": " Table of Contents Diagrams: Diagrams.net Diagrams: Diagrams.net There is no exportDiagramsnet or exportDrawio task, because working with these diagrams is more convenient than with the other diagramming tools. Diagrams.net (formerly known as Draw.io) is a neat little tool which is able to store the source of your diagrams in the meta-data of your .png or .svg files. To recognize these files as diagrams.net files, give them the extension myfile .dio.png or myfile .dio.svg . In IntelliJ, with the asciidoctor plugin and the diagrams.net plugin installed, type something like image::mynewdiagram.dio.png[] IntelliJ will show you that the file doesn&#8217;t exist. Press alt + shift + enter to create the file. IntelliJ will then launch a local copy of the diagrams.net editor. Every change in the diagram will be directly reflected in your document. Figure 1. just a demo image asciidoctor plugin diagrams.net plugin // Please, replace #yourelement with a real element id on your webpage MarketplaceWidget.setupMarketplaceWidget('card', 7391, \".button1\"); MarketplaceWidget.setupMarketplaceWidget('card', 15635, \".button2\"); "
},

{
    "id": 97,
    "uri": "020_tutorial/040_microsite/index.html",
    "menu": "tutorial",
    "title": "Microsite",
    "text": " This chapter lists tutorials related to publishing a microsite. "
},

{
    "id": 98,
    "uri": "020_tutorial/040_microsite/130_theming.html",
    "menu": "tutorial",
    "title": "How to change the theme",
    "text": " Table of Contents How to change the default theme for generateSite How to change the default theme for generateSite The goal of docToolchain is to provide an environment where you can focus on documentation, and not worry about theming. That&#8217;s why both the jBake templates and CSS are hidden. Let&#8217;s learn how theming works under the hood. docToolchain builds the result theme from three locations: It copies its internal theme into the output path of the site (defaults to build/microsite/temp/src/site ). It looks after the system environment variable DTC_SITETHEME . If this variable is set, it takes precedence over the default theme (technically,it is an override at the file level). It looks after the theme in your current repository (defaults to src/site ). If you want to create a new theme, call the docToolchain task copyTheme . This task copies the theme to the src/site location. After that, you can modify it as you like and create a new zip file with the result. For more information about what the theme structure looks like, head over to the jBake documentation . The basic template uses Twitter Bootstrap 5 as its CSS framework. Use the copyThemes task to copy all hidden jBake resources to your project. You can then remove the resources you don’t need, and change those you want to change. copyThemes overwrites existing files, but because your code is safely managed using version control, this shouldn’t be a problem. "
},

{
    "id": 99,
    "uri": "020_tutorial/040_microsite/043_multi-markup.html",
    "menu": "tutorial",
    "title": "generateSite: Multi-Markup",
    "text": " Table of Contents How to Work with Different Markup Styles Meta-Data Header Markdown HTML restructuredText (.rst) Additional Markup Languages Special Cases How to Work with Different Markup Styles The generateSite task is often used to convert AsciiDoc to HTML. AsciiDoc is the default (and preferred) markup language for documentation written in docToolchain. But because docToolchain is designed to be used by larger teams and organisations, it also leverages jBake, which is capable of rendering AsciiDoc, Markdown, and plain HTML. Meta-Data Header In AsciiDoc, metadata is defined as attributes beginning with jbake- , such as :jbake-header: . For other markup languages, the metadata is defined in a block at the beginning of the document, delimited by ~ ~ [footnote: this can be configured in the jbake.properties file of the theme, and will be available in docToolchainConfig.groovy in the next version]. Refer to the Metadata Header section in the jBake documentation for more information. Markdown jBake Since jBake directly supports Markdown, you can use it without any additional configuration. As illustrated by this sample repository , docToolchain utilises the convention-over-configuration principle to determine the menu ( jbake-menu ), the location within the menu ( jbake-order ), and the title entry of the menu ( jbake-title ) from the folder structure and the document&#8217;s first headline. If you wish to override these defaults, you can use a metadata header. Flavours Here, the Markdown standard is relatively limited. For extended features, you&#8217;ll need to specify the flavour you want to use. jBake employs flexmark to render Markdown, and flexmark supports various flavours. These can be configured within the jbake.properties file within the theme. The default is markdown.extensions=GITHUB,EXTRA,TABLES,TOC,FENCED_CODE_BLOCKS . See also https://jbake.org/docs/2.6.7/#markdown_extensions for more details. HTML Plain HTML is supported in the same way as Markdown. The HTML body will be displayed in the content area of the microsite. Refer to src/docs/Demo/html.html in the sample repository. restructuredText (.rst) Since jBake doesn&#8217;t support restructuredText, docToolchain uses a different mechanism: docToolchainConfig.groovy /** if you need support for additional markup converters, you can configure them here you have three different types of script you can define: - groovy: just groovy code as string - groovyFile: path to a groovy script - bash: a bash command. It will receive the name of the file to be converted as first argument `groovy` and `groovyFile` will have access to the file and config object `dtcw:rstToHtml.py` is an internal script to convert restructuredText. Needs `python3` and `docutils` installed. **/ additionalConverters = [ //'.one': [command: 'println \"test\"+file.canonicalPath', type: 'groovy'], //'.two': [command: 'scripts/convert-md.groovy', type: 'groovyFile'], //'.rst': [command: 'dtcw:rstToHtml.py', type: 'bash'], ] Once an additional converter is configured, docToolchain will traverse all doc-files, check the extension, and invoke the configured script if the extension matches. The script&#8217;s task is to convert the file to a markup format recognised by jBake (AsciiDoc, Markdown, or HTML). Afterwards, jBake will process everything as usual. In this case, the Python docutils will convert restructuredText to HTML. Additional Markup Languages You can integrate additional markup languages in the same way as you added restructuredText. The only difference is that you will configure the script to render your files as a reference to your converter script, rather than using the internal script. You can find an example of the internal script for restructured text here: https://github.com/docToolchain/docToolchain/blob/ng/scripts/rstToHtml.py . Special Cases This mechanism also enables you to add new features to existing markup languages. For instance, you can use a script to replace all plantUML references in a Markdown file with a reference to a kroki.io server to render the file. docToolchainConfig.groovy ... additionalConverters = [ '.md': [ type: 'groovyFile', command: 'scripts/markdown-kroki.groovy' ] ] ... scripts/markdown-kroki.groovy import java.io.ByteArrayOutputStream; import java.io.IOException; import java.util.Base64; import java.util.zip.Deflater; public static byte[] encode(String decoded) throws IOException { return Base64.getUrlEncoder().encode(compress(decoded.getBytes())); } private static byte[] compress(byte[] source) throws IOException { Deflater deflater = new Deflater(Deflater.BEST_COMPRESSION); deflater.setInput(source); deflater.finish(); byte[] buffer = new byte[2048]; int compressedLength = deflater.deflate(buffer); byte[] result = new byte[compressedLength]; System.arraycopy(buffer, 0, result, 0, compressedLength); return result; } def source = file.text def krokiServer = \"https://kroki.io/\" def newSource = source.replaceAll(/(?s)```(plantuml|mermaid)([^`]*)```/){all, type, diagramSource -&gt; System.out.println file.canonicalPath System.out.println type System.out.println diagramSource imageUrl = krokiServer+type+'/png/'+new String(encode(diagramSource)) System.out.println imageUrl return \"![$type diagram]($imageUrl \\\"Image Title\\\")\" } file.write(newSource) "
},

{
    "id": 100,
    "uri": "010_manual/20_install.html",
    "menu": "manual",
    "title": "Install docToolchain",
    "text": " Table of Contents Install docToolchain Installation Overview Install dtcw in your project directory Run docToolchain in a container Install docToolchain with dtcw Install docToolchain with SDKMAN! Run your First Command Configure docToolchain to Use Existing Documents Create a New Documentation Project from Scratch with Arc42 Generate HTML and PDF Upgrading to a New docToolchain Release Install docToolchain 11 minutes to read Installation Overview docToolchain is composed of two parts: doctoolchain which is the toolchain used to create your documentation the docToolchain shell wrapper script installed in your project which calls the toolchain The use of this setup has the following advantages: It&#8217;s easy to build your documentation within your project folder. Ensures that everyone in the project uses the same docToolchain version. Keeps all docToolchain technology out of your project repository. Facilitates the installation of the docToolchain if not installed. Makes it easier to upgrade to newer versions of docToolchain. Install dtcw in your project directory The docToolchain wrapper script dtcw , respective dtcw.ps1 or dtcw.bat for MS Windows, is meant to be installed in your project root directory. The wrapper script simplifies calls to the docToolchain. Even if you are going to use docToolchain in multiple projects, the toolchain will only be installed once on your system. Steps for MacOS/Linux/WSL2 with bash If you have an Apple Silicon (M1/M2) Mac, make sure that you have docker up and running and type the following commands in the Terminal: `arch -x86_64 /bin/bash` Now, download dtcw into your project directory and make the script executable with the following commands: cd &lt;your project&gt; curl -Lo dtcw https://doctoolchain.org/dtcw chmod +x dtcw If you don&#8217;t have curl installed, you can also use wget : cd &lt;your project&gt; wget doctoolchain.org/dtcw chmod +x dtcw Windows with Powershell cd &lt;your project&gt; Invoke-WebRequest doctoolchain.org/dtcw.ps1 -Outfile dtcw.ps1 Got an error message that you are not allowed to execute powershell scripts? Try to switch to an unrestricted powershell by executing powershell.exe -ExecutionPolicy Unrestricted . Windows with cmd.exe cd &lt;your project&gt; curl -Lo dtcw.bat doctoolchain.org/dtcw.bat dtcw.bat wraps the dtcw.ps1 script and executes it in powershell. This might be easier to use if you haven&#8217;t yet configured your powershell as a developer. In case your development team uses different operating systems, put the wrapper scripts for the desired operating systems ( dtcw , dtcw.ps1 , and dtcw.bat ) into your project. Once the docToolchain wrapper is installed in your project directory you have to decide how to install the toolchain: Run docToolchain in a container with the docToolchain container image or Use your custom docker image . Install docToolchain with dtcw in the users home directory $HOME/.doctoolchain Install docToolchain with SDKMAN! a tool for managing parallel versions of multiple Software Development Kits. docToolchain depends on Java 11 (Java 11, 14, and 17 are also supported) If you don&#8217;t use the docToolchain container image you have to install Java on your system. In case you have Java already installed, make sure JAVA_HOME is set. You may use dtcw to install the correct Java version, as shown in the next steps. Run docToolchain in a container The docToolchain project provides a container image of approximately 900 MB from the Docker Hub container registry. The Dockerfile from which the image is created may be found at https://github.com/docToolchain/docker-image . To run docToolchain in a container you need an installed container engine. The best known container engine is Docker . If the container engine is installed you can Run your First Command . The docToolchain wrapper script in your project directory will detect the container engine and pull the docToolchain image on the first invocation. Use your custom docker image Some might need to create their own docker image to add additional tooling or configurations, e.g. proxy settings. In this case you can pass the image name via parameter image directly after docker : ./dtcw docker image &lt;image_name&gt; generateHTML .\\dtcw.ps1 docker image &lt;image_name&gt; generateHTML .\\dtcw.bat docker image &lt;image_name&gt; generateHTML Pass environment variables to docker containers To pass any environment variable to the docker container you can make use of an environment file . The environment file must have the name dtcw_docker.env and must be located in the same folder as dtcw . An example content is e.g.: # set environment variables for docToolchain docker container PROJECT=TEST_PROJECT TEAM=TEST_TEAM Pass additional parameter to docker containers To pass additional parameters to the docker container you can make use of the parameter extra_arguments followed by a string with the additional parameters. One usecase is to enable you to set environment variables to dynamic values. ./dtcw docker image &lt;image_name&gt; extra_arguments \"--env USER=${USERNAME} --env REPO_LOCATION=`git config remote.origin.url`\" generateHTML Install docToolchain with dtcw Steps for MacOS/Linux/WSL2 with bash To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw install doctoolchain In case you have no Java installed you may use dtcw to install Java in a subdirectory of $HOME/.doctoolchain . ./dtcw install java Unable to locate Java Runtime - check your Bash environment If dtcw complains about not being able to locate a Java Runtime, make sure Java is found in your Bash shell, the shell used by dtcw . If you use dtcw from another shell like zsh , it may be that your shell finds the supported Java version but your bash setup doesn&#8217;t. In that case, please switch to bash and make sure that a supported Java version is found. Afterwards, you can switch back to your shell. Windows with Powershell To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw.ps1 install doctoolchain In case you have no Java installed you can use dtcw.ps1 to install Java: .\\dtcw.ps1 install java Windows with cmd.exe To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw.bat install doctoolchain In case you have no Java installed you can use dtcw.ps1 to install Java: .\\dtcw.bat install java If the docToolchain installation finished successfully, you are ready to Run your First Command . Install docToolchain with SDKMAN! TODO: description how to install docToolchain with SDKMAN! . Run your First Command Call the docToolchain wrapper with tasks --group doctoolchain to show all tasks provided by docToolchain. Those tasks may be used when invoking the docToolchain wrapper script. The first time docToolchain is called, it downloads all necessary dependencies. Therefore, the execution of the command may take some time. Subsequent calls to docToolchain will be faster. ./dtcw tasks --group=doctoolchain dtcw 0.50 - 8061694f docToolchain 2.3.0 Available docToolchain environments: local (1) Environments with docToolchain [2.3.0]: local (2) Using environment: local (3) Using Java 17.0.6 [/home/john_doe/.doctoolchain/jdk/bin/java] (4) Downloading https://services.gradle.org/distributions/gradle-7.5.1-bin.zip (5) ..........10%..........20%..........30%...........40%..........50%..........60%..........70%...........80%..........90%..........100% Welcome to Gradle 7.5.1! Here are the highlights of this release: - Support for Java 18 - Support for building with Groovy 4 - Much more responsive continuous builds - Improved diagnostics for dependency resolution For more details see https://docs.gradle.org/7.5.1/release-notes.html To honour the JVM settings for this build a single-use Daemon process will be forked. See https://docs.gradle.org/7.5.1/userguide/gradle_daemon.html#sec:disabling_the_daemon. Daemon will be stopped at the end of the build &gt; Configure project : Config file '/code/docToolchainConfig.groovy' does not exist' (6) [ant:input] [ant:input] do you want me to create a default one for you? (y, n) y 1 List of available docToolchain environments. The output may vary depending on your system. In our example only the local environment is available since neither sdk nor docker was found. 2 Environments in which docToolchain s available. The output may vary depending on how you installed docToolchain. In our example docToolchain was found in the user&#8217;s local environment in $HOME/.doctoolchain . 3 Shows the used docToolchain environment. In case docToolchain is installed in more than one environment the wrapper script picks the environment in the following order: local , sdk , and then docker . 4 Location of the used Java. In our example Java was installed in the local environment with the docToolchain wrapper script. 5 docToolchain was invoked the first time, thus it is downloading its dependencies. 6 The docToolchain configuration file docToolchainConfig.groovy wasn&#8217;t found in the project repository. docToolchain asks if it should create a new one. .\\dtcw.ps1 tasks --group=doctoolchain dtcw.bat tasks --group=doctoolchain If you are behind a corporate proxy, you might need to consider build-script dependencies are fetched from a repository referenced by the property mavenRepository . By default, the value https://plugins.gradle.org/m2/ is used. When a repository requiring credentials is used the properties mavenUsername and mavenPassword can be set as well. Example command passing a custom maven repository with credentials from the command line DTC_OPTS=\"-PmavenRepository=your_maven_repo -PmavenUsername=your_username -PmavenPassword=your_pw\" ./dtcw tasks --group=doctoolchain --info Configure docToolchain to Use Existing Documents If your project already has documents in AsciiDoc format, you&#8217;ll need to tell docToolchain where to find them. To do so, take a look at the created docToolchainConfig.groovy and update it. Create a New Documentation Project from Scratch with Arc42 If you want to use the arc42 template in your project, you can get it in AsciiDoc format by using the following commands. Linux / WSL2 with bash ./dtcw downloadTemplate Windows with Powershell .\\dtcw.ps1 downloadTemplate Windows with cmd.exe dtcw.bat downloadTemplate Generate HTML and PDF By now, the docToolchain wrapper dtcw should be in your project folder along with the arc42 template. Now Let&#8217;s render arc42 to HTML and PDF. To do so, run the commands below: Linux / WSL2 with bash ./dtcw generateHTML ./dtcw generatePDF Windows .\\dtcw.ps1 generateHTML .\\dtcw.ps1 generatePDF As a result, you will see the progress of your build together with some warnings which you can just ignore for the moment. The first build generated some files within the build : build |-- html5 | |-- arc42 | | `-- arc42.html | `-- images | |-- 05_building_blocks-EN.png | |-- 08-Crosscutting-Concepts-Structure-EN.png | `-- arc42-logo.png `-- pdf |-- arc42 | `-- arc42.pdf `-- images |-- 05_building_blocks-EN.png |-- 08-Crosscutting-Concepts-Structure-EN.png `-- arc42-logo.png Congratulations! If you see the same folder structure, you&#8217;ve just rendered the standard arc42 template as HTML and PDF! Please raise an issue on github if you didn&#8217;t get the right output. Blog-Posts: Behind the great Firewall , Enterprise AsciiDoctor Upgrading to a New docToolchain Release If there is a new docToolchain release you wish to use, do the following: Open the docToolchain wrapper script ( dtcw , respective dtcw.ps1 and dtcw.bat ) in your favourite text editor and look for the line with DTC_VERSION which should be located near the start of the file: # See https://github.com/docToolchain/docToolchain/releases for available versions. # Set DTC_VERSION to \"latest\" to get the latest, yet unreleased docToolchain version. VERSION=2.1.0 Change it to match the desired release. In case you want to install docToolchain in local user environment install the new docToolchain release with the following command: ./dtcw install doctoolchain If you want to test a not-yet-released feature, you can set the DTC_VERSION to latest and dtcw will clone or pull the current default branch of the project. Please note this only works with a local copy, not with a Docker install. If you want to develop new features for docToolchain, you can also use latestdev as version. In this case, dtcw will try to clone the docToolchain repository with the ssh-git protocol to a fork in $HOME/.doctoolchain/docToolchain-latest . latest and latestdev currently only work with the bash version of the wrapper. "
},

{
    "id": 101,
    "uri": "010_manual/60_further_reading.html",
    "menu": "manual",
    "title": "Useful Resources",
    "text": " Table of Contents Useful Resources Introduction Underlying Technologies Books Useful Resources 2 minutes to read Introduction Everything you need to know about docToolchain, from the underlying technology to useful resources. Underlying Technologies Learn more about the technologies that support docToolchain, as well as some useful resources. Markup AsciiDoc This is our preferred markup language for technical docs. Asciidoctor User-Manual AsciiDoc Syntax Quick Reference \"Asciidoctor Deep Dive Video\" by Alexander Schwartz Markdown Since we use JBake as a static site generator, you can write your docs in Markdown too. flexmark-java is the Markdown parser and flavor jBake uses. markdown-to-asciidoc library can be used if you prefer to use the exportMarkdown -Task. Templates arc42 The perfect template for your software solution architecture documentation. arc42 arc42 Tips &amp; Tricks arc42 FAQ Docs as Code Docs as Code Treat your docs as if they were code. Docs-as-Code write the docs: docs-as-code Static Site Generator Static Site Generator The underlying static site generator for the generateSite -Task is jBake Our standard theme is docsy Our CSS framework is Twitter Bootstrap Books Note These are Amazon affiliate links. Title Author Language Docs Like Code Anne Gentle English Modern Technical Writing: An Introduction to Software Documentation Andrew Etter English arc42 by Example Gernot Starke, Stefan Zörner, Michael Simons, Ralf D. Müller English Communicating Software Architectures with arc42 Gernot Starke und Peter Hruschka English Software Architecture for Developers, Volume 2 Simon Brown English arc42 in Aktion: Praktische Tipps zur Architekturdokumentation von Gernot Starke and Peter Hruschka40:00 German Softwarearchitekturen dokumentieren und kommunizieren: Entwürfe, Entscheidungen und Lösungen nachvollziehbar und wirkungsvoll festhalten von Stefan Zörner German "
},

{
    "id": 102,
    "uri": "010_manual/40_features.html",
    "menu": "manual",
    "title": "Using docToolchain to Build Docs",
    "text": " Table of Contents Using docToolchain to Build Docs Using docToolchain to Build Docs 1 minute to read docToolchain implements many features via scripts, which you call through the command line. These scripts are called tasks in this documentation. Learn more about these scripts in the Tasks menu. "
},

{
    "id": 103,
    "uri": "010_manual/040_contributors.html",
    "menu": "-",
    "title": "moved",
    "text": " document.location.href = '../10_about/30_community.html'; "
},

{
    "id": 104,
    "uri": "010_manual/30_config.html",
    "menu": "manual",
    "title": "Configuration",
    "text": " Table of Contents Configuration mainConfigFile and docDir AsciiDoc config Command Line Parameters Configuration 2 minutes to read This appendix covers all configuration introduced by docToolchain. AsciiDoc, AsciiDoctor, Gradle and other tools and libraries used know of more configuration settings and you can read about those in the corresponding documentation. mainConfigFile and docDir docToolchain should be easy to use. That&#8217;s why the goal is to have one config file with all settings for each project. But first of all, docToolchain has to know where your documentation project is located. If docDir is defined, the default for mainConfigFile is Config.groovy in the root folder of your docDir . You have several options to specify the location of your documentation project ( docDir ) and the location of your config file ( mainConfigFile ). Commandline Specify the property on the commandline ./dtcw generateHTML -PmainConfigFile=Config.groovy Tip you can verify the location of your Config.groovy by executing docToolchain with the --info parameter which sets the loglevel to info . It will print the location on the command line (among other settings) dynamic configuration properties Sometimes you need a more dynamic configuration. Since the configuration file is an executable .groovy file, you can not only configure static values but also fetch dynamic once. For example, example = System.properties.myProperty You can then specify the property with the -D parameter like this ./dtcw docker generateHTML -DmyProperty=myValue In the same way, you can use environment variables example = System.getenv(\"myEnvVariable\") But in this case, you have to ensure that the environment variable can be accessed. It will not work for docker based execution of dtcw Content of the mainConfigFile outputPath = 'build/docs' // If you want to use the Antora integration, set this to true. // This requires your project to be setup as Antora module. // You can use `downloadTemplate` task to bootstrap your project. //useAntoraIntegration = false // Path where the docToolchain will search for the input files. // This path is appended to the docDir property specified in gradle.properties // or in the command line, and therefore must be relative to it. inputPath = 'src/docs'; inputFiles = [ [file: 'manual_test_script.adoc', formats: ['html','pdf']], /** inputFiles **/ ] //folders in which asciidoc will find images. //these will be copied as resources to ./images //folders are relative to inputPath imageDirs = [ /** imageDirs **/ ] // whether the build should fail when detecting broken image references // if this config is set to true all images will be embedded // failOnMissingImages = false taskInputsDirs = [\"${inputPath}/images\"] taskInputsFiles = [] //****************************************************************************************** //customization of the Jbake gradle plugin used by the generateSite task jbake.with { // possibility to configure additional asciidoctorj plugins used by jbake plugins = [ ] // possibiltiy to configure additional asciidoctor attributes passed to the jbake task asciidoctorAttributes = [ ] } //Configuration for exportChangelog exportChangelog = [:] changelog.with { // Directory of which the exportChangelog task will export the changelog. // It should be relative to the docDir directory provided in the // gradle.properties file. dir = 'src/docs' // Command used to fetch the list of changes. // It should be a single command taking a directory as a parameter. // You cannot use multiple commands with pipe between. // This command will be executed in the directory specified by changelogDir // it the environment inherited from the parent process. // This command should produce asciidoc text directly. The exportChangelog // task does not do any post-processing // of the output of that command. // // See also https://git-scm.com/docs/pretty-formats cmd = 'git log --pretty=format:%x7c%x20%ad%x20%n%x7c%x20%an%x20%n%x7c%x20%s%x20%n --date=short' } //***************************************************************************************** //Configureation for publishToConfluence confluence = [:] // 'input' is an array of files to upload to Confluence with the ability // to configure a different parent page for each file. // // Attributes // - 'file': absolute or relative path to the asciidoc generated html file to be exported // - 'url': absolute URL to an asciidoc generated html file to be exported // - 'ancestorName' (optional): the name of the parent page in Confluence as string; // this attribute has priority over ancestorId, but if page with given name doesn't exist, // ancestorId will be used as a fallback // - 'ancestorId' (optional): the id of the parent page in Confluence as string; leave this empty // if a new parent shall be created in the space // Set it for every file so the page scanning is done only for the given ancestor page trees. // // The following four keys can also be used in the global section below // - 'spaceKey' (optional): page specific variable for the key of the confluence space to write to // - 'subpagesForSections' (optional): The number of nested sub-pages to create. Default is '1'. // '0' means creating all on one page. // The following migration for removed configuration can be used. // 'allInOnePage = true' is the same as 'subpagesForSections = 0' // 'allInOnePage = false &amp;&amp; createSubpages = false' is the same as 'subpagesForSections = 1' // 'allInOnePage = false &amp;&amp; createSubpages = true' is the same as 'subpagesForSections = 2' // - 'pagePrefix' (optional): page specific variable, the pagePrefix will be a prefix for the page title and it's sub-pages // use this if you only have access to one confluence space but need to store several // pages with the same title - a different pagePrefix will make them unique // - 'pageSuffix' (optional): same usage as prefix but appended to the title and it's subpages // only 'file' or 'url' is allowed. If both are given, 'url' is ignored confluence.with { input = [ [ file: \"build/docs/html5/arc42-template-de.html\" ], ] // endpoint of the confluenceAPI (REST) to be used // https://[yourServer] api = 'https://[yourServer]' // requests per second for confluence API calls rateLimit = 10 // Additionally, spaceKey, subpagesForSections, pagePrefix and pageSuffix can be globally defined here. The assignment in the input array has precedence // the key of the confluence space to write to spaceKey = 'asciidoc' // if true, all pages will be created using the new editor v2 // enforceNewEditor = false // variable to determine how many layers of sub pages should be created subpagesForSections = 1 // the pagePrefix will be a prefix for each page title // use this if you only have access to one confluence space but need to store several // pages with the same title - a different pagePrefix will make them unique pagePrefix = '' pageSuffix = '' /* WARNING: It is strongly recommended to store credentials securely instead of commiting plain text values to your git repository!!! Tool expects credentials that belong to an account which has the right permissions to to create and edit confluence pages in the given space. Credentials can be used in a form of: - passed parameters when calling script (-PconfluenceUser=myUsername -PconfluencePass=myPassword) which can be fetched as a secrets on CI/CD or - gradle variables set through gradle properties (uses the 'confluenceUser' and 'confluencePass' keys) Often, same credentials are used for Jira &amp; Confluence, in which case it is recommended to pass CLI parameters for both entities as -Pusername=myUser -Ppassword=myPassword */ //optional API-token to be added in case the credentials are needed for user and password exchange. //apikey = \"[API-token]\" // HTML Content that will be included with every page published // directly after the TOC. If left empty no additional content will be // added // extraPageContent = '&lt;ac:structured-macro ac:name=\"warning\"&gt;&lt;ac:parameter ac:name=\"title\" /&gt;&lt;ac:rich-text-body&gt;This is a generated page, do not edit!&lt;/ac:rich-text-body&gt;&lt;/ac:structured-macro&gt; extraPageContent = '' // enable or disable attachment uploads for local file references enableAttachments = false // default attachmentPrefix = attachment - All files to attach will require to be linked inside the document. // attachmentPrefix = \"attachment\" // Optional proxy configuration, only used to access Confluence // schema supports http and https // proxy = [host: 'my.proxy.com', port: 1234, schema: 'http'] // Optional: specify which Confluence OpenAPI Macro should be used to render OpenAPI definitions // possible values: [\"confluence-open-api\", \"open-api\", \"swagger-open-api\", true]. true is the same as \"confluence-open-api\" for backward compatibility // useOpenapiMacro = \"confluence-open-api\" } //***************************************************************************************** //Configuration for the export script 'exportEA.vbs'. // The following parameters can be used to change the default behaviour of 'exportEA'. // All parameter are optionally. // - connection: Parameter allows to select a certain database connection by // using the ConnectionString as used for directly connecting to the project // database instead of looking for EAP/EAPX files inside and below the 'src' folder. // - 'packageFilter' is an array of package GUID's to be used for export. All // images inside and in all packages below the package represented by its GUID // are exported. A packageGUID, that is not found in the currently opened // project, is silently skipped. PackageGUID of multiple project files can // be mixed in case multiple projects have to be opened. // - exportPath: relative path to base 'docDir' to which the diagrams and notes are to be exported // - searchPath: relative path to base 'docDir', in which Enterprise Architect project files are searched // - absoluteSearchPath: absolute path in which Enterprise Architect project files are searched // - glossaryAsciiDocFormat: if set, the EA glossary is exported into exportPath as 'glossary.ad' // - glossaryTypes: if set and glossary is exported, used to filter for certain types. // Not set or empty list will cause no filtered glossary. // - diagramAttributes: if set, the diagram attributes are exported and formatted as specified // - imageFormat: if set, the image format is used for the export of diagrams. Default is '.png'. exportEA.with { // OPTIONAL: Set the connection to a certain project or comment it out to use all project files inside the src folder or its child folder. // connection = \"DBType=1;Connect=Provider=SQLOLEDB.1;Integrated Security=SSPI;Persist Security Info=False;Initial Catalog=[THE_DB_NAME_OF_THE_PROJECT];Data Source=[server_hosting_database.com];LazyLoad=1;\" // OPTIONAL: Add one or multiple packageGUIDs to be used for export. All packages are analysed, if no packageFilter is set. // packageFilter = [ // \"{A237ECDE-5419-4d47-AECC-B836999E7AE0}\", // \"{B73FA2FB-267D-4bcd-3D37-5014AD8806D6}\" // ] // OPTIONAL: export diagrams, notes, etc. below folder src/docs // exportPath = \"src/docs/\" // OPTIONAL: EA project files are expected to be located in folder src/projects // searchPath = \"src/projects/\" // OPTIONAL: terms will be exported as asciidoc 'Description, single-line' // glossaryAsciiDocFormat = \"TERM:: MEANING\" // OPTIONAL: only terms of type Business and Technical will be exported. // glossaryTypes = [\"Business\", \"Technical\"] // OPTIONAL: Additional files will be exported containing diagram attributes in the given asciidoc format // diagramAttributes = \"Modified: %DIAGRAM_AUTHOR%, %DIAGRAM_MODIFIED%, %DIAGRAM_NAME%, // %DIAGRAM_GUID%, %DIAGRAM_CREATED%, %DIAGRAM_NOTES%, %DIAGRAM_DIAGRAM_TYPE%, %DIAGRAM_VERSION%\" // OPTIONAL: format of the exported diagrams. Defaults to '.png' if the parameter is not provided. // imageFormat = \".svg\" } htmlSanityCheck.with { //sourceDir = \"build/html5/site\" // where to put results of sanityChecks... //checkingResultsDir = // OPTIONAL: directory where the results written to in JUnit XML format //junitResultsDir = // OPTIONAL: which statuscodes shall be interpreted as warning, error or success defaults to standard //httpSuccessCodes = [] //httpWarningCodes = [] //httpErrorCodes = [] // fail build on errors? failOnErrors = false } // Configuration for Jira related tasks jira = [:] jira.with { // endpoint of the JiraAPI (REST) to be used api = 'https://your-jira-instance' // requests per second for Jira API calls rateLimit = 10 /* WARNING: It is strongly recommended to store credentials securely instead of commiting plain text values to your git repository!!! Tool expects credentials that belong to an account which has the right permissions to read the JIRA issues for a given project. Credentials can be used in a form of: - passed parameters when calling script (-PjiraUser=myUsername -PjiraPass=myPassword) which can be fetched as a secrets on CI/CD or - gradle variables set through gradle properties (uses the 'jiraUser' and 'jiraPass' keys) Often, Jira &amp; Confluence credentials are the same, in which case it is recommended to pass CLI parameters for both entities as -Pusername=myUser -Ppassword=myPassword */ // the key of the Jira project project = 'PROJECTKEY' // the format of the received date time values to parse dateTimeFormatParse = \"yyyy-MM-dd'T'H:m:s.SSSz\" // i.e. 2020-07-24'T'9:12:40.999 CEST // the format in which the date time should be saved to output dateTimeFormatOutput = \"dd.MM.yyyy HH:mm:ss z\" // i.e. 24.07.2020 09:02:40 CEST // the label to restrict search to label = 'label1' // Legacy settings for Jira query. This setting is deprecated &amp; support for it will soon be completely removed. Please use JiraRequests settings jql = \"project='%jiraProject%' AND labels='%jiraLabel%' ORDER BY priority DESC, duedate ASC\" // Base filename in which Jira query results should be stored resultsFilename = 'JiraTicketsContent' saveAsciidoc = true // if true, asciidoc file will be created with *.adoc extension saveExcel = true // if true, Excel file will be created with *.xlsx extension // Output folder for this task inside main outputPath resultsFolder = 'JiraRequests' /* List of requests to Jira API: These are basically JQL expressions bundled with a filename in which results will be saved. User can configure custom fields IDs and name those for column header, i.e. customfield_10026:'Story Points' for Jira instance that has custom field with that name and will be saved in a coloumn named \"Story Points\" */ exports = [ [ filename:\"File1_Done_issues\", jql:\"project='%jiraProject%' AND status='Done' ORDER BY duedate ASC\", customfields: [customfield_10026:'Story Points'] ], [ filename:'CurrentSprint', jql:\"project='%jiraProject%' AND Sprint in openSprints() ORDER BY priority DESC, duedate ASC\", customfields: [customfield_10026:'Story Points'] ] ] } // Configuration for OpenAPI related task openApi = [:] // 'specFile' is the name of OpenAPI specification yaml file. Tool expects this file inside working dir (as a filename or relative path with filename) // 'infoUrl' and 'infoEmail' are specification metadata about further info related to the API. By default this values would be filled by openapi-generator plugin placeholders // openApi.with { specFile = 'src/docs/petstore-v2.0.yaml' // i.e. 'petstore.yaml', 'src/doc/petstore.yaml' infoUrl = 'https://my-api.company.com' infoEmail = 'info@company.com' } // Sprint changelog configuration generate changelog lists based on tickets in sprints of an Jira instance. // This feature requires at least Jira API &amp; credentials to be properly set in Jira section of this configuration sprintChangelog = [:] sprintChangelog.with { sprintState = 'closed' // it is possible to define multiple states, i.e. 'closed, active, future' ticketStatus = \"Done, Closed\" // it is possible to define multiple ticket statuses, i.e. \"Done, Closed, 'in Progress'\" showAssignee = false showTicketStatus = false showTicketType = true sprintBoardId = 12345 // Jira instance probably have multiple boards; here it can be defined which board should be used // Output folder for this task inside main outputPath resultsFolder = 'Sprints' // if sprintName is not defined or sprint with that name isn't found, release notes will be created on for all sprints that match sprint state configuration sprintName = 'PRJ Sprint 1' // if sprint with a given sprintName is found, release notes will be created just for that sprint allSprintsFilename = 'Sprints_Changelogs' // Extension will be automatically added. } collectIncludes = [:] collectIncludes.with { // fileFilter = \"adoc\" // define which files are considered. default: \"ad|adoc|asciidoc\" // minPrefixLength = \"3\" // define what minimum length the prefix. default: \"3\" // maxPrefixLength = \"3\" // define what maximum length the prefix. default: \"\" // separatorChar = \"_\" // define the allowed separators after prefix. default: \"-_\" // cleanOutputFolder = true // should the output folder be emptied before generation? default: false // excludeDirectories = [] // define additional directories that should not be traversed. } // Configuration for Structurizr related tasks structurizr = [:] structurizr.with { // Configure where `exportStructurizr` looks for the Structurizr model. workspace = { // The directory in which the Structurizr workspace file is located. // path = 'src/docs/structurizr' // By default `exportStructurizr` looks for a file '${structurizr.workspace.path}/workspace.dsl' // You can customize this behavior with 'filename'. Note that the workspace filename is provided without '.dsl' extension. // filename = 'workspace' } export = { // Directory for the exported diagrams. // // WARNING: Do not put manually created/changed files into this directory. // If a valid Structurizr workspace file is found the directory is deleted before the diagram files are generated. // outputPath = 'src/docs/structurizr/diagrams' // Format of the exported diagrams. Defaults to 'plantuml' if the parameter is not provided. // // Following formats are supported: // - 'plantuml': the same as 'plantuml/structurizr' // - 'plantuml/structurizr': exports views to PlantUML // - 'plantuml/c4plantuml': exports views to PlantUML with https://github.com/plantuml-stdlib/C4-PlantUML // format = 'plantuml' } } // Configuration for openAI related tasks openAI = [:] openAI.with { // This task requires a person access token for openAI. // Ensure to pass this token as parameters when calling the task // using -PopenAI.token=xx-xxxxxxxxxxxxxx //model = \"text-davinci-003\" //maxToken = '500' //temperature = '0.3' } // Configuration for pandoc options pandocOptions = [ '--toc' ] AsciiDoc config Command Line Parameters "
},

{
    "id": 105,
    "uri": "010_manual/010_introduction_and_goals.html",
    "menu": "-",
    "title": "moved",
    "text": " document.location.href = '../10_about/20_what-is-doctoolchain.html'; "
},

{
    "id": 106,
    "uri": "010_manual/50_Frequently_asked_Questions.html",
    "menu": "manual",
    "title": "Solutions to Common Problems",
    "text": " Table of Contents Solutions to Common Problems References Images Sparx Enterprise Architect Known error Messages Solutions to Common Problems 9 minutes to read This section tries to answer the most common and frequently asked questions about how to work with docToolchain. It will also contain questions relevant to the tools used to build docToolchain, but the main focus is docToolchain itself. If you are stuck, make sure that you also check other sources like Stack Overflow . There is also a great FAQ for all your arc42 questions: https://faq.arc42.org/home/ If you have a question or problem for which you can&#8217;t find a solution, you can for this repo, add your question and create a pull request raise the issue through the GitHub issue tracker ask your question on Stack Overflow discuss the problem on Slack References Q: How can I reference source code from my documentation? Answer As long, as you stay within your documents folder (default src/docs ), you can simply reference other files with a relative include::filename.adoc[] -statement. If you need to reference files outside of the documents folder, you need to reference them with an absolute path. include::/home/runner/work/docToolchain/docToolchainfilename.adoc[] The /home/runner/work/docToolchain/docToolchain will point to the folder where your dtcw file resides. In order make this also work in your editor preview, specify a line like the following in your documents: ifndef::projectRootDir[:projectRootDir: ../../../] Images Asciidoctor User Manual on images Asciidoctor Quick Reference on images AsciiDoctor Writer Guide on images Q: Why are images not shown in the preview of my editor? Answer This is most likely because your editor doesn&#8217;t know where they are stored. If you follow the default settings, you probably store your images in a subfolder images . The build script knows about it, because the attribute imagesdir has been set to ./images , but your editor doesn&#8217;t care about the build script - it only checks the currently opened AsciiDoc file. The solution is to add a line to each file which checks if the imagesdir is set and if not, sets it to a valid value: ifndef::imagesdir[:imagesdir: ../images] Q: Which image format should I use? Answer AsciiDoc and AsciiDoctor support several formats like GIF, PNG, JPG and SVG. However, if you want to use most features, some formats are better to use than others: GIF is not supported by the PDF renderer. Use JPG or PNG instead. JPG is great for photos but not for diagrams (you might get compression artifacts). So, if you want to use photos from your flipcharts - JPG might work for you. SVG great for high resolution diagrams, but not good supported by DOCX as output format. OpenOffice Writer might display the image a bit stretched, MS Word didn&#8217;t display it at all in some experiments. PDF output might display a warning that newer SVG versions are not supported (happens especially with diagrams.net images). PNG this is the preferred format for images used with docToolchain. All output formats support it and if diagrams are rendered with a resolution high enough to display all details, it will also be scaled well with all output formats. Q: Why are my images rotated in the output? Answer This most likely happens when you&#8217;ve taken photos with a mobile device and include them in you docs. A mobile device does not rotate the image itself, it only stores the orientation of the device in the metadata of the photo. Your operating system will show you the image as expected, but the rendered AsciiDoc will not. This can be „fixed“ with Imagemagick, by using convert -auto-orient or mogrify -auto-orient (thanx to @rotnroll666 for this tip). You can also try to just open the image in your favourite editor and re-save it. === exportVisio Q: I get an error message saying that a library is not registered when I try to run the exportVisio -task. Ausnahme beim Festlegen von \"Visible\": \"Das COM-Objekt des Typs \"Microsoft.Office.Interop.Visio.ApplicationClass\" kann nicht in den Schnittstellentyp \"Microsoft.Office.Interop.Visio.IVApplication\" umgewandelt werden. Dieser Vorgang konnte nicht durchgeführt werden, da der QueryInterface-Aufruf an die COM-Komponente für die Schnittstelle mit der IID \"{000D0700-0000-0000-C000-000000000046}\" aufgrund des folgenden Fehlers nicht durchgeführt werden konnte: Bibliothek nicht registriert. (Ausnahme von HRESULT: 0x8002801D (TYPE_E_LIBNOTREGISTERED)).\" In ...\\scripts\\VisioPageToPngConverter.ps1:48 Zeichen:1 + $VisioApp.Visible = $false + ~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : NotSpecified: (:) [], SetValueInvocationException + FullyQualifiedErrorId : ExceptionWhenSetting Answer When Visio is installed, it registers itself as a com library. It seems that this registration can break. You can fix this by visiting the windows system settings &#8594; install or uninstall a program, select visio , select change and then repair . Sparx Enterprise Architect Q: Sparx Enterprise Architect is a Windows tool, isn&#8217;t it? Answer Yes, it is, but it is written to support CrossOver in order to run on Linux based systems. Wine, the open source branch of CrossOver, seems to work as well. Take a look at this page to see how to install it on a linux based system: https://www.sparxsystems.com/support/faq/ea_on_linux.html I (Ralf) once gave it a try and even managed to get remote control over EA via VBS and COM up and running (which is the pre-requisite for docToolchain). Known error Messages Q: I get the error for ':generateDeck' saying 'No such file or directory' when cloning reveal.js. ./dtcw generateDeck dtcw - docToolchain wrapper V0.38 docToolchain Vlatest docToolchain as CLI available docker available home folder exists cloning reveal.js ./dtcw: line 133: cd: $HOME/.doctoolchain/docToolchain-latest/resources: No such file or directory Answer You&#8217;re using dtcw v0.38 or an older version. This is because with the release of docToolchain 3.x, the ':generateDeck' tasks no longer rely on helper scripts. To resolve this issue, simply upgrade dtcw to the latest version. The good news is that dtcw is backwards compatible with docToolchain, meaning you can use the latest version of dtcw while still referring to older versions of docToolchain. To switch to other version of docToolchain refer to the installation docs . Q: I get the error saying 'Failed to create MD5 hash for file content'. * What went wrong: Failed to capture snapshot of input files for task ':generateHTML' property 'sourceDir' during up-to-date check. &gt; Failed to create MD5 hash for file content.` Answer There are two known reasons for this error. One of the .adoc files is opened in an editor, so that windows can&#8217;t get the lock for that file. &#8594; Close all .adoc files. You use the Bash script doctoolchain on a windows system. &#8594; Use doctoolchain.bat instead. It works even in a Bash Shell. Q: I get the error saying 'Unsupported major.minor version 52.0' Answer This is a sign that you use an outdated version of Java. Please upgrade to Java 8 at least and 14 max. The docToolchain-wrapper (dtcw) in v2.0 will check the java version for you so that you will not see this error message in the future. Q: I get an error message saying 'Error occurred during initialization of VM' Starting a Gradle Daemon, 1 incompatible Daemon could not be reused, use --status for details FAILURE: Build failed with an exception. * What went wrong: Unable to start the daemon process. … Error occurred during initialization of VM Could not reserve enough space for 2097152KB object heap Answer Somehow docToolchain can&#8217;t allocate the memory which is configured out of the box. Try to free up some memory or comment out the line org.gradle.jvmargs=-Xmx2048m in gradle.properties Q: I get the error saying Could not initialize class java.awt.GraphicsEnvironment$LocaleGE Answer This seems to be a problem with WSL on Windows. Some sources mention to run Java in headless mode, but in this case, it doesn&#8217;t solve the problem. The root cause seems to be plantUML trying to get some font information. Only real solution seems to be to shutdown WSL from a powershell window with wsl --shutdown and retry. Warning this will kill all your WSL terminals without warning. Another solution seems to be to install a fresh version of your java runtime (I thought it is immutable, but it really helps). Best Solution is to switch to powershell. Another solution is to avoid PlantUML and generate Diagrams through a kroki.io server. Another variant of this is Can&#8217;t connect to X11 window server using '192.168.189.153:0' as the value of the DISPLAY variable. . In this case, it might help to install an X-Server (x410 for example) and configure the DISPLAY variable correctly. An easy way to test your configuration is to run xeyes in WSL. Make sure that your WSL is up-to-date by running wsl --update . This is not part of your regular Windows update! Q: I get a Failed to create parent directory /project/.gradle error &gt; Gradle could not start your build. &gt; Could not create service of type CrossBuildFileHashCache using BuildSessionServices.createCrossBuildFileHashCache(). &gt; Failed to create parent directory '/project/.gradle' when creating directory '/project/.gradle/6.7.1/fileHashes' Answer This issue can occur in CI environments (such as Bamboo) that have restricted permissions in the working folder where files or directories created outside the container might not be accessible inside the container. Before starting the container, give the working directory maximum permissions for allowing access to the user inside the Docker container. chmod -R o+rwx ${bamboo.working.directory} ./dtcw generateSite Another solution could be that you work on the same project with WSL and Powershell. In such an environment, the WSL environment creates temporary files which can not be modified via powershell. In such a case, just delete the .gradle folder. Q: I get an error stating that Gradle dependencies cannot be downloaded because a proxy is restricting internet access Answer Remember that dtcw is a wrapper around Gradle. So instead of calling this: ./dtcw generateSite You could call this instead (remember to replace the values used in our example): ./dtcw generateSite -Dhttp.proxyHost=127.0.0.1 -Dhttp.proxyPort=3128 \"-http.nonProxyHosts=*.nonproxyrepos.com|localhost\" (IP, port, etc. just an example) For more information about Gradle proxy configuration, read this article . "
},

{
    "id": 107,
    "uri": "010_manual/single-page.html",
    "menu": "-",
    "title": "docToolchain Manual",
    "text": " toc-title docToolchain Manual 1. What Is docToolchain? 1.1. Introduction 1.2. Docs as Code 1.3. arc42 1.4. How docToolchain Brings Everything Together 1.5. What You Get with docToolchain 1.5.1. A Ready-Made Document Management System 1.5.2. Built-In Collaboration and Review 1.5.3. Image References and Code Snippets 1.5.4. Compound and Stakeholder-Tailored Docs 1.5.5. And So Much More&#8230;&#8203; 1.6. Install docToolchain 1.6.1. Installation Overview 1.6.2. Install dtcw in your project directory 1.6.3. Run docToolchain in a container 1.6.4. Install docToolchain with dtcw 1.6.5. Install docToolchain with SDKMAN! 1.6.6. Run your First Command 1.6.7. Configure docToolchain to Use Existing Documents 1.6.8. Create a New Documentation Project from Scratch with Arc42 1.6.9. Generate HTML and PDF 1.6.10. Upgrading to a New docToolchain Release 1.7. Using docToolchain to Build Docs 2. docToolchain Tasks 3. autobuildSite 3.1. About This Task 3.2. Source 4. generateHTML 4.1. About This Task 4.2. Generating Single-File HTML Output 4.3. Creating Text-Based Diagrams 4.4. Controlling Diagram Size 4.5. Further Reading and Resources 4.6. Source 5. copyThemes 5.1. About This Task 5.2. Source 6. fixEncoding 6.1. About This Task 6.2. Source 7. prependFilename 7.1. About This Task 7.2. Source 8. collectIncludes 8.1. About This Task 8.2. The Optional Parameter Configurations 8.3. Example 8.4. Source 9. generatePDF 9.1. About This Task 9.2. Creating a Custom PDF Theme 9.3. Further Reading and Resources 9.4. Source 10. generateSite 10.1. About This Task 10.2. Pages 10.3. Configuration 10.3.1. Menu 10.3.2. Links 10.3.3. Configuring the JBake plugin 10.4. Templates and Style 10.5. Landing Page 10.6. Blog 10.7. Search 10.8. CI/CD 10.9. Further Reading and Resources 10.10. Source 11. generateDocbook 11.1. About This Task 11.2. Source 12. generateDeck 12.1. About This Task 12.1.1. Configure RevealJs 12.2. Source 13. publishToConfluence 13.1. About This Task 13.2. Special Features 13.2.1. Easy Code Block Conversion 13.2.2. Minimal Impact on Non-Techie Confluence Users 13.2.3. Keywords Automatically Attached as Labels 13.3. Configuration 13.4. Attributes 13.5. CSS Styling 13.6. Source 14. convertToDocx 14.1. Before You Begin 14.2. Further Reading and Resources 14.3. Source 15. createReferenceDoc 15.1. Before You Begin 15.2. About This Task 15.3. Config.groovy Notes 15.4. Source 16. convertToEpub 16.1. Dependency 16.2. About This Task 16.3. Further Reading and Resources 16.4. Source 17. exportEA 17.1. About This Task 17.2. Important 17.3. The Optional Parameter Configurations 17.3.1. connection 17.3.2. packageFilter 17.3.3. exportPath 17.3.4. searchPath 17.3.5. glossaryAsciiDocFormat 17.3.6. glossaryTypes 17.3.7. diagramAttributes 17.3.8. imageFormat 17.3.9. additionalOptions 17.4. Glossary export 17.5. Further Reading and Resources 17.6. Source 18. exportVisio 18.1. About This Task 18.2. Important Information About This Task 18.3. Further Reading and Resources 18.4. Source 19. exportDrawIo 19.1. About This Task 19.2. About diagrams.net 19.3. How to Change Your Workflow to Use diagrams.net 19.4. How to Convert a Confluence Page to AsciiDoc 20. exportChangeLog 20.1. About This Task 20.2. Further Reading and Resources 20.3. Source 21. exportContributors 21.1. About This Task 21.2. How to Use This Task 21.3. About the Avatar-Icons 21.4. File Attributes 22. exportJiraIssues 22.1. About This Task 22.2. Migrate configuration to version &gt;= 3.2.0 22.3. Configuration 22.3.1. Deprecation Notice 22.3.2. Configuration Options 22.4. Source 23. exportJiraSprintChangelogIssues 23.1. About This Task 23.2. Configuration 23.3. Source 24. exportPPT 24.1. About This Task 24.2. Further Reading and Resources 24.3. Source 25. exportExcel 25.1. About This Task 25.2. Further Reading and Resources 25.3. Source 26. exportMarkdown 26.1. About This Task 26.2. Source 27. exportOpenAPI 27.1. About This Task 27.2. Configuration 27.3. Source 28. exportStructurizr 28.1. About This Task 28.2. Configuration 28.3. Example Configuration 28.4. Source 29. htmlSanityCheck 29.1. About This Task 29.2. Further Reading and Resources 29.3. Source 30. dependencyUpdates 30.1. About This Task 30.2. Further Reading and Resources 30.3. Development 30.4. Setting Up a Dev Environment 30.4.1. Before You Begin 30.4.2. Do a Local Install for Docker and SDKMAN! 30.4.3. Create Gradle-Independent Tasks 30.4.4. Create or Change a Theme 30.4.5. Special Functionality for Themes (Config Fragments) 30.5. Running Tests 30.5.1. Execute Tests 30.5.2. Execute a specific test 30.5.3. Workaround to Ensure Correct Proxy Settings for Tests 30.6. Creating a New Release 30.6.1. Before You Begin 30.6.2. GitHub 30.6.3. Docker Hub 30.6.4. Blog Post 30.6.5. docToolchain-Wrapper (dtcw) 30.6.6. SDKMAN! 30.7. Debugging 30.7.1. Environment 30.7.2. Gradle 30.7.3. jBake Templates 30.7.4. Theming, Menu and Images 30.7.5. Script Execution Debugging 30.8. Solutions to Common Problems 30.8.1. References 30.8.2. Images 30.8.3. Sparx Enterprise Architect 30.8.4. Known error Messages 30.9. Useful Resources 30.9.1. Introduction 30.9.2. Underlying Technologies 30.9.3. Books 30.10. Configuration 30.10.1. mainConfigFile and docDir 30.10.2. AsciiDoc config 30.10.3. Command Line Parameters .gravatar img { margin-left: 3px; border-radius: 4px; } docToolchain Manual .gravatar img { margin-left: 3px; border-radius: 4px; } .gravatar img { margin-left: 3px; border-radius: 4px; } 1. What Is docToolchain? 4 minutes to read 1.1. Introduction docToolchain is a documentation generation tool that uses the Docs as Code approach as a basis for its architecture, plus some additional automation provided by the arc42 template . 1.2. Docs as Code ‘Docs as code’ refers to a philosophy that you should write documentation using the same tools as you use to write code. If you need to write technical docs for your software project, why not use the same tools and processes as you use for your source code? There are so many benefits: You don’t have to learn a complicated docs management system. Developers feel more at home in the docs because they look and feel like code. You can manage docs using standard version control like GitHub. 1.3. arc42 arc42 has been a part of docToolchain since the earliest version. But what is arc42? Dr. Gernot Starke and Peter Hruschka created the arc42 template as a standard for software architecture documentation. They used their experience of software architectures both in the template structure and the explanations that appear in each chapter to guide you when you’re writing your documentation. arc42 is available in well-known formats including MS Word, textile, and Confluence. All of these formats are automatically generated from a single golden master which is formatted in AsciiDoc . 1.4. How docToolchain Brings Everything Together To follow a docs as code approach, you need a build script that automates steps like exporting diagrams and rendering Markdown (or AsciiDoc in the case of docToolchain) to the target format. Creating this type of build script is not easy (and even harder to maintain). There are also lots of questions to answer: “How do I create .docx?” and “Why doesn’t lib x work with lib y?” docToolchain is the result of one developer’s journey through the docs as code universe. The goal of docToolchain is to automate the creation of technical docs through an easy-to-use build script that only needs to be configured not modified, and that is nurtured and cared for by a diverse open source community . 1.5. What You Get with docToolchain 1.5.1. A Ready-Made Document Management System By using a version control system like Git , you get a perfect document management system for free. Git allows you to version your docs, branch them, and also leaves an audit trail. You can even check who wrote which part of the docs. Isn’t that great? And because your docs are simple plain text, it’s easy to do a diff and see exactly what has changed. Bonus: storing your docs in the same repo as your code means they’re always in sync! 1.5.2. Built-In Collaboration and Review As a distributed version control system, Git comes with doc collaboration and review processes built in. People can fork the docs and send pull requests for the changes they make. You review the changes. Done! Most Git frontends like Bitbucket , GitLab and GitHub also allow you to reject pull requests with comments. 1.5.3. Image References and Code Snippets Instead of pasting images into a binary document format, docToolchain lets you reference images. This ensures that your imagery is always up-to-date every time you rebuild your documents. You can also reference code snippets directly from your source code. You&#8217;ll save so much time because your docs and code will always be in sync and completely up to date! 1.5.4. Compound and Stakeholder-Tailored Docs As if image refs and code snippets weren&#8217;t enough, docToolchain also lets you split docs into several sub-documents plus a master for greater cohesion. And you&#8217;re not restricted to one master. You can create master docs for different stakeholders that only contain the chapters they need. 1.5.5. And So Much More&#8230;&#8203; If you can dream it, you can script it! Want to include a list of open issues from Jira? You can! Want to include a changelog from Git? Go for it! Want to use inline text-based diagrams? Knock yourself out! 1.6. Install docToolchain 11 minutes to read 1.6.1. Installation Overview docToolchain is composed of two parts: doctoolchain which is the toolchain used to create your documentation the docToolchain shell wrapper script installed in your project which calls the toolchain The use of this setup has the following advantages: It&#8217;s easy to build your documentation within your project folder. Ensures that everyone in the project uses the same docToolchain version. Keeps all docToolchain technology out of your project repository. Facilitates the installation of the docToolchain if not installed. Makes it easier to upgrade to newer versions of docToolchain. 1.6.2. Install dtcw in your project directory The docToolchain wrapper script dtcw , respective dtcw.ps1 or dtcw.bat for MS Windows, is meant to be installed in your project root directory. The wrapper script simplifies calls to the docToolchain. Even if you are going to use docToolchain in multiple projects, the toolchain will only be installed once on your system. Steps for MacOS/Linux/WSL2 with bash If you have an Apple Silicon (M1/M2) Mac, make sure that you have docker up and running and type the following commands in the Terminal: `arch -x86_64 /bin/bash` Now, download dtcw into your project directory and make the script executable with the following commands: cd &lt;your project&gt; curl -Lo dtcw https://doctoolchain.org/dtcw chmod +x dtcw If you don&#8217;t have curl installed, you can also use wget : cd &lt;your project&gt; wget doctoolchain.org/dtcw chmod +x dtcw Windows with Powershell cd &lt;your project&gt; Invoke-WebRequest doctoolchain.org/dtcw.ps1 -Outfile dtcw.ps1 Got an error message that you are not allowed to execute powershell scripts? Try to switch to an unrestricted powershell by executing powershell.exe -ExecutionPolicy Unrestricted . Windows with cmd.exe cd &lt;your project&gt; curl -Lo dtcw.bat doctoolchain.org/dtcw.bat dtcw.bat wraps the dtcw.ps1 script and executes it in powershell. This might be easier to use if you haven&#8217;t yet configured your powershell as a developer. In case your development team uses different operating systems, put the wrapper scripts for the desired operating systems ( dtcw , dtcw.ps1 , and dtcw.bat ) into your project. Once the docToolchain wrapper is installed in your project directory you have to decide how to install the toolchain: Run docToolchain in a container with the docToolchain container image or Use your custom docker image . Install docToolchain with dtcw in the users home directory $HOME/.doctoolchain Install docToolchain with SDKMAN! a tool for managing parallel versions of multiple Software Development Kits. docToolchain depends on Java 11 (Java 11, 14, and 17 are also supported) If you don&#8217;t use the docToolchain container image you have to install Java on your system. In case you have Java already installed, make sure JAVA_HOME is set. You may use dtcw to install the correct Java version, as shown in the next steps. 1.6.3. Run docToolchain in a container The docToolchain project provides a container image of approximately 900 MB from the Docker Hub container registry. The Dockerfile from which the image is created may be found at https://github.com/docToolchain/docker-image . To run docToolchain in a container you need an installed container engine. The best known container engine is Docker . If the container engine is installed you can Run your First Command . The docToolchain wrapper script in your project directory will detect the container engine and pull the docToolchain image on the first invocation. Use your custom docker image Some might need to create their own docker image to add additional tooling or configurations, e.g. proxy settings. In this case you can pass the image name via parameter image directly after docker : ./dtcw docker image &lt;image_name&gt; generateHTML .\\dtcw.ps1 docker image &lt;image_name&gt; generateHTML .\\dtcw.bat docker image &lt;image_name&gt; generateHTML Pass environment variables to docker containers To pass any environment variable to the docker container you can make use of an environment file . The environment file must have the name dtcw_docker.env and must be located in the same folder as dtcw . An example content is e.g.: # set environment variables for docToolchain docker container PROJECT=TEST_PROJECT TEAM=TEST_TEAM Pass additional parameter to docker containers To pass additional parameters to the docker container you can make use of the parameter extra_arguments followed by a string with the additional parameters. One usecase is to enable you to set environment variables to dynamic values. ./dtcw docker image &lt;image_name&gt; extra_arguments \"--env USER=${USERNAME} --env REPO_LOCATION=`git config remote.origin.url`\" generateHTML 1.6.4. Install docToolchain with dtcw Steps for MacOS/Linux/WSL2 with bash To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw install doctoolchain In case you have no Java installed you may use dtcw to install Java in a subdirectory of $HOME/.doctoolchain . ./dtcw install java Unable to locate Java Runtime - check your Bash environment If dtcw complains about not being able to locate a Java Runtime, make sure Java is found in your Bash shell, the shell used by dtcw . If you use dtcw from another shell like zsh , it may be that your shell finds the supported Java version but your bash setup doesn&#8217;t. In that case, please switch to bash and make sure that a supported Java version is found. Afterwards, you can switch back to your shell. Windows with Powershell To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw.ps1 install doctoolchain In case you have no Java installed you can use dtcw.ps1 to install Java: .\\dtcw.ps1 install java Windows with cmd.exe To install docToolchain in $HOME/.doctoolchain execute the following command. ./dtcw.bat install doctoolchain In case you have no Java installed you can use dtcw.ps1 to install Java: .\\dtcw.bat install java If the docToolchain installation finished successfully, you are ready to Run your First Command . 1.6.5. Install docToolchain with SDKMAN! TODO: description how to install docToolchain with SDKMAN! . 1.6.6. Run your First Command Call the docToolchain wrapper with tasks --group doctoolchain to show all tasks provided by docToolchain. Those tasks may be used when invoking the docToolchain wrapper script. The first time docToolchain is called, it downloads all necessary dependencies. Therefore, the execution of the command may take some time. Subsequent calls to docToolchain will be faster. ./dtcw tasks --group=doctoolchain dtcw 0.50 - 8061694f docToolchain 2.3.0 Available docToolchain environments: local (1) Environments with docToolchain [2.3.0]: local (2) Using environment: local (3) Using Java 17.0.6 [/home/john_doe/.doctoolchain/jdk/bin/java] (4) Downloading https://services.gradle.org/distributions/gradle-7.5.1-bin.zip (5) ..........10%..........20%..........30%...........40%..........50%..........60%..........70%...........80%..........90%..........100% Welcome to Gradle 7.5.1! Here are the highlights of this release: - Support for Java 18 - Support for building with Groovy 4 - Much more responsive continuous builds - Improved diagnostics for dependency resolution For more details see https://docs.gradle.org/7.5.1/release-notes.html To honour the JVM settings for this build a single-use Daemon process will be forked. See https://docs.gradle.org/7.5.1/userguide/gradle_daemon.html#sec:disabling_the_daemon. Daemon will be stopped at the end of the build &gt; Configure project : Config file '/code/docToolchainConfig.groovy' does not exist' (6) [ant:input] [ant:input] do you want me to create a default one for you? (y, n) y 1 List of available docToolchain environments. The output may vary depending on your system. In our example only the local environment is available since neither sdk nor docker was found. 2 Environments in which docToolchain s available. The output may vary depending on how you installed docToolchain. In our example docToolchain was found in the user&#8217;s local environment in $HOME/.doctoolchain . 3 Shows the used docToolchain environment. In case docToolchain is installed in more than one environment the wrapper script picks the environment in the following order: local , sdk , and then docker . 4 Location of the used Java. In our example Java was installed in the local environment with the docToolchain wrapper script. 5 docToolchain was invoked the first time, thus it is downloading its dependencies. 6 The docToolchain configuration file docToolchainConfig.groovy wasn&#8217;t found in the project repository. docToolchain asks if it should create a new one. .\\dtcw.ps1 tasks --group=doctoolchain dtcw.bat tasks --group=doctoolchain If you are behind a corporate proxy, you might need to consider build-script dependencies are fetched from a repository referenced by the property mavenRepository . By default, the value https://plugins.gradle.org/m2/ is used. When a repository requiring credentials is used the properties mavenUsername and mavenPassword can be set as well. Example command passing a custom maven repository with credentials from the command line DTC_OPTS=\"-PmavenRepository=your_maven_repo -PmavenUsername=your_username -PmavenPassword=your_pw\" ./dtcw tasks --group=doctoolchain --info 1.6.7. Configure docToolchain to Use Existing Documents If your project already has documents in AsciiDoc format, you&#8217;ll need to tell docToolchain where to find them. To do so, take a look at the created docToolchainConfig.groovy and update it. 1.6.8. Create a New Documentation Project from Scratch with Arc42 If you want to use the arc42 template in your project, you can get it in AsciiDoc format by using the following commands. Linux / WSL2 with bash ./dtcw downloadTemplate Windows with Powershell .\\dtcw.ps1 downloadTemplate Windows with cmd.exe dtcw.bat downloadTemplate 1.6.9. Generate HTML and PDF By now, the docToolchain wrapper dtcw should be in your project folder along with the arc42 template. Now Let&#8217;s render arc42 to HTML and PDF. To do so, run the commands below: Linux / WSL2 with bash ./dtcw generateHTML ./dtcw generatePDF Windows .\\dtcw.ps1 generateHTML .\\dtcw.ps1 generatePDF As a result, you will see the progress of your build together with some warnings which you can just ignore for the moment. The first build generated some files within the build : build |-- html5 | |-- arc42 | | `-- arc42.html | `-- images | |-- 05_building_blocks-EN.png | |-- 08-Crosscutting-Concepts-Structure-EN.png | `-- arc42-logo.png `-- pdf |-- arc42 | `-- arc42.pdf `-- images |-- 05_building_blocks-EN.png |-- 08-Crosscutting-Concepts-Structure-EN.png `-- arc42-logo.png Congratulations! If you see the same folder structure, you&#8217;ve just rendered the standard arc42 template as HTML and PDF! Please raise an issue on github if you didn&#8217;t get the right output. Blog-Posts: Behind the great Firewall , Enterprise AsciiDoctor 1.6.10. Upgrading to a New docToolchain Release If there is a new docToolchain release you wish to use, do the following: Open the docToolchain wrapper script ( dtcw , respective dtcw.ps1 and dtcw.bat ) in your favourite text editor and look for the line with DTC_VERSION which should be located near the start of the file: # See https://github.com/docToolchain/docToolchain/releases for available versions. # Set DTC_VERSION to \"latest\" to get the latest, yet unreleased docToolchain version. VERSION=2.1.0 Change it to match the desired release. In case you want to install docToolchain in local user environment install the new docToolchain release with the following command: ./dtcw install doctoolchain If you want to test a not-yet-released feature, you can set the DTC_VERSION to latest and dtcw will clone or pull the current default branch of the project. Please note this only works with a local copy, not with a Docker install. If you want to develop new features for docToolchain, you can also use latestdev as version. In this case, dtcw will try to clone the docToolchain repository with the ssh-git protocol to a fork in $HOME/.doctoolchain/docToolchain-latest . latest and latestdev currently only work with the bash version of the wrapper. 1.7. Using docToolchain to Build Docs 1 minute to read docToolchain implements many features via scripts, which you call through the command line. These scripts are called tasks in this documentation. Learn more about these scripts in the Tasks menu. 2. docToolchain Tasks .gravatar img { margin-left: 3px; border-radius: 4px; } 3. autobuildSite 1 minute to read 3.1. About This Task This script starts an endless loop which checks for changes to your docs source then re-runs the generateSite -task whenever it detects changes. The output will be logged to build/generateSite.log . 3.2. Source Show source code of bin/autobuildSite.bash or go directly to GitHub · docToolchain/bin/autobuildSite.bash . bin/autobuildSite.bash #!/bin/bash DIR_TO_WATCH='src/' #COMMAND='rm -r build || true &amp;&amp; mkdir -p build/microsite/output/images/ &amp;&amp; ./dtcw generateSite 2&gt;&amp;1 | tee build/generateSite.log' COMMAND='mkdir -p build/microsite/output/images/ &amp;&amp; ./dtcw generateSite 2&gt;&amp;1 | tee build/generateSite.log' #execute first time cp src/docs/images/ready.png build/microsite/output/images/status.png #eval $COMMAND #wait for changes and execute while true ; do watch --no-title --chgexit \"ls -lR ${DIR_TO_WATCH} | sha1sum\" cp src/docs/images/building.png build/microsite/output/images/status.png eval \"$COMMAND\" cp src/docs/images/ready.png build/microsite/output/images/status.png sleep 6 done .gravatar img { margin-left: 3px; border-radius: 4px; } 4. generateHTML 3 minutes to read 4.1. About This Task This is the standard Asciidoctor generator which is supported out of the box. The result is written to build/html5 (the HTML files need the images folder to be in the same directory to display correctly). 4.2. Generating Single-File HTML Output If you would like the generator to produce a single-file HTML, you can configure Asciidoctor to store the images inline as data-uri by setting :data-uri: in the config of your AsciiDoc file. But be warned. The file can quickly become very large and some browsers might struggle to render it. 4.3. Creating Text-Based Diagrams docToolchain is configured to use the asciidoctor-diagram plugin to create PlantUML diagrams. The plugin also supports many other text-based diagrams, but PlantUML is the most common. To use the plugin, specify your PlantUML code like this: .example diagram [plantuml, \"{plantUMLDir}demoPlantUML\", png] (1) ---- class BlockProcessor class DiagramBlock class DitaaBlock class PlantUmlBlock BlockProcessor &lt;|-- DiagramBlock DiagramBlock &lt;|-- DitaaBlock DiagramBlock &lt;|-- PlantUmlBlock ---- 1 The element of this list specifies the diagram tool plantuml to be used. The second element is the name of the image to be created, and the third specifies the image type. {plantUMLDir} ensures that PlantUML also works for the generatePDF task. Without it, generateHTML works fine, but the PDF will not contain the generated images. Be sure to specify a unique image name for each diagram, otherwise they will overwrite each other. The above example renders as: Figure 1. example diagram 4.4. Controlling Diagram Size If you want to control the size of the diagram in the output, configure the \"width\" attribute (in pixels) or the \"scale\" attribute (floating point ratio) passed to asciidoctor-diagram . The following example updates the diagram above by changing the declaration to one of the versions below: [plantuml, target=\"{plantUMLDir}demoPlantUMLWidth\", format=png, width=250] # rest of the diagram definition [plantuml, target=\"{plantUMLDir}demoPlantUMLScale\", format=png, scale=0.75] # rest of the diagram definition The output will render like this: Figure 2. example diagram (with specified width) Figure 3. example diagram (with specified scale) To work correctly, PlantUML needs Graphviz dot installed. If you can&#8217;t install it, use the Java-based version of the dot library instead. Just add !pragma layout smetana as the first line of your diagram definition. 4.5. Further Reading and Resources This blog post explains more about single-file HTML. Read this blog post to understand how to use PlantUML without Graphviz dot. Other helpful posts related to the generateHTML task: PlantUML with Gradle PlantUML with Asciidoctor-pdf PlantUML Revisited 4.6. Source Show source code of scripts/AsciiDocBasics.gradle or go directly to GitHub · docToolchain/scripts/AsciiDocBasics.gradle . scripts/AsciiDocBasics.gradle task generateHTML ( type: AsciidoctorTask, group: 'docToolchain', description: 'use html5 as asciidoc backend') { attributes ( 'plantUMLDir' : file(\"${docDir}/${config.outputPath}/html5\").toURI().relativize(new File(\"${docDir}/${config.outputPath}/html5/plantUML/\").toURI()).getPath(), ) // specify output folder explicitly to avoid cleaning targetDir from other generated content outputDir = file(targetDir + '/html5/') outputOptions { separateOutputDirs = false backends = ['html5'] } def sourceFilesHTML = findSourceFilesByType(['html']) // onlyIf { // sourceFilesHTML // } sources { sourceFilesHTML.each { include it.file File useFile = new File(srcDir, it.file) if (!useFile.exists()) { throw new Exception (\"\"\" The file $useFile in HTML config does not exist! Please check the configuration 'inputFiles' in $mainConfigFile.\"\"\") } } } resources { config.imageDirs.each { imageDir -&gt; from(new File(file(srcDir),imageDir)) logger.info ('imageDir: '+imageDir) into './images' } config.resourceDirs.each { resource -&gt; from(new File(file(srcDir),resource.source)) logger.info ('resource: '+resource.source) into resource.target } } doFirst { if (sourceFilesHTML.size()==0) { throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'html'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 5. copyThemes 1 minute to read 5.1. About This Task docToolchain provides you with a simple Twitter bootstrap default theme to get you started. You can use the copyThemes task to apply a different theme (either jBakeTheme or pdfTheme) to your project. Feel free to remove all files which should remain as the default and change all others. When you next run docToolchain, your theme files will be laid over the default theme in order to generate the PDF or site. 5.2. Source Show source code of scripts/copyThemes.gradle or go directly to GitHub · docToolchain/scripts/copyThemes.gradle . scripts/copyThemes.gradle //tag::copyThemes[] task copyThemes( description: 'copy some default files to your project for you to modify', group: 'docToolchain helper' ) { doFirst { } doLast { def color = { color, text -&gt; def colors = [black: 30, red: 31, green: 32, yellow: 33, blue: 34, magenta: 35, cyan: 36, white: 37] return new String((char) 27) + \"[${colors[color]}m${text}\" + new String((char) 27) + \"[0m\" } def lang = ant.input(message: \"${color 'green', 'What do you want me to copy?'}\", validargs: 'pdfTheme,jBakeTheme', addproperty: 'what') switch (ant.what) { case 'pdfTheme': def targetDir = new File(pdfThemeDir) /** if (targetDir.exists()) { println \"${targetDir.canonicalPath} already exists\" println \"in order to re-install the theme, please remove the folder first and re-run the script\" throw new RuntimeException(\"pdfTheme folder already exists\") } **/ targetDir.mkdirs() def source = new File(projectDir, 'template_config/pdfTheme') println source.canonicalPath println targetDir.canonicalPath copy { from new File(projectDir, 'template_config/pdfTheme') into targetDir } println \"pdfTheme copied into ${targetDir}\" break case 'jBakeTheme': def targetDir = new File(new File(docDir, inputPath), config.microsite.siteFolder?:'../site') /** if (targetDir.exists()) { println \"${targetDir.canonicalPath} already exists\" println \"in order to re-install the theme, please remove the folder first and re-run the script\" throw new RuntimeException(\"jBakeTheme folder already exists\") } **/ targetDir.mkdirs() copy { from new File(projectDir, 'src/site') into targetDir } def siteTheme = System.getenv('DTC_SITETHEME')?:\"\" def themeFolder = new File(projectDir, \"../themes/\" + siteTheme.md5()) copy { from(themeFolder) {} into targetDir } println \"jBakeTheme copied into ${targetDir.canonicalPath}\" break } } } //end::copyThemes[] .gravatar img { margin-left: 3px; border-radius: 4px; } 6. fixEncoding 1 minute to read 6.1. About This Task Whenever Asciidoctor has to process a file that is not UTF-8 encoded, Ruby tries to read it, then throws an error similar to this one: asciidoctor: FAILED: /home/demo/test.adoc: Failed to load AsciiDoc document - invalid byte sequence in UTF-8 Unfortunately, finding the incorrectly encoded file is difficult if a lot of includes:: are used, and Asciidoctor will only show the name of the main document. This is not Asciidoctor&#8217;s fault. The fault lies with the Ruby interpreter that sits underneath. The fixEncoding task crawls through all *.ad and *.adoc files and checks their encoding. If it comes across a file which is not UTF-8 encoded, it will rewrite it with the UTF-8 encoding. 6.2. Source Show source code of scripts/fixEncoding.gradle or go directly to GitHub · docToolchain/scripts/fixEncoding.gradle . scripts/fixEncoding.gradle import groovy.util.* import static groovy.io.FileType.* task fixEncoding( description: 'finds and converts non UTF-8 adoc files to UTF-8', group: 'docToolchain helper', ) { doLast { File sourceFolder = new File(\"${docDir}/${inputPath}\") println(\"sourceFolder: \" + sourceFolder.canonicalPath) sourceFolder.traverse(type: FILES) { file -&gt; if (file.name ==~ '^.*(ad|adoc|asciidoc)$') { CharsetToolkit toolkit = new CharsetToolkit(file); // guess the encoding def guessedCharset = toolkit.getCharset().toString().toUpperCase(); if (guessedCharset!='UTF-8') { def text = file.text file.write(text, \"utf-8\") println(\" converted ${file.name} from '${guessedCharset}' to 'UFT-8'\") } } } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 7. prependFilename 1 minute to read 7.1. About This Task When Asciidoctor renders a file, the file context only knows the name of the top-level AsciiDoc file. But an include file doesn&#8217;t know that it is being included. It simply gets the name of the master file and has no chance to get its own name as an attribute. This task crawls through all AsciiDoc files and prepends the name of the current file like this: :filename: 015_tasks/03_task_prependFilename.adoc This way, each file gets its own filename. This enables features like the inclusion of file contributors (see exportContributors-task). This task skips all files named config.* , _config.* , feedback.* and _feedback.* . 7.2. Source Show source code of scripts/prependFilename.gradle or go directly to GitHub · docToolchain/scripts/prependFilename.gradle . scripts/prependFilename.gradle import static groovy.io.FileType.* task prependFilename( description: 'crawls through all AsciiDoc files and prepends the name of the current file', group: 'docToolchain helper', ) { doLast { File sourceFolder = new File(\"${docDir}/${inputPath}\") println(\"sourceFolder: \" + sourceFolder.canonicalPath) sourceFolder.traverse(type: FILES) { file -&gt; if (file.name ==~ '^.*(ad|adoc|asciidoc)$') { if (file.name.split('[.]')[0] in [\"feedback\", \"_feedback\", \"config\", \"_config\"]) { println \"skipped \"+file.name } else { def text = file.getText('utf-8') def name = file.canonicalPath - sourceFolder.canonicalPath name = name.replace(\"\\\\\", \"/\").replaceAll(\"^/\", \"\") if (text.contains(\":filename:\")) { text = text.replaceAll(\":filename:.*\", \":filename: $name\") println \"updated \"+name } else { text = \":filename: $name\\n\" + text println \"added \"+name } file.write(text,'utf-8') } } } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 8. collectIncludes 2 minutes to read 8.1. About This Task This task crawls through your entire project looking for AsciiDoc files with a specific name pattern, then creates a single AsciiDoc file which includes only those files. When you create modular documentation, most includes are static. For example, the arc42-template has 12 chapters and a master template that includes those 12 chapters. Normally when you work with dynamic modules like ADRs (Architecture Decision Records) you create those files on the fly. Maybe not within your /src/docs folder, but alongside the code file for which you wrote the ADR. In order to include these files in your documentation, you have to add the file with its whole relative path to one of your AsciiDoc files. This task will handle it for you! Just stick to this file-naming pattern ^[A-Za-z]{3,}[-_].* (begin with at least three letters and a dash/underscore) and this task will collect the file and write it to your build folder. You only have to include this generated file from within your documentation. If you provide templates for the documents, those templates are skipped if the name matches the pattern ^.\\*[-\\_][tT]emplate [-\\_].* . 8.2. The Optional Parameter Configurations You can configure which files are found by the script be setting the parameters in the Config.groovy file. collectIncludes = [:] collectIncludes.with { fileFilter = \"adoc\" // define which files are considered. default: \"ad|adoc|asciidoc\" minPrefixLength = \"3\" // define what minimum length the prefix. default: \"3\" maxPrefixLength = \"3\" // define what maximum length the prefix. default: \"\" separatorChar = \"_\" // define the allowed separators after prefix. default: \"-_\" cleanOutputFolder = true // should the output folder be emptied before generation? default: false excludeDirectories = [] // define additional directories that should not be traversed. } 8.3. Example You have a file called: /src/java/yourCompany/domain/books/ADR-1-whyWeUseTheAISINInsteadOFISBN.adoc The task will collect this file and write another file called: /build/docs/_includes/ADR_includes.adoc &#8230;&#8203;which will look like this: include::../../../src/java/yourCompany/domain/books/ADR-1-whyWeUseTheAISINInsteadOFISBN.adoc[] Obviously, you&#8217;ll reap the most benefits if the task has several ADR files to collect. 😎 You can then include these files in your main documentation by using a single include: include::{targetDir}/docs/_includes/ADR_includes.adoc[] 8.4. Source Show source code of scripts/collectIncludes.gradle or go directly to GitHub · docToolchain/scripts/collectIncludes.gradle . scripts/collectIncludes.gradle import static groovy.io.FileType.* import static groovy.io.FileVisitResult.* import java.security.MessageDigest task collectIncludes( description: 'collect all ADRs as includes in one file', group: 'docToolchain' ) { doFirst { boolean cleanOutputFolder = config.collectIncludes.cleanOutputFolder?:false String outputFolder = targetDir + '/_includes' if (cleanOutputFolder){ delete fileTree(outputFolder) } new File(outputFolder).mkdirs() } doLast { //let's search the whole project for files, not only the docs folder //exclude typical system folders final defaultExcludedDirectories = [ '.git', '.github', '.idea', '.gradle', '.repo', '.svn', 'build', 'node_modules' ] //running as subproject? set scandir to main project String scanDir_save = scanDir if (project.name!=rootProject.name &amp;&amp; scanDir=='.') { scanDir = project(':').projectDir.path } if (docDir.startsWith('.')) { docDir = file(new File(projectDir, docDir).canonicalPath) } logger.info \"docToolchain&gt; docDir: ${docDir}\" logger.info \"docToolchain&gt; scanDir: ${scanDir}\" if (scanDir.startsWith('.')) { scanDir = file(new File(docDir, scanDir).canonicalPath) } else { scanDir = file(new File(scanDir, \"\").canonicalPath) } logger.info \"docToolchain&gt; scanDir: ${scanDir}\" logger.info \"docToolchain&gt; includeRoot: ${includeRoot}\" if (includeRoot.startsWith('.')) { includeRoot = file(new File(docDir, includeRoot).canonicalPath) } logger.info \"docToolchain&gt; includeRoot: ${includeRoot}\" File sourceFolder = scanDir println \"sourceFolder: \" + sourceFolder.canonicalPath def collections = [:] String fileFilter = config.collectIncludes.fileFilter?:\"ad|adoc|asciidoc\" String minPrefixLength = config.collectIncludes.minPrefixLength?:\"3\" String maxPrefixLength = config.collectIncludes.maxPrefixLength?:\"\" String separatorChar = config.collectIncludes.separatorChar?:\"-_\" def extraExcludeDirectories = config.collectIncludes.excludeDirectories?:[] def excludedDirectories = defaultExcludedDirectories + extraExcludeDirectories String prefixRegEx = \"[A-Za-z]{\" + minPrefixLength + \",\" + maxPrefixLength + \"}\" String separatorCharRegEx = \"[\" + separatorChar + \"]\" String fileFilterRegEx = \"^\" + prefixRegEx + separatorCharRegEx + \".*[.](\" + fileFilter + \")\\$\" logger.info \"considering files with this pattern: \" + fileFilterRegEx sourceFolder.traverse( type: FILES, preDir : { if (it.name in excludedDirectories) return SKIP_SUBTREE }, excludeNameFilter: excludedDirectories ) { file -&gt; if (file.name ==~ fileFilterRegEx) { String typeRegEx = \"^(\" + prefixRegEx + \")\" + separatorCharRegEx + \".*\\$\" def type = file.name.replaceAll(typeRegEx,'\\$1').toUpperCase() if (!collections[type]) { collections[type] = [] } logger.info \"file: \" + file.canonicalPath def fileName = (file.canonicalPath - scanDir.canonicalPath)[1..-1] if (file.name ==~ '^.*[Tt]emplate.*$') { logger.info \"ignore template file: \" + fileName } else { String includeFileRegEx = \"^.*\" + prefixRegEx + \"_includes.adoc\\$\" if (file.name ==~ includeFileRegEx) { logger.info \"ignore generated _includes files: \" + fileName } else { if ( fileName.startsWith('docToolchain') || fileName.replace(\"\\\\\", \"/\").matches('^.*/docToolchain/.*$')) { //ignore docToolchain as submodule } else { logger.info \"include corrected file: \" + fileName collections[type] &lt;&lt; fileName } } } } } println \"targetFolder: \" + (targetDir - docDir) logger.info \"targetDir - includeRoot: \" + (targetDir - includeRoot) def pathDiff = '../' * ((targetDir - docDir) .replaceAll('^/','') .replaceAll('/$','') .replaceAll(\"[^/]\",'').size()+1) logger.info \"pathDiff: \" + pathDiff collections.each { type, fileNames -&gt; if (fileNames) { def outFile = new File(targetDir + '/_includes', type + '_includes.adoc') logger.info outFile.canonicalPath-sourceFolder.canonicalPath outFile.write(\"// this is autogenerated\\n\") logger.info \"docToolchain&gt; Use Antora integration: ${useAntoraIntegration}\" fileNames.sort().each { fileName -&gt; if (useAntoraIntegration) { outFile.append(\"ifndef::optimize-content[]\\n\") outFile.append (\"include::../\" + pathDiff + scanDir_save + \"/\" + fileName.replace(\"\\\\\", \"/\")+\"[]\\n\") outFile.append(\"endif::optimize-content[]\\n\\n\") outFile.append(\"ifdef::optimize-content[]\\n\") outFile.append (\"include::example\\$\" + fileName.replace(\"\\\\\", \"/\").replace(\"${inputPath}/modules/ROOT/examples/\", \"\")+\"[]\\n\") outFile.append(\"endif::optimize-content[]\\n\\n\") } else { outFile.append (\"include::../\" + pathDiff + scanDir_save + \"/\" + fileName.replace(\"\\\\\", \"/\")+\"[]\\n\\n\") } } } } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 9. generatePDF 2 minutes to read 9.1. About This Task This task makes use of the asciidoctor-pdf plugin to render your documents as pretty PDF files. Files are written to build/pdf . The PDF is generated directly from your AsciiDoc sources. There is no need for an intermediate format or other tools. The result looks more like a nicely rendered book than a print-to-PDF HTML page. For a file to be rendered, it has to be configured in the doctoolchainConfig.groovy file. There you will find a section that looks like this: inputFiles = [ [file: 'manual.adoc', formats: ['html','pdf']], /** inputFiles **/ ] Add the files that you want to be rendered, along with the desired format. In this case pdf . Hint Why do you need to configure the files to be rendered? Asciidoctor renders all .adoc files by default. It doesn&#8217;t matter if they are the main documents or chapters you want to include. Most people only want to convert selected files to PDF, so that&#8217;s why you need to configure which ones. 9.2. Creating a Custom PDF Theme If you want to change colors, fonts or page headers and footers, you can do so by creating a custom-theme.yml file. Copy the file src/docs/pdfTheme/custom-theme.yml from docToolchain to your project and reference it from your main .adoc`file by setting the `:pdf-themesdir: . In addition, set the :pdf-theme: to the name of your theme. In this case custom . For example, insert the following at the top of your document to reference custom-theme.yml from the /pdfTheme folder. :pdf-themesdir: ../pdfTheme :pdf-theme: custom 9.3. Further Reading and Resources Learn how to modify a theme by reading asciidoctor-pdf theming guide . The Beyond HTML blog post is also an excellent resource if you want to dig a little deeper. 9.4. Source Show source code of scripts/AsciiDocBasics.gradle or go directly to GitHub · docToolchain/scripts/AsciiDocBasics.gradle . scripts/AsciiDocBasics.gradle task generatePDF ( type: AsciidoctorTask, group: 'docToolchain', description: 'use pdf as asciidoc backend') { attributes ( 'plantUMLDir' : file(\"${docDir}/${config.outputPath}/pdf/images/plantUML/\").path, ) outputDir = file(targetDir + '/pdf/') attributes ( 'data-uri': 'true', 'plantUMLDir' : file(\"${docDir}/${config.outputPath}/images/\").path, 'imagesoutdir' : file(\"${docDir}/${config.outputPath}/images/\").path ) def sourceFilesPDF = findSourceFilesByType(['pdf']) // onlyIf { // sourceFilesPDF // } sources { sourceFilesPDF.each { include it.file logger.info it.file File useFile = new File(srcDir, it.file) if (!useFile.exists()) { throw new Exception (\"\"\" The file $useFile in PDF config does not exist! Please check the configuration 'inputFiles' in $mainConfigFile.\"\"\") } } } outputOptions { backends = ['pdf'] } doFirst { if (sourceFilesPDF.size()==0) { throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'pdf'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } } /** //check if a remote pdfTheme is defined def pdfTheme = System.getenv('DTC_PDFTHEME') def themeFolder = pdfTheme.md5() if (pdfTheme) { //check if it is already installed //TODO: finish this... } **/ } .gravatar img { margin-left: 3px; border-radius: 4px; } 10. generateSite 8 minutes to read 10.1. About This Task When you have only one document, the output of generateHTML might meet your requirements. But as your documentation grows, and you have multiple documents, you will need a microsite which bundles all the information. The generateSite task uses jBake to create a static site with a landing page, a blog and search. 10.2. Pages The microsite is page-oriented, not document-oriented. If you have already organized your documents by chapter, use them as pages to create a great user experience. The arc42-template sources are a good example. To include a page in the microsite, add a metadata header to it. page metadata :jbake-menu: arc42 :jbake-title: Solution Strategy :jbake-order: 4 :jbake-type: page_toc :jbake-status: published :filename: 015_tasks/03_task_generateSite.adoc :toc: [[section-solution-strategy]] === Solution Strategy Here is an overview of each element: jbake-menu The top-level menu&#8217;s code for this page. Defaults to the top-level folder name (without the order prefix) of the .adoc file within the docDir . Example: if the top-level folder name is 10_news it will default to the value news . For each code, the display text and the order in the top-level menu can be configured . jbake-title The title to be displayed in the drop-down top-level menu. Defaults to the first headline of the file. jbake-order Applies a sort order to drop-down entries. Defaults to a prefixed file number, such as 04 _filename.adoc or to the prefixed number of the second-level folder name. When nothing is defined the default value is -1 or -987654321 for index pages. jbake-type The page type. Controls which template is used to render the page. You will mostly use page for a full-width page or page_toc for a page with a table of contents (toc) rendered on the left. Defaults to page_toc . jbake-status Either draft or published . Only published pages will be rendered. Defaults to published for files with a jbake-order and draft for files without jbake-order or files prefixed with _ . filename Required for edit and feedback links (coming soon). Defaults to the filename :-). ifndef Fixes the imagesdir according to the nesting level of your docs folder. Defaults to the main docDir/images . toc For :jbake-type: page_toc , you need this line to generate the toc. Start your pages with a == level headline. You can fix the level offset when you include the page in a larger document with include::chapter.adoc[leveloffset=+1] . 10.3. Configuration The configuration follows the convention-over-configuration approach. If you follow the conventions, you don&#8217;t have to configure anything. But if you want to, you can override the convention behaviour with a configuration. 10.3.1. Menu Navigation elements The navigation is organized with following elements: A top level menu. For each item of this top level menu, a section sidebar on the left. The location of a page in the top-level menu and in the section sidebar depends on: Its location in the folder structure Page attributes Site configurations Example: src/docs/ ├── 10_foo │   ├── 10_first.adoc │   └── 20_second.adoc └── 20_bar ├── 10_lorem.adoc ├── 20_ipsum │   ├── 10_topic-A.adoc │   └── 20_topic-B.adoc └── 30_delis ├── 10_one.adoc ├── 20_two.adoc └── index.adoc The top level folders ( 10_foo and 20_bar ) are used to determine to which menu-code the page belongs ( foo and bar , unless overridden by the :jbake-menu: inside each page). In the section sidebar, the navigation tree is determined by the folder structure. Folders are nodes in the sidebar tree. Each node can contain pages (leafs) or other folders (child nodes). The order is controlled by the prefix of the file or folder name (unless overridden by the :jbake-order: inside each page). When an index page is present (like 20_bar/30_delis/index.adoc in the example) then the navigation tree node corresponds to this index page (you can click on it and the title is taken from the page). When this index.adoc does not declare a specific order with :jbake-order: then the order of the parent folder (for the example: 30 because the folder is named 30_delis ). When the index page is absent (like there is no 20_bar/20_ipsum/index.adoc in the example) then the name of the folder is used to create the node, and you can not click on the node because no pages is associated with this node. You can still define the order with the name (for the example 20 because the folder is named 20_ipsum ). When there is no sub-folder, only a flat list of pages is created. When an index.adoc page is defined inside the top level folder (like: 10_foo/index.adoc or 20_bar/index.adoc ) then the page will be listed in the section navigation tree in the sidebar as any other regular page. By default, it will be the first element of the tree, unless the value is overridden by a :jbake-order: attribute. Configuring the top level menu The :jbake-menu: is only the code for the menu entry to be created. You can map these codes to menu entries through the configuration ( microsite -Section) in the following way: menu = [code1: 'Some Title 1', code2: 'Other Title 2', code3: '-'] When no mapping is defined in the configuration file, the code is used as title. The menu configuration is also impacting the display order. If you have four files, located in following folder structure: src/docs ├── code1 │   ├── demo1.adoc │   └── demo2.adoc └── code3    ├── demo3.adoc    └── _demo4.adoc Where demo1.adoc and demo3.adoc contain no :jbake-menu: header, demo2.adoc contains :jbake-menu: code2 , then: demo1.adoc will have a menu-code of code1 because it is located in the folder code1 . This code is translated through the configuration to the menu named Some Title 1 . demo2.adoc is in the same folder, but the :jbake-menu: attribute has a higher precedence which results in menu-code code2 . This code is translated through the configuration to the menu named Other Title 2 . demo3.adoc will have a menu-code code3 because it is located in the folder code3 . This code is translated through the configuration to the special menu - which will not be displayed. This is an easy way to hide a menu in the rendered microsite. _demo4.adoc starts with an underscore _ and thus will be handled as draft ( :jbake-status: draft ). It will not be rendered as part of any menu, but it will be available in the microsite as \"hidden\" _demo4-draft.html . Feel free to remove these draft renderings before you publish your microsite. 10.3.2. Links In the column on the right, links are driven by the values defined in docToolchainConfig.groovy . \"Improve this doc\": displayed when gitRepoUrl is set. \"Create an issue\": displayed when issueUrl is set. 10.3.3. Configuring the JBake plugin Behind the scene the generateSite task is relying on Jbake. In the docToolchainConfig.groovy it is possible to amend the configuration of the jbake gradle plugin: Add additional asciidoctorj plugins (add dependencies to the jbake configuration) Add additional asciidoctor attributes jbake configuration //customization of the Jbake gradle plugin used by the generateSite task jbake.with { // possibility to configure additional asciidoctorj plugins used by jbake plugins = [ ] // possibiltiy to configure additional asciidoctor attributes passed to the jbake task asciidoctorAttributes = [ ] } The plugins are retrieved from a repository (by default maven-central) configured with project property depsMavenRepository . When a repository requiring credentials is used the properties depsMavenUsername and depsMavenPassword can be set as well. 10.4. Templates and Style The jBake templates and CSS are hidden for convenience. The basic template uses Twitter Bootstrap 5 as its CSS framework. Use the copyThemes task to copy all hidden jBake resources to your project. You can then remove the resources you don&#8217;t need, and change those you want to change. copyThemes overwrites existing files, but because your code is safely managed using version control, this shouldn&#8217;t be a problem. 10.5. Landing Page Place an index.gsp page as your landing page in src/site/templates . This landing page is plain HTML5 styled with Twitter Bootstrap. The page header and footer are added by docToolchain. An example can be found at copyThemes or on GitHub . 10.6. Blog The microsite also contains a simple but powerful blog. Use it to inform your team about changes, as well as architecture decision records (ADRs). To create a new blog post, create a new file in src/docs/blog/&lt;year&gt;/&lt;post-name&gt;.adoc with the following template: blog post template :jbake-title: &lt;title-of your post&gt; :jbake-date: &lt;date formatted as 2021-02-28&gt; :jbake-type: post :jbake-tags: &lt;blog, asciidoc&gt; :jbake-status: published :imagesdir: ../../images = {jbake-title} {jbake-author} {jbake-date} &lt;insert your text here&gt; 10.7. Search The microsite does not have its own local search. But it does have a search input field which can be used to link to another search engine. 10.8. CI/CD When running in an automated build, set the environment variable DTC_HEADLESS to true or 1 . This stops docToolchain from asking to install the configured theme, and it will simply assume that you do want to install it. You can also avoid the theme downloading with every build by copying the themes folder from $HOME/.doctoolchain/themes to the corresponding folder in your build container. 10.9. Further Reading and Resources Read about the previewSite task here. 10.10. Source Show source code of scripts/generateSite.gradle or go directly to GitHub · docToolchain/scripts/generateSite.gradle . scripts/generateSite.gradle import groovy.util.* import static groovy.io.FileType.* buildscript { repositories { maven { credentials { username mavenUsername password mavenPassword } url mavenRepository } } dependencies { classpath libs.asciidoctorj.diagram } } repositories { maven { credentials { username depsMavenUsername password depsMavenPassword } url depsMavenRepository } } dependencies { jbake libs.asciidoctorj.diagram jbake libs.pebble config.jbake.plugins.each { plugin -&gt; jbake plugin } } apply plugin: 'org.jbake.site' def color = { color, text -&gt; def colors = [black: 30, red: 31, green: 32, yellow: 33, blue: 34, magenta: 35, cyan: 36, white: 37] return new String((char) 27) + \"[${colors[color]}m${text}\" + new String((char) 27) + \"[0m\" } jbake { version = '2.6.7' srcDirName = \"${targetDir}/microsite/tmp/site\" destDirName = \"${targetDir}/microsite/output\" configuration['asciidoctor.option.requires'] = \"asciidoctor-diagram\" config.microsite.each { key, value -&gt; configuration['site.'+key-'config.microsite.'] = value?:'' //println 'site.'+key-'config.microsite.' +\" = \"+ value } def micrositeContextPath = config.microsite.contextPath?:'/' configuration['asciidoctor.attributes'] = [ \"sourceDir=${targetDir}\", 'source-highlighter=prettify@', //'imagesDir=../images@', \"imagesoutDir=${targetDir}/microsite/output/images@\", \"imagesDir=${micrositeContextPath.endsWith('/') ? micrositeContextPath : micrositeContextPath.concat('/')}images@\", \"targetDir=${targetDir}\", \"docDir=${docDir}\", \"projectRootDir=${new File(docDir).canonicalPath}@\", ] if(config.jbake.asciidoctorAttributes) { config.jbake.asciidoctorAttributes.each { entry -&gt; configuration['asciidoctor.attributes'] &lt;&lt; entry } } } def prepareAndCopyTheme = { //copy internal theme println \"copy internal theme ${new File(projectDir, 'src/site').canonicalPath}\" copy { from('src/site') into(\"${targetDir}/microsite/tmp/site\") } //check if a remote pdfTheme is defined def siteTheme = System.getenv('DTC_SITETHEME')?:\"\" def themeFolder = new File(projectDir, \"../themes/\" + siteTheme.md5()) try { if (siteTheme) { println \"use siteTheme $siteTheme\" //check if it is already installed if (!themeFolder.exists()) { if (System.getenv('DTC_HEADLESS')) { ant.yesno = \"y\" } else { println \"${color 'green', \"\"\"\\nTheme '$siteTheme' is not installed yet. \"\"\"}\" def input = ant.input(message: \"\"\" ${color 'green', 'do you want me to download and install it to '} ${color 'green', ' ' + themeFolder.canonicalPath} ${color 'green', 'for you?'}\\n\"\"\", validargs: 'y,n', addproperty: 'yesno') } if (ant.yesno == \"y\") { themeFolder.mkdirs() download.run { src siteTheme dest new File(themeFolder, 'siteTheme.zip') overwrite true } copy { from zipTree(new File(themeFolder, 'siteTheme.zip')) into themeFolder } delete { delete new File(themeFolder, 'siteTheme.zip') } } else { println \"${color 'green', \"\"\"\\nI will continue without the theme for now... \"\"\"}\" siteTheme = \"\" } } //copy external theme if (siteTheme) { copy { from(themeFolder) {} into(\"${targetDir}/microsite/tmp/\") } //check if the config has to be updated // check if config still contains /** microsite **/ def configFile = new File(docDir, mainConfigFile) def configFileText = configFile.text if (configFileText.contains(\"/** start:microsite **/\")) { def configFragment = new File(targetDir,'/microsite/tmp/site/configFragment.groovy') if (configFragment.exists()) { println \"${color 'green', \"\"\" It seems that this theme is used for the first time in this project. Let's configure it! If you are unsure, change these settings later in your config file $configFile.canonicalPath \"\"\"}\" def comment = \"\" def conf = \"\" def example = \"\" def i = 0 configFragment.eachLine { line -&gt; if (line.trim()) { if (line.startsWith(\"//\")) { conf += \" \" + line + \"\\n\" def tmp = line[2..-1].trim() comment += color('green', tmp) + \"\\n\" if (tmp.toLowerCase().startsWith(\"example\")) { example = tmp.replaceAll(\"[^ ]* \", \"\") } } else { //only prompt if there is something to prompt if (line.contains(\"##\")) { def property = line.replaceAll(\"[ =].*\", \"\") if (!example) { example = config.microsite[property] } comment = color('blue', \"$property\") + \"\\n\" + comment if (example) { ant.input(message: comment, addproperty: 'res' + i, defaultvalue: example) } else { ant.input(message: comment, addproperty: 'res' + i) } (comment, example) = [\"\", \"\"] line = line.replaceAll(\"##.+##\", ant['res' + i]) conf += \" \" + line + \"\\n\" i++ } else { conf += \" \" + line + \"\\n\" } } } else { conf += \"\\n\" } } configFile.write(configFileText.replaceAll(\"(?sm)/[*][*] start:microsite [*][*]/.*/[*][*] end:microsite [*][*]/\", \"%%marker%%\").replace(\"%%marker%%\", conf)) println color('green', \"config written\\nopen ${targetDir}/microsite/output/index.html in your browser\\nto see your microsite!\") } //copy the dummy docs (blog, landing page) to the project repository copy { from(new File(themeFolder, 'site/doc')) {} into(new File(docDir, inputPath)) } } } } } catch (Exception e) { println color('red', e.message) if (e.message.startsWith(\"Not Found\")) { themeFolder.deleteDir() throw new GradleException(\"Couldn't find theme. Did you specify the right URL?\\n\"+e.message) } else { throw new GradleException(e.message) } } //copy project theme if (config.microsite.siteFolder) { def projectTheme = new File(new File(docDir, inputPath), config.microsite.siteFolder) println \"copy project theme ${projectTheme.canonicalPath}\" copy { from(projectTheme) {} into(\"${targetDir}/microsite/tmp/site\") } } } def convertAdditionalFormats = { if (config.microsite.additionalConverters) { File sourceFolder = new File(targetDir, '/microsite/tmp/site/doc') sourceFolder.traverse(type: FILES) { file -&gt; def extension = '.' + file.name.split(\"[.]\")[-1] if (config.microsite.additionalConverters[extension]) { def command = config.microsite.additionalConverters[extension].command def type = config.microsite.additionalConverters[extension].type def binding = new Binding([ file : file, config: config ]) def shell = new GroovyShell(getClass().getClassLoader(), binding) switch (type) { case 'groovy': shell.evaluate(command) break case 'groovyFile': shell.evaluate(new File(docDir, command).text) break case 'bash': if (command=='dtcw:rstToHtml.py') { // this is an internal script command = projectDir.canonicalPath+'/scripts/rstToHtml.py' } command = ['bash', '-c', command + ' \"' + file + '\"'] def process = command.execute([], new File(docDir)) process.waitFor() if (process.exitValue()) { def error = process.err.text println \"\"\" can't convert '${file.canonicalPath-docDir-'/build/microsite/tmp/site/doc'}': ${error} \"\"\" throw new Exception(\"\"\" can't convert '${file.canonicalPath-docDir-'/build/microsite/tmp/site/doc'}': ${error} \"\"\") } } } } } } def parseAsciiDocAttribs = { origText, jbake -&gt; def parseAttribs = true def text = \"\" def beforeToc = \"\" origText.eachLine { line -&gt; if (parseAttribs &amp;&amp; line.startsWith(\":jbake\")) { def parsedJbakeAttribute = (line - \":jbake-\").split(\": +\", 2) if(parsedJbakeAttribute.length != 2) { logger.warn(\"jbake-attribute is not valid or Asciidoc conform: $line\") logger.warn(\"jbake-attribute $line will be ignored, trying to continue...\") } else { jbake[parsedJbakeAttribute[0]] = parsedJbakeAttribute[1] } } else { if (line.startsWith(\"[\")) { // stop parsing jBake-attribs when a [source] - block starts which might contain those attribs as example parseAttribs = false } text += line+\"\\n\" //there are some attributes which have to be set before the toc if (line.startsWith(\":toc\") ) { beforeToc += line+\"\\n\" } } } return [text, beforeToc] } def parseOtherAttribs = { origText, jbake -&gt; if (origText.contains('~~~~~~')) { def parseAttribs = true def text = \"\" origText.eachLine { line -&gt; if (parseAttribs &amp;&amp; line.contains(\"=\")) { line = (line - \"jbake-\").split(\"=\", 2) jbake[line[0]] = line[1] } else { if (line.startsWith(\"~~~~~~\")) { // stop parsing jBake-attribs when delimiter shows up parseAttribs = false } else { text += line + \"\\n\" } } } return text } else { return origText } } def renderHeader = { fileName, jbake -&gt; def header = '' if (fileName.toLowerCase() ==~ '^.*(html|md)$') { jbake.each { key, value -&gt; if (key == 'order') { header += \"jbake-${key}=${(value ?: '1') as Integer}\\n\" } else { if (key in ['type', 'status']) { header += \"${key}=${value}\\n\" } else { header += \"jbake-${key}=${value}\\n\" } } } header += \"~~~~~~\\n\\n\" } else { jbake.each { key, value -&gt; if (key == 'order') { header += \":jbake-${key}: ${(value ?: '1') as Integer}\\n\" } else { header += \":jbake-${key}: ${value}\\n\" } } } return header } def fixMetaDataHeader = { //fix MetaData-Header File sourceFolder = new File(targetDir, '/microsite/tmp/site/doc') logger.info(\"sourceFolder: \" + sourceFolder.canonicalPath) sourceFolder.traverse(type: FILES) { file -&gt; if (file.name.toLowerCase() ==~ '^.*(ad|adoc|asciidoc|html|md)$') { if (file.name.startsWith(\"_\") || file.name.startsWith(\".\")) { //ignore } else { def origText = file.text //parse jbake attributes def text = \"\" def jbake = [ status: \"published\", order: -1, type: 'page_toc' ] if (file.name.toLowerCase() ==~ '^.*(md|html)$') { // we don't have a toc for md or html jbake.type = 'page' } def beforeToc = \"\" if (file.name.toLowerCase() ==~ '^.*(ad|adoc|asciidoc)$') { (text, beforeToc) = parseAsciiDocAttribs(origText, jbake) } else { text = parseOtherAttribs(origText, jbake) } def name = file.canonicalPath - (sourceFolder.canonicalPath+File.separator) if (File.separator=='\\\\') { name = name.split(\"\\\\\\\\\") } else { name = name.split(\"/\") } if (name.size()&gt;1) { if (!jbake.menu) { jbake.menu = name[0] if (jbake.menu ==~ /[0-9]+[-_].*/) { jbake.menu = jbake.menu.split(\"[-_]\", 2)[1] } } def docname = name[-1] if (docname ==~ /[0-9]+[-_].*/) { jbake.order = docname.split(\"[-_]\",2)[0] docname = docname.split(\"[-_]\",2)[1] } if (name.size() &gt; 2) { if ((jbake.order as Integer)==0) { // let's take the order from the second level dir or file and not the file def secondLevel = name[1] if (secondLevel ==~ /[0-9]+[-_].*/) { jbake.order = secondLevel.split(\"[-_]\",2)[0] } } else { if (((jbake.order?:'1') as Integer) &gt; 0) { // } else { jbake.status = \"draft\" } } } if (jbake.order==-1 &amp;&amp; docname.startsWith('index')) { jbake.order = -987654321 // special 'magic value' given to index pages. jbake.status = \"published\" } // news blog if (jbake.order==-1 &amp;&amp; jbake.type=='post') { jbake.order = 0 try { jbake.order = Date.parse(\"yyyy-MM-dd\", jbake.date).time / 100000 } catch ( Exception e) { System.out.println \"unparsable date ${jbake.date} in $name\" } jbake.status = \"published\" } def leveloffset = 0 if (file.name.toLowerCase() ==~ '^.*(ad|adoc|asciidoc)$') { text.eachLine { line -&gt; if (!jbake.title &amp;&amp; line ==~ \"^=+ .*\") { jbake.title = (line =~ \"^=+ (.*)\")[0][1] def level = (line =~ \"^(=+) .*\")[0][1] if (level == \"=\") { leveloffset = 1 } } } } else { if (file.name.toLowerCase() ==~ '^.*(html)$') { if (!jbake.title) { text.eachLine { line -&gt; if (!jbake.title &amp;&amp; line ==~ \"^&lt;h[1-9]&gt;.*&lt;/h.*\") { jbake.title = (line =~ \"^&lt;h[1-9]&gt;(.*)&lt;/h.*\")[0][1] } } } } else { // md if (!jbake.title) { text.eachLine { line -&gt; if (!jbake.title &amp;&amp; line ==~ \"^#+ .*\") { jbake.title = (line =~ \"^#+ (.*)\")[0][1] } } } } } if (!jbake.title) { jbake.title = docname } if (leveloffset==1) { //leveloffset needed // we always start with \"==\" not with \"=\" // only used for adoc text = text.replaceAll(\"(?ms)^(=+) \", '$1= ') } if (config.microsite.customConvention) { def binding = new Binding([ file : file, sourceFolder : sourceFolder, config: config, headers : jbake ]) def shell = new GroovyShell(getClass().getClassLoader(), binding) shell.evaluate(config.microsite.customConvention) System.out.println jbake } def header = renderHeader(file.name, jbake) if (file.name.toLowerCase() ==~ '^.*(ad|adoc|asciidoc)$') { file.write(header + \"\\nifndef::dtc-magic-toc[]\\n:dtc-magic-toc:\\n$beforeToc\\n\\n:toc: left\\n\\n++++\\n&lt;!-- endtoc --&gt;\\n++++\\nendif::[]\\n\" + text, \"utf-8\") } else { file.write(header + \"\\n\" + text, \"utf-8\") } } } } } } task generateSite( group: 'docToolchain', description: 'generate a microsite using jBake.') { doLast { new File(\"${targetDir}/microsite/tmp\").mkdirs() println new File(\"${targetDir}/microsite/tmp/\").canonicalPath prepareAndCopyTheme() //copy docs copy { from(new File(docDir, inputPath)) {} into(\"${targetDir}/microsite/tmp/site/doc\") } // if configured, convert restructuredText or anything else convertAdditionalFormats() // convention over configuration fixMetaDataHeader() } } task previewSite( group: 'docToolchain', dependsOn: [], description: 'preview your Microsite', ) { doLast { println(\"previewSite command has been deprecated.\") println(\"To preview your site, open ${targetDir}/microsite/output/index.html in your browser.\") println(\"To read alternative ways to preview your site, please consult the documentation.\") } } previewSite.dependsOn(generateSite) previewSite.mustRunAfter(bake) task copyImages(type: Copy) { config.imageDirs.each { imageDir -&gt; from(new File (new File(docDir, inputPath),imageDir)) {} logger.info ('imageDir: '+imageDir) into(\"${targetDir}/microsite/output/images\") } config.resourceDirs.each { resource -&gt; from(new File(file(srcDir),resource.source)) logger.info ('resource: '+resource.source) into(\"${targetDir}/microsite/output/\" + resource.target) } } bake.dependsOn copyImages generateSite.finalizedBy bake .gravatar img { margin-left: 3px; border-radius: 4px; } 11. generateDocbook 1 minute to read 11.1. About This Task A helper task, generateDocbook generates the intermediate format for convertToDocx &lt;&lt;&gt;&gt; and convertToEpub . 11.2. Source Show source code of scripts/AsciiDocBasics.gradle or go directly to GitHub · docToolchain/scripts/AsciiDocBasics.gradle . scripts/AsciiDocBasics.gradle task generateDocbook ( type: AsciidoctorTask, group: 'docToolchain', description: 'use docbook as asciidoc backend') { def sourceFilesDOCBOOK = findSourceFilesByType(['docbook', 'epub', 'docx']) // onlyIf { // sourceFilesDOCBOOK // } sources { sourceFilesDOCBOOK.each { include it.file logger.info it.file File useFile = new File(srcDir, it.file) if (!useFile.exists()) { throw new Exception (\"\"\" The file $useFile in DOCBOOK config does not exist! Please check the configuration 'inputFiles' in $mainConfigFile.\"\"\") } } } outputOptions { backends = ['docbook'] } outputDir = file(targetDir+'/docbook/') doFirst { if (sourceFilesDOCBOOK.size()==0) { throw new Exception (\"\"\" &gt;&gt; No source files defined for type of '[docbook, epub, docx]'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 12. generateDeck 1 minute to read 12.1. About This Task This task makes use of the asciidoctor-reveal.js backend to render your documents into an HTML-based presentation. It creates a PowerPoint presentation, then enriches it by adding reveal.js slide definitions in AsciiDoc to the speaker notes. For best results, use this task with the exportPPT task. 12.1.1. Configure RevealJs docToolchain comes with some opinionated, sane defaults for RevealJs. You can overwrite any of them and provide further configuration as per asciidoctor-reveal.js documentation. 12.2. Source Show source code of scripts/AsciiDocBasics.gradle or go directly to GitHub · docToolchain/scripts/AsciiDocBasics.gradle . scripts/AsciiDocBasics.gradle task generateDeck ( type: AsciidoctorJRevealJSTask, group: 'docToolchain', description: 'use revealJs as asciidoc backend to create a presentation') { // corresponding Asciidoctor reveal.js config // :revealjs_theme: theme = 'black' revealjsOptions { // :revealjs_hideAddressBar: hideAddressBarOnMobile = 'true' // :revealjs_history: pushToHistory = 'true' // :revealjs_progress: progressBar = 'true' // :revealjs_slideNumber: slideNumber = 'true' // :revealjs_touch: touchMode = 'true' // :revealjs_transition: transition = 'linear' } attributes ( 'idprefix': 'slide-', 'idseparator': '-', 'docinfo1': '', ) def sourceFilesREVEAL = findSourceFilesByType(['revealjs']) sources { sourceFilesREVEAL.each { include it.file logger.info it.file File useFile = new File(srcDir, it.file) if (!useFile.exists()) { throw new Exception (\"\"\" The file $useFile in REVEAL config does not exist! Please check the configuration 'inputFiles' in $mainConfigFile.\"\"\") } } } outputDir = file(targetDir+'/decks/') resources { from(sourceDir) { include 'images/**' } into(\"\") logger.info \"${docDir}/${config.outputPath}/images\" } doFirst { if (sourceFilesREVEAL.size()==0) { throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'revealjs'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } } } generateDeck.dependsOn asciidoctorGemsPrepare .gravatar img { margin-left: 3px; border-radius: 4px; } 13. publishToConfluence 10 minutes to read 13.1. About This Task This task takes a generated HTML file, splits it by headline, and pushes it to your instance of Confluence . This lets you use the docs-as-code approach even if your organisation insists on using Confluence as its main document repository. From the 01.01.2024 on, Atlassian turns off API V1 for Confluence Cloud, if there is a V2 equivalent. docToolchain versions from 3.1 on support API V2. If you are using an older version of docToolchain, you&#8217;ll need to upgrade to a newer version. To enable API V2 , set useV1Api to false in the Confluence section of the docToolchain configuration file. Currently, docToolchain only has full support for the old Confluence editor. The new editor is not fully supported yet. You can use the new editor, but you may experience some unexpected layout issues/ changes. To make use of the new editor you need to set enforceNewEditor to true in the Confluence section of the docToolchain configuration file. 13.2. Special Features 13.2.1. Easy Code Block Conversion [source] -blocks are converted to code-macro blocks in Confluence. Confluence supports a very limited list of languages supported for code block syntax highlighting. When specifying an unknown language, it would even display an error. Therefore, some transformation is applied. If no language is given in the source block, it is explicitly set to plain text (because the default would be Java that might not always apply). Some known and common AsciiDoc source languages are mapped to Confluence code block languages. source target note json yml produces an acceptable highlighting shell bash only a specific shell is supported yaml yml different name of language If the language of the source block is not supported by Confluence, it is set to plain text as fallback to avoid the error. Get a list of valid languages (and learn how to add others) here . 13.2.2. Minimal Impact on Non-Techie Confluence Users Only pages and images that changed between task runs are published, and only those changes are notified to page watchers, cutting down on 'spam'. 13.2.3. Keywords Automatically Attached as Labels :keywords: are attached as labels to every Confluence page generated using the publishToConfluence task. See Atlassian&#8217;s own guidelines on labels . Several keywords are allowed, and they must be separated by commas. For example: :keywords: label_1, label-2, label3, &#8230;&#8203; . Labels (keywords) must not contain a space character. Use either '_' or '-'. 13.3. Configuration You configure the publishToConfluence task in the file docToolchainConfig.groovy. It is located in the root of your project folder. We try to make the configuration self-explanatory, but below is some more information about each config option. input is an array of files to upload to Confluence with the ability to configure a different parent page for each file. 13.4. Attributes file : absolute or relative path to the asciidoc generated html file to be exported url : absolute URL to an asciidoc generated html file to be exported ancestorName (optional): the name of the parent page in Confluence as string; this attribute has priority over ancestorId, but if page with given name doesn&#8217;t exist, ancestorId will be used as a fallback ancestorId (optional): the id of the parent page in Confluence as string; leave this empty if a new parent shall be created in the space The following four keys can also be used in the global section below spaceKey : page specific variable for the key of the confluence space to write to case sensitive! If the case is not correct, it can be that new page will be created but can&#8217;t be updated in the next run. subpagesForSections (optional): The number of nested sub-pages to create. Default is '1'. '0' means creating all on one page. The following migration for removed configuration can be used. allInOnePage = true is the same as subpagesForSections = 0 allInOnePage = false &amp;&amp; createSubpages = false is the same as subpagesForSections = 1 allInOnePage = false &amp;&amp; createSubpages = true is the same as subpagesForSections = 2 pagePrefix (optional): page specific variable, the pagePrefix will be a prefix for the page title and it&#8217;s sub-pages use this if you only have access to one confluence space but need to store several pages with the same title - a different pagePrefix will make them unique pageSuffix (optional): same usage as prefix but appended to the title and it&#8217;s subpages only 'file' or 'url' is allowed. If both are given, 'url' is ignored ancestorId The page ID of the parent page where you want your docs to be published. Go to this page, click Edit and the required ID will show up in the URL. Specify the ID as a string within the config file. api Endpoint of the confluenceAPI (REST) to be used and looks like https://[yourServer]/[context] , while [context] is optional. If you use Confluence Cloud, you can omit the context. If you use Confluence Server, you may need to set a context, depending on your Confluence configuration. rateLimit (since 3.2.0), The rate limit for Confluence requests. Default is 10 requests per second. useV1Api This feature is available for docToolchain &gt;= 3.1 only If you set this to false , ensure the api config is set to https://[yourCloudDomain] . (Mind no context given here) If you are using Confluence Cloud, you can set this to false to use the new API V2. If you are using Confluence Server, you can set this to true to use the old API V1. If you are using Confluence Cloud and set this to false , you will get an error message, once Atlassian turns off API V1 (starting 01.01.2024). enforceNewEditor Atlassian is currently rolling out a new editor for Confluence. If you want to use the new editor, you can set this to true . If you are using the old editor, you can set this to false . If you are using the new editor, you may experience some unexpected layout issues/ changes, since the new editor has yet no feature parity and therefore may be incompatible. disableToC This boolean configuration determines whether the table of contents (ToC) is disabled on the page once uploaded to Confluence. false by default, so the ToC is active. pagePrefix/pageSuffix Confluence can&#8217;t handle two pages with the same name - even with different casing (lowercase, UPPERCASE, a mix). This script matches pages regardless of case and refuses to replace a page whose name differs from an existing page only by casing. Ideally, you should create a new Confluence space for each piece of larger documentation. If you are restricted and can&#8217;t create new spaces, you can use pagePrefix / pageSuffix to define a prefix/suffix for the doc so that it doesn&#8217;t conflict with other page names. pageVersionComment Set an optional comment for the new page version in Confluence. credentials For security reasons it is highly recommended to store your credentials in a separate file outside the Git repository, such as in your Home folder. To authenticate with username and API token, use: credentials = \"user:${new File(\"/users/me/apitoken\").text}\" or credentials = \"user:${new File(\"/users/me/apitoken\").text}\"`.bytes.encodeBase64().toString()` to &#8230;&#8203;&#8230;&#8203;.. You can create an API-token in your profile . To authenticate with username and password, use: credentials = &#8230;&#8203;&#8230;&#8203; You can also set your username, password of apitoken as an environment variable. You then do the following: 1. Open the file that contains the environment variables: a. On a Mac, go to your Home folder and open the file .zpfrofile. 2. &#8230;&#8203;. If you wish to simplify the injection of credentials from external sources, do the following: 1. In docToolchainConfig.groovy, do not enter the credentials. Make sure the credentials are escaped. 2. Create a gradle.properties file in the project or home directory. See the gradle user guide . 3. Open the file, and put the variables in it: - confluenceUser=myusername, and on a new line - confluencePass=myuserpassword apikey In situations where you have to use full user authorisation because of internal Confluence permission handling, you&#8217;ll need to add the API-token in addition to the credentials. The API-token cannot be added to the credentials because it&#8217;s used for user and password exchange. Therefore, the API-token can be added as parameter apikey , which makes the addition of the token a separate header field with key: keyId and value of apikey . An example (including storing of the real value outside this configuration) is: apikey = \"${new File(\"/home/me/apitoken\").text}\" . bearerToken You can pass a Confluence Personal Access Token as the bearerToken . It is an alternative to credentials . Do not confuse it with apiKey . extraPageContent If you need to prefix your pages with a warning stating that 'this is generated content', this is where you do it. enableAttachments If value is set to true , any links to local file references will be uploaded as attachments. The current implementation only supports a single folder, the name of which will be used as a prefix to validate whether your file should be uploaded. If you enable this feature, and use a folder which starts with 'attachment', an adaption of this prefix is required. pageLimit Limits the number of pages retrieved from the server to check if a page with this name already exists. jiraServerId Only required if you are using Jira on-premise. If you are using Jira cloud you do not need to set this value. Stores the Jira server ID that your Confluence instance is connected to. If a value is set, all anchors pointing to a Jira ticket will be replaced by the Confluence Jira macro. How-To find your Jira server ID please check the Atlassian documentation . All files to attach will need to be linked inside the document: link:attachment/myfolder/myfile.json[My API definition] attachmentPrefix Stores the expected foldername of your output directory. Default is attachment . proxy If you need to provide proxy to access Confluence, you can set a map with the keys host (e.g. 'my.proxy.com' ), port (e.g. '1234' ) and schema (e.g. 'http' ) of your proxy. useOpenapiMacro If this option is present and equal to confluence-open-api or swagger-open-api then any source block marked with class openapi will be wrapped in the Elitesoft Swagger Editor macro (see Elitesoft Swagger Editor ). The key depends on the version of the macro. For backward compatibility, if this option is present and equal to true , then again the Elitesoft Swagger Editor macro will be used. If this option is present and equal to \"open-api\" then any source block marked with class openapi will be wrapped in Open API Documentation for Confluence macro: (see Open API Documentation for Confluence ). A download source (yaml) button is shown by default. Using the plugin can be handled on different ways. copy/paste the content of the YAML file to the plugin without linking to the origin source by using the url to the YAML file [source.openapi,yaml] ---- \\include::https://my-domain.com/path-to-yaml[] ---- copy/paste the content of the YAML file to the plugin without linking to the origin source by using a YAML file in your project structure: [source.openapi,yaml] ---- \\include::my-yaml-file.yaml[] ---- create a link between the plugin and the YAML file without copying the content into the plugin. The advantage following this way is that even in case the API specification is changed without re-generating the documentation, the new version of the configuration is used in Confluence. [source.openapi,yaml,role=\"url:https://my-domain.com/path-to-yaml\"] ---- \\include::https://my-domain.com/path-to-yaml[] ---- publishToConfluence.gradle //Configureation for publishToConfluence confluence = [:] // 'input' is an array of files to upload to Confluence with the ability // to configure a different parent page for each file. // // Attributes // - 'file': absolute or relative path to the asciidoc generated html file to be exported // - 'url': absolute URL to an asciidoc generated html file to be exported // - 'ancestorName' (optional): the name of the parent page in Confluence as string; // this attribute has priority over ancestorId, but if page with given name doesn't exist, // ancestorId will be used as a fallback // - 'ancestorId' (optional): the id of the parent page in Confluence as string; leave this empty // if a new parent shall be created in the space // Set it for every file so the page scanning is done only for the given ancestor page trees. // // The following four keys can also be used in the global section below // - 'spaceKey' (optional): page specific variable for the key of the confluence space to write to // - 'subpagesForSections' (optional): The number of nested sub-pages to create. Default is '1'. // '0' means creating all on one page. // The following migration for removed configuration can be used. // 'allInOnePage = true' is the same as 'subpagesForSections = 0' // 'allInOnePage = false &amp;&amp; createSubpages = false' is the same as 'subpagesForSections = 1' // 'allInOnePage = false &amp;&amp; createSubpages = true' is the same as 'subpagesForSections = 2' // - 'pagePrefix' (optional): page specific variable, the pagePrefix will be a prefix for the page title and it's sub-pages // use this if you only have access to one confluence space but need to store several // pages with the same title - a different pagePrefix will make them unique // - 'pageSuffix' (optional): same usage as prefix but appended to the title and it's subpages // only 'file' or 'url' is allowed. If both are given, 'url' is ignored confluence.with { input = [ [ file: \"build/docs/html5/arc42-template-de.html\" ], ] // endpoint of the confluenceAPI (REST) to be used // https://[yourServer] api = 'https://[yourServer]' // requests per second for confluence API calls rateLimit = 10 // Additionally, spaceKey, subpagesForSections, pagePrefix and pageSuffix can be globally defined here. The assignment in the input array has precedence // the key of the confluence space to write to spaceKey = 'asciidoc' // if true, all pages will be created using the new editor v2 // enforceNewEditor = false // variable to determine how many layers of sub pages should be created subpagesForSections = 1 // the pagePrefix will be a prefix for each page title // use this if you only have access to one confluence space but need to store several // pages with the same title - a different pagePrefix will make them unique pagePrefix = '' pageSuffix = '' /* WARNING: It is strongly recommended to store credentials securely instead of commiting plain text values to your git repository!!! Tool expects credentials that belong to an account which has the right permissions to to create and edit confluence pages in the given space. Credentials can be used in a form of: - passed parameters when calling script (-PconfluenceUser=myUsername -PconfluencePass=myPassword) which can be fetched as a secrets on CI/CD or - gradle variables set through gradle properties (uses the 'confluenceUser' and 'confluencePass' keys) Often, same credentials are used for Jira &amp; Confluence, in which case it is recommended to pass CLI parameters for both entities as -Pusername=myUser -Ppassword=myPassword */ //optional API-token to be added in case the credentials are needed for user and password exchange. //apikey = \"[API-token]\" // HTML Content that will be included with every page published // directly after the TOC. If left empty no additional content will be // added // extraPageContent = '&lt;ac:structured-macro ac:name=\"warning\"&gt;&lt;ac:parameter ac:name=\"title\" /&gt;&lt;ac:rich-text-body&gt;This is a generated page, do not edit!&lt;/ac:rich-text-body&gt;&lt;/ac:structured-macro&gt; extraPageContent = '' // enable or disable attachment uploads for local file references enableAttachments = false // default attachmentPrefix = attachment - All files to attach will require to be linked inside the document. // attachmentPrefix = \"attachment\" // Optional proxy configuration, only used to access Confluence // schema supports http and https // proxy = [host: 'my.proxy.com', port: 1234, schema: 'http'] // Optional: specify which Confluence OpenAPI Macro should be used to render OpenAPI definitions // possible values: [\"confluence-open-api\", \"open-api\", \"swagger-open-api\", true]. true is the same as \"confluence-open-api\" for backward compatibility // useOpenapiMacro = \"confluence-open-api\" } 13.5. CSS Styling Some AsciiDoctor features depend on specific CSS style definitions. Unless these styles are defined, some formatting that is present in the HTML version will not be represented when published to Confluence. To configure Confluence to include additional style definitions: Log in to Confluence as a space admin. Go to the desired space. Select Space tools &gt; Look and Feel &gt; Stylesheet . Click Edit then enter the desired style definitions. Click Save . The default style definitions can be found in the AsciiDoc project as asciidoctor-default.css . You will most likely NOT want to include the entire thing, as some of the definitions are likely to disrupt Confluence&#8217;s layout. The following style definitions are Confluence-compatible, and will enable the use of the built-in roles ( big / small , underline / overline / line-through , COLOR / COLOR -background for the sixteen HTML color names ): .big{font-size:larger} .small{font-size:smaller} .underline{text-decoration:underline} .overline{text-decoration:overline} .line-through{text-decoration:line-through} .aqua{color:#00bfbf} .aqua-background{background-color:#00fafa} .black{color:#000} .black-background{background-color:#000} .blue{color:#0000bf} .blue-background{background-color:#0000fa} .fuchsia{color:#bf00bf} .fuchsia-background{background-color:#fa00fa} .gray{color:#606060} .gray-background{background-color:#7d7d7d} .green{color:#006000} .green-background{background-color:#007d00} .lime{color:#00bf00} .lime-background{background-color:#00fa00} .maroon{color:#600000} .maroon-background{background-color:#7d0000} .navy{color:#000060} .navy-background{background-color:#00007d} .olive{color:#606000} .olive-background{background-color:#7d7d00} .purple{color:#600060} .purple-background{background-color:#7d007d} .red{color:#bf0000} .red-background{background-color:#fa0000} .silver{color:#909090} .silver-background{background-color:#bcbcbc} .teal{color:#006060} .teal-background{background-color:#007d7d} .white{color:#bfbfbf} .white-background{background-color:#fafafa} .yellow{color:#bfbf00} .yellow-background{background-color:#fafa00} 13.6. Source Show source code of scripts/publishToConfluence.gradle or go directly to GitHub · docToolchain/scripts/publishToConfluence.gradle . scripts/publishToConfluence.gradle task publishToConfluence( description: 'publishes the HTML rendered output to confluence', group: 'docToolchain' ) { doLast { logger.info(\"docToolchain&gt; docDir: \"+docDir) config.confluence.api = findProperty(\"confluence.api\")?:config.confluence.api //TODO default should be false, if the V1 has been removed in cloud config.confluence.useV1Api = findProperty(\"confluence.useV1Api\") != null ? findProperty(\"confluence.useV1Api\") : config.confluence.useV1Api != [:] ? config.confluence.useV1Api :true Asciidoc2ConfluenceTask.From(config, docDir).execute() } } Show source code of core/src/main/groovy/org/docToolchain/scripts/asciidoc2confluence.groovy or go directly to GitHub · docToolchain/core/src/main/groovy/org/docToolchain/scripts/asciidoc2confluence.groovy . core/src/main/groovy/org/docToolchain/scripts/asciidoc2confluence.groovy package org.docToolchain.scripts /** * THIS SCRIPT HAS BEEN DEPRECATED. IT IS NOT USED ANYMORE. PLEASE REFER TO THE NEW Asciidoc2ConfluenceTask * IMPLEMENTATION INSTEAD. REFERENCE ONLY. */ import org.docToolchain.atlassian.transformer.HtmlTransformer /** * Created by Ralf D. Mueller and Alexander Heusingfeld * https://github.com/rdmueller/asciidoc2confluence * * this script expects an HTML document created with AsciiDoctor * in the following style (default AsciiDoctor output) * &lt;div class=\"sect1\"&gt; * &lt;h2&gt;Page Title&lt;/h2&gt; * &lt;div class=\"sectionbody\"&gt; * &lt;div class=\"sect2\"&gt; * &lt;h3&gt;Sub-Page Title&lt;/h3&gt; * &lt;/div&gt; * &lt;div class=\"sect2\"&gt; * &lt;h3&gt;Sub-Page Title&lt;/h3&gt; * &lt;/div&gt; * &lt;/div&gt; * &lt;/div&gt; * &lt;div class=\"sect1\"&gt; * &lt;h2&gt;Page Title&lt;/h2&gt; * ... * &lt;/div&gt; * */ /* Additions for issue #342 marked as #342-dierk42 ;-) */ // some dependencies import org.jsoup.nodes.Document import org.jsoup.nodes.Element import org.jsoup.nodes.Entities import org.jsoup.nodes.TextNode import org.jsoup.select.Elements import groovy.transform.Field import java.nio.charset.Charset import java.nio.file.Path import java.security.MessageDigest import static groovy.io.FileType.FILES import org.docToolchain.atlassian.confluence.clients.ConfluenceClientV1 import org.docToolchain.atlassian.confluence.clients.ConfluenceClientV2 import org.docToolchain.configuration.ConfigService import org.docToolchain.atlassian.confluence.ConfluenceService @Field ConfigService configService = new ConfigService(config) @Field ConfluenceService confluenceService = new ConfluenceService(configService) @Field def confluenceClient = configService.getConfigProperty(\"confluence.useV1Api\") ? new ConfluenceClientV1(configService) : new ConfluenceClientV2(configService) @Field def CDATA_PLACEHOLDER_START = '&lt;cdata-placeholder&gt;' @Field def CDATA_PLACEHOLDER_END = '&lt;/cdata-placeholder&gt;' @Field def baseUrl def allPages // #938-mksiva: global variable to hold input spaceKey passed in the Config.groovy def spaceKeyInput // configuration def confluenceSpaceKey def confluenceSubpagesForSections @Field def confluencePagePrefix @Field def confluencePageSuffix //def baseApiPath = new URI(config.confluence.api).path // helper functions def MD5(String s) { MessageDigest.getInstance(\"MD5\").digest(s.bytes).encodeHex().toString() } def parseAdmonitionBlock(block, String type) { content = block.select(\".content\").first() titleElement = content.select(\".title\") titleText = '' if(titleElement != null) { titleText = \"&lt;ac:parameter ac:name=\\\"title\\\"&gt;${titleElement.text()}&lt;/ac:parameter&gt;\" titleElement.remove() } block.after(\"&lt;ac:structured-macro ac:name=\\\"${type}\\\"&gt;${titleText}&lt;ac:rich-text-body&gt;${content}&lt;/ac:rich-text-body&gt;&lt;/ac:structured-macro&gt;\") block.remove() } /* #342-dierk42 add labels to a Confluence page. Labels are taken from :keywords: which are converted as meta tags in HTML. Building the array: see below Confluence allows adding labels only after creation of a page. Therefore we need extra API calls. Currently the labels are added one by one. Suggestion for improvement: Build a label structure of all labels an place them with one call. Replaces exisiting labels. No harm Does not check for deleted labels when keywords are deleted from source document! */ def addLabels = { def pageId, def labelsArray -&gt; // Attach each label in a API call of its own. The only prefix possible // in our own Confluence is 'global' labelsArray.each { label -&gt; label_data = [ prefix : 'global', name : label ] confluenceClient.addLabel(pageId, label_data) println \"added label \" + label + \" to page ID \" + pageId } } def uploadAttachment = { def pageId, String url, String fileName, String note -&gt; def is def localHash if (url.startsWith('http')) { is = new URL(url).openStream() //build a hash of the attachment localHash = MD5(new URL(url).openStream().text) } else { is = new File(url).newDataInputStream() //build a hash of the attachment localHash = MD5(new File(url).newDataInputStream().text) } def attachment = confluenceClient.getAttachment(pageId, fileName) if (attachment?.results) { // attachment exists. need an update? if (confluenceClient.attachmentHasChanged(attachment, localHash)) { //hash is different -&gt; attachment needs to be updated confluenceClient.updateAttachment(pageId, attachment.results[0].id, is, fileName, note, localHash) println \" updated attachment\" } } else { confluenceClient.createAttachment(pageId, is, fileName, note, localHash) } } def realTitle(pageTitle){ confluencePagePrefix + pageTitle + confluencePageSuffix } def rewriteMarks (body) { // Confluence strips out mark elements. Replace them with default formatting. body.select('mark').wrap('&lt;span style=\"background:#ff0;color:#000\"&gt;&lt;/style&gt;').unwrap() } // #352-LuisMuniz: Helper methods // Fetch all pages of the defined config ancestorsIds. Only keep relevant info in the pages Map // The map is indexed by lower-case title def retrieveAllPages = { String spaceKey -&gt; // #938-mksiva: added a condition spaceKeyInput is null, if it is null, it means that, space key is different, so re fetch all pages. if (allPages != null &amp;&amp; spaceKeyInput == null) { println \"allPages already retrieved\" allPages } else { def pageIds = [] def checkSpace = false int pageLimit = config.confluence.pageLimit ? config.confluence.pageLimit : 100 config.confluence.input.each { input -&gt; if (!input.ancestorId) { // if one ancestorId is missing we should scan the whole space checkSpace = true; return } pageIds.add(input.ancestorId) } println (\".\") if(checkSpace) { allPages = confluenceClient.fetchPagesBySpaceKey(spaceKey, pageLimit) } else { allPages = confluenceClient.fetchPagesByAncestorId(pageIds, pageLimit) } allPages } } // Retrieve a page by id with contents and version def retrieveFullPage = { String id -&gt; println(\"retrieving page with id \" + id) confluenceClient.retrieveFullPageById(id) } //if a parent has been specified, check whether a page has the same parent. boolean hasRequestedParent(Map existingPage, String requestedParentId) { if (requestedParentId) { existingPage.parentId == requestedParentId } else { true } } def rewriteDescriptionLists(body) { def TAGS = [ dt: 'th', dd: 'td' ] body.select('dl').each { dl -&gt; // WHATWG allows wrapping dt/dd in divs, simply unwrap them dl.select('div').each { it.unwrap() } // group dts and dds that belong together, usually it will be a 1:1 relation // but HTML allows for different constellations def rows = [] def current = [dt: [], dd: []] rows &lt;&lt; current dl.select('dt, dd').each { child -&gt; def tagName = child.tagName() if (tagName == 'dt' &amp;&amp; current.dd.size() &gt; 0) { // dt follows dd, start a new group current = [dt: [], dd: []] rows &lt;&lt; current } current[tagName] &lt;&lt; child.tagName(TAGS[tagName]) child.remove() } rows.each { row -&gt; def sizes = [dt: row.dt.size(), dd: row.dd.size()] def rowspanIdx = [dt: -1, dd: sizes.dd - 1] def rowspan = Math.abs(sizes.dt - sizes.dd) + 1 def max = sizes.dt if (sizes.dt &lt; sizes.dd) { max = sizes.dd rowspanIdx = [dt: sizes.dt - 1, dd: -1] } (0..&lt;max).each { idx -&gt; def tr = dl.appendElement('tr') ['dt', 'dd'].each { type -&gt; if (sizes[type] &gt; idx) { tr.appendChild(row[type][idx]) if (idx == rowspanIdx[type] &amp;&amp; rowspan &gt; 1) { row[type][idx].attr('rowspan', \"${rowspan}\") } } else if (idx == 0) { tr.appendElement(TAGS[type]).attr('rowspan', \"${rowspan}\") } } } } dl.wrap('&lt;table&gt;&lt;/table&gt;') .unwrap() } } def rewriteInternalLinks (body, anchors, pageAnchors) { // find internal cross-references and replace them with link macros body.select('a[href]').each { a -&gt; def href = a.attr('href') if (href.startsWith('#')) { def anchor = href.substring(1) def pageTitle = anchors[anchor] ?: pageAnchors[anchor] if (pageTitle &amp;&amp; a.text()) { // as Confluence insists on link texts to be contained // inside CDATA, we have to strip all HTML and // potentially loose styling that way. a.html(a.text()) a.wrap(\"&lt;ac:link${anchors.containsKey(anchor) ? ' ac:anchor=\"' + anchor + '\"' : ''}&gt;&lt;/ac:link&gt;\") .before(\"&lt;ri:page ri:content-title=\\\"${realTitle pageTitle}\\\"/&gt;\") .wrap(\"&lt;ac:plain-text-link-body&gt;${CDATA_PLACEHOLDER_START}${CDATA_PLACEHOLDER_END}&lt;/ac:plain-text-link-body&gt;\") .unwrap() } } } } def rewriteJiraLinks = { body -&gt; // find links to jira tickets and replace them with jira macros body.select('a[href]').each { a -&gt; def href = a.attr('href') if (href.startsWith(config.jira.api + \"/browse/\")) { def ticketId = a.text() a.before(\"\"\"&lt;ac:structured-macro ac:name=\\\"jira\\\" ac:schema-version=\\\"1\\\"&gt; &lt;ac:parameter ac:name=\\\"key\\\"&gt;${ticketId}&lt;/ac:parameter&gt; &lt;ac:parameter ac:name=\\\"serverId\\\"&gt;${config.confluence.jiraServerId}&lt;/ac:parameter&gt; &lt;/ac:structured-macro&gt;\"\"\") a.remove() } } } def rewriteOpenAPI (org.jsoup.nodes.Element body) { if (config.confluence.useOpenapiMacro == true || config.confluence.useOpenapiMacro == 'confluence-open-api') { body.select('div.openapi pre &gt; code').each { code -&gt; def parent=code.parent() def rawYaml=code.wholeText() code.parent() .wrap('&lt;ac:structured-macro ac:name=\"confluence-open-api\" ac:schema-version=\"1\" ac:macro-id=\"1dfde21b-6111-4535-928a-470fa8ae3e7d\"&gt;&lt;/ac:structured-macro&gt;') .unwrap() code.wrap(\"&lt;ac:plain-text-body&gt;${CDATA_PLACEHOLDER_START}${CDATA_PLACEHOLDER_END}&lt;/ac:plain-text-body&gt;\") .replaceWith(new TextNode(rawYaml)) } } else if (config.confluence.useOpenapiMacro == 'swagger-open-api') { body.select('div.openapi pre &gt; code').each { code -&gt; def parent=code.parent() def rawYaml=code.wholeText() code.parent() .wrap('&lt;ac:structured-macro ac:name=\"swagger-open-api\" ac:schema-version=\"1\" ac:macro-id=\"f9deda8a-1375-4488-8ca5-3e10e2e4ee70\"&gt;&lt;/ac:structured-macro&gt;') .unwrap() code.wrap(\"&lt;ac:plain-text-body&gt;${CDATA_PLACEHOLDER_START}${CDATA_PLACEHOLDER_END}&lt;/ac:plain-text-body&gt;\") .replaceWith(new TextNode(rawYaml)) } } else if (config.confluence.useOpenapiMacro == 'open-api') { def includeURL=null for (Element e : body.select('div .listingblock.openapi')) { for (String s : e.className().split(\" \")) { if (s.startsWith(\"url\")) { //include the link to the URL for the macro includeURL = s.replace('url:', '') } } } body.select('div.openapi pre &gt; code').each { code -&gt; def parent=code.parent() def rawYaml=code.wholeText() code.parent() .wrap('&lt;ac:structured-macro ac:name=\"open-api\" ac:schema-version=\"1\" data-layout=\"default\" ac:macro-id=\"4302c9d8-fca4-4f14-99a9-9885128870fa\"&gt;&lt;/ac:structured-macro&gt;') .unwrap() if (includeURL!=null) { code.before('&lt;ac:parameter ac:name=\"url\"&gt;'+includeURL+'&lt;/ac:parameter&gt;') } else { //default: show download button code.before('&lt;ac:parameter ac:name=\"showDownloadButton\"&gt;true&lt;/ac:parameter&gt;') code.wrap(\"&lt;ac:plain-text-body&gt;${CDATA_PLACEHOLDER_START}${CDATA_PLACEHOLDER_END}&lt;/ac:plain-text-body&gt;\") .replaceWith(new TextNode(rawYaml)) } } } } def getEmbeddedImageData(src){ def imageData = src.split(\"[;:,]\") def fileExtension = imageData[1].split(\"/\")[1] // treat svg+xml as svg to be able to create a file from the embedded image // more MIME types: https://www.iana.org/assignments/media-types/media-types.xhtml#image if(fileExtension == \"svg+xml\"){ fileExtension = \"svg\" } return Map.of( \"fileExtension\", fileExtension, \"encoding\", imageData[2], \"encodedContent\", imageData[3] ) } def handleEmbeddedImage(basePath, fileName, fileExtension, encodedContent) { def imageDir = \"images/\" if(config.imageDirs.size() &gt; 0){ def dir = config.imageDirs.find { it -&gt; def configureImagesDir = it.replace('./', '/') Path.of(basePath, configureImagesDir, fileName).toFile().exists() } if(dir != null){ imageDir = dir.replace('./', '/') } } if(!Path.of(basePath, imageDir, fileName).toFile().exists()){ println \"Could not find embedded image at a known location\" def embeddedImagesLocation = \"/confluence/images/\" new File(basePath + embeddedImagesLocation).mkdirs() def imageHash = MD5(encodedContent) println \"Embedded Image Hash \" + imageHash def image = new File(basePath + embeddedImagesLocation + imageHash + \".${fileExtension}\") if(!image.exists()){ println \"Creating image at \" + basePath + embeddedImagesLocation image.withOutputStream {output -&gt; output.write(encodedContent.decodeBase64())} } fileName = imageHash + \".${fileExtension}\" return Map.of( \"filePath\", image.canonicalPath, \"fileName\", fileName ) } else { return Map.of( \"filePath\", basePath + imageDir + fileName, \"fileName\", fileName ) } } //modify local page in order to match the internal confluence storage representation a bit better //definition lists are not displayed by confluence, so turn them into tables //body can be of type Element or Elements def parseBody(body, anchors, pageAnchors) { def uploads = [] rewriteOpenAPI body body.select('div.paragraph').unwrap() body.select('div.ulist').unwrap() //body.select('div.sect3').unwrap() [ 'note':'info', 'warning':'warning', 'important':'warning', 'caution':'note', 'tip':'tip' ].each { adType, cType -&gt; body.select('.admonitionblock.'+adType).each { block -&gt; parseAdmonitionBlock(block, cType) } } //special for the arc42-template body.select('div.arc42help').select('.content') .wrap('&lt;ac:structured-macro ac:name=\"expand\"&gt;&lt;/ac:structured-macro&gt;') .wrap('&lt;ac:rich-text-body&gt;&lt;/ac:rich-text-body&gt;') .wrap('&lt;ac:structured-macro ac:name=\"info\"&gt;&lt;/ac:structured-macro&gt;') .before('&lt;ac:parameter ac:name=\"title\"&gt;arc42&lt;/ac:parameter&gt;') .wrap('&lt;ac:rich-text-body&gt;&lt;p&gt;&lt;/p&gt;&lt;/ac:rich-text-body&gt;') body.select('div.arc42help').unwrap() body.select('div.title').wrap(\"&lt;strong&gt;&lt;/strong&gt;\").before(\"&lt;br /&gt;\").wrap(\"&lt;div&gt;&lt;/div&gt;\") body.select('div.listingblock').wrap(\"&lt;p&gt;&lt;/p&gt;\").unwrap() // see if we can find referenced images and fetch them new File(\"tmp/images/.\").mkdirs() // find images, extract their URLs for later uploading (after we know the pageId) and replace them with this macro: // &lt;ac:image ac:align=\"center\" ac:width=\"500\"&gt; // &lt;ri:attachment ri:filename=\"deployment-context.png\"/&gt; // &lt;/ac:image&gt; body.select('img').each { img -&gt; def src = img.attr('src') def imgWidth = img.attr('width')?:500 def imgAlign = img.attr('align')?:\"center\" //it is not an online image, so upload it to confluence and use the ri:attachment tag if(!src.startsWith(\"http\")) { def sanitizedBaseUrl = baseUrl.toString().replaceAll('\\\\\\\\','/').replaceAll('/[^/]*$','/') def newUrl def fileName //it is an embedded image if(src.startsWith(\"data:image\")){ def imageData = getEmbeddedImageData(src) def fileExtension = imageData.get(\"fileExtension\") def encodedContent = imageData.get(\"encodedContent\") fileName = img.attr('alt').replaceAll(/\\s+/,\"_\").concat(\".${fileExtension}\") def embeddedImage = handleEmbeddedImage(sanitizedBaseUrl, fileName, fileExtension, encodedContent) newUrl = embeddedImage.get(\"filePath\") fileName = embeddedImage.get(\"fileName\") }else { newUrl = sanitizedBaseUrl + src fileName = java.net.URLDecoder.decode((src.tokenize('/')[-1]),\"UTF-8\") } newUrl = java.net.URLDecoder.decode(newUrl,\"UTF-8\") println \" image: \"+newUrl uploads &lt;&lt; [0,newUrl,fileName,\"automatically uploaded\"] img.after(\"&lt;ac:image ac:align=\\\"${imgAlign}\\\" ac:width=\\\"${imgWidth}\\\"&gt;&lt;ri:attachment ri:filename=\\\"${fileName}\\\"/&gt;&lt;/ac:image&gt;\") } // it is an online image, so we have to use the ri:url tag else { img.after(\"&lt;ac:image ac:align=\\\"imgAlign\\\" ac:width=\\\"${imgWidth}\\\"&gt;&lt;ri:url ri:value=\\\"${src}\\\"/&gt;&lt;/ac:image&gt;\") } img.remove() } if(config.confluence.enableAttachments){ attachmentPrefix = config.confluence.attachmentPrefix ? config.confluence.attachmentPrefix : 'attachment' body.select('a').each { link -&gt; def src = link.attr('href') println \" attachment src: \"+src //upload it to confluence and use the ri:attachment tag if(src.startsWith(attachmentPrefix)) { def newUrl = baseUrl.toString().replaceAll('\\\\\\\\','/').replaceAll('/[^/]*$','/')+src def fileName = java.net.URLDecoder.decode((src.tokenize('/')[-1]),\"UTF-8\") newUrl = java.net.URLDecoder.decode(newUrl,\"UTF-8\") uploads &lt;&lt; [0,newUrl,fileName,\"automatically uploaded non-image attachment by docToolchain\"] def uriArray=fileName.split(\"/\") def pureFilename = uriArray[uriArray.length-1] def innerhtml = link.html() link.after(\"&lt;ac:structured-macro ac:name=\\\"view-file\\\" ac:schema-version=\\\"1\\\"&gt;&lt;ac:parameter ac:name=\\\"name\\\"&gt;&lt;ri:attachment ri:filename=\\\"${pureFilename}\\\"/&gt;&lt;/ac:parameter&gt;&lt;/ac:structured-macro&gt;\") link.after(\"&lt;ac:link&gt;&lt;ri:attachment ri:filename=\\\"${pureFilename}\\\"/&gt;&lt;ac:plain-text-link-body&gt; &lt;![CDATA[\\\"${innerhtml}\\\"]]&gt;&lt;/ac:plain-text-link-body&gt;&lt;/ac:link&gt;\") link.remove() } } } if(config.confluence.jiraServerId){ rewriteJiraLinks body } rewriteMarks body rewriteDescriptionLists body rewriteInternalLinks body, anchors, pageAnchors //not really sure if must check here the type String bodyString = body if(body instanceof Element){ bodyString = body.html() } Element saneHtml = new Document(\"\") .outputSettings(new Document.OutputSettings().syntax(Document.OutputSettings.Syntax.xml).prettyPrint(false)) .html(bodyString) def pageString = new HtmlTransformer().transformToConfluenceFormat(saneHtml) return Map.of( \"page\", pageString, \"uploads\", uploads ) } def generateAndAttachToC(localPage) { def content if(config.confluence.disableToC){ def prefix = (config.confluence.extraPageContent?:'') content = prefix+localPage }else{ def default_toc = '&lt;p&gt;&lt;ac:structured-macro ac:name=\"toc\"/&gt;&lt;/p&gt;' def prefix = (config.confluence.tableOfContents?:default_toc)+(config.confluence.extraPageContent?:'') content = prefix+localPage def default_children = '&lt;p&gt;&lt;ac:structured-macro ac:name=\"children\"&gt;&lt;ac:parameter ac:name=\"sort\"&gt;creation&lt;/ac:parameter&gt;&lt;/ac:structured-macro&gt;&lt;/p&gt;' content += (config.confluence.tableOfChildren?:default_children) } def localHash = MD5(localPage) content += '&lt;ac:placeholder&gt;hash: #'+localHash+'#&lt;/ac:placeholder&gt;' return content } // the create-or-update functionality for confluence pages // #342-dierk42: added parameter 'keywords' def pushToConfluence = { pageTitle, pageBody, parentId, anchors, pageAnchors, keywords -&gt; parentId = parentId?.toString() def deferredUpload = [] String realTitleLC = realTitle(pageTitle).toLowerCase() String realTitle = realTitle(pageTitle) //try to get an existing page def parsedBody = parseBody(pageBody, anchors, pageAnchors) localPage = parsedBody.get(\"page\") deferredUpload.addAll(parsedBody.get(\"uploads\")) def localHash = MD5(localPage) localPage = generateAndAttachToC(localPage) // #938-mksiva: Changed the 3rd parameter from 'config.confluence.spaceKey' to 'confluenceSpaceKey' as it was always taking the default spaceKey // instead of the one passed in the input for each row. def pages = retrieveAllPages(confluenceSpaceKey) println(\"pages retrieved\") // println \"Suche nach vorhandener Seite: \" + pageTitle Map existingPage = pages[realTitleLC] def page if (existingPage) { if (hasRequestedParent(existingPage, parentId)) { page = retrieveFullPage(existingPage.id as String) } else { page = null } } else { page = null } // println \"Gefunden: \" + page.id + \" Titel: \" + page.title if (page) { println \"found existing page: \" + page.id +\" version \"+page.version.number //extract hash from remote page to see if it is different from local one def remotePage = page.body.storage.value.toString().trim() def remoteHash = remotePage =~ /(?ms)hash: #([^#]+)#/ remoteHash = remoteHash.size()==0?\"\":remoteHash[0][1] // println \"remoteHash: \" + remoteHash // println \"localHash: \" + localHash if (remoteHash == localHash) { println \"page hasn't changed!\" deferredUpload.each { uploadAttachment(page?.id, it[1], it[2], it[3]) } deferredUpload = [] // #324-dierk42: Add keywords as labels to page. if (keywords) { addLabels(page.id, keywords) } return page.id } else { def newPageVersion = (page.version.number as Integer) + 1 confluenceClient.updatePage( page.id, realTitle, confluenceSpaceKey, localPage, newPageVersion, config.confluence.pageVersionComment ?: '', parentId ) println \"&gt; updated page \"+page.id deferredUpload.each { uploadAttachment(page.id, it[1], it[2], it[3]) } deferredUpload = [] // #324-dierk42: Add keywords as labels to page. if (keywords) { addLabels(page.id, keywords) } return page.id } } else { //#352-LuisMuniz if the existing page's parent does not match the requested parentId, fail if (existingPage &amp;&amp; !hasRequestedParent(existingPage, parentId)) { throw new IllegalArgumentException(\"Cannot create page, page with the same \" + \"title=${existingPage.title} \" + \"with id=${existingPage.id} already exists in the space. \" + \"A Confluence page title must be unique within a space, consider specifying a 'confluencePagePrefix' in ConfluenceConfig.groovy\") } //create a page page = confluenceClient.createPage( realTitle, confluenceSpaceKey, localPage, config.confluence.pageVersionComment ?: '', parentId ) println \"&gt; created page \"+page?.id deferredUpload.each { uploadAttachment(page?.id, it[1], it[2], it[3]) } deferredUpload = [] // #324-dierk42: Add keywords as labels to page. if (keywords) { addLabels(page?.id, keywords) } return page?.id } } def parseAnchors(page) { def anchors = [:] page.body.select('[id]').each { anchor -&gt; def name = anchor.attr('id') anchors[name] = page.title anchor.before(\"&lt;ac:structured-macro ac:name=\\\"anchor\\\"&gt;&lt;ac:parameter ac:name=\\\"\\\"&gt;${name}&lt;/ac:parameter&gt;&lt;/ac:structured-macro&gt;\") } anchors } def pushPages pushPages = { pages, anchors, pageAnchors, labels -&gt; pages.each { page -&gt; page.title = page.title.trim() println page.title def id = pushToConfluence page.title, page.body, page.parent, anchors, pageAnchors, labels page.children*.parent = id // println \"Push children von id \" + id pushPages page.children, anchors, pageAnchors, labels // println \"Ende Push children von id \" + id } } def recordPageAnchor(head) { def a = [:] if (head.attr('id')) { a[head.attr('id')] = head.text() } a } def promoteHeaders(tree, start, offset) { (start..7).each { i -&gt; tree.select(\"h${i}\").tagName(\"h${i-offset}\").before('&lt;br /&gt;') } } def retrievePageIdByName = { String name -&gt; def data = confluenceClient.retrievePageIdByName(name, confluenceSpaceKey) return data?.results?.get(0)?.id } def getPagesRecursive(Element element, String parentId, Map anchors, Map pageAnchors, int level, int maxLevel) { def pages = [] element.select(\"div.sect${level}\").each { sect -&gt; def title = sect.select(\"h${level + 1}\").text() pageAnchors.putAll(recordPageAnchor(sect.select(\"h${level + 1}\"))) Elements pageBody if (level == 1) { pageBody = sect.select('div.sectionbody') } else { pageBody = new Elements(sect) pageBody.select(\"h${level + 1}\").remove() } def currentPage = [ title: title, body: pageBody, children: [], parent: parentId ] if (maxLevel &gt; level) { currentPage.children.addAll(getPagesRecursive(sect, null, anchors, pageAnchors, level + 1, maxLevel)) pageBody.select(\"div.sect${level + 1}\").remove() } else { pageBody.select(\"div.sect${level + 1}\").unwrap() } promoteHeaders sect, level + 2, level + 1 pages &lt;&lt; currentPage anchors.putAll(parseAnchors(currentPage)) } return pages } def getPages(Document dom, String parentId, int maxLevel) { def anchors = [:] def pageAnchors = [:] def sections = pages = [] def title = dom.select('h1').text() if (maxLevel &lt;= 0) { dom.select('div#content').each { pageBody -&gt; pageBody.select('div.sect2').unwrap() promoteHeaders pageBody, 2, 1 def page = [title : title, body : pageBody, children: [], parent : parentId] pages &lt;&lt; page sections = page.children parentId = null anchors.putAll(parseAnchors(page)) } } else { // let's try to select the \"first page\" and push it to confluence dom.select('div#preamble div.sectionbody').each { pageBody -&gt; pageBody.select('div.sect2').unwrap() def preamble = [ title: title, body: pageBody, children: [], parent: parentId ] pages &lt;&lt; preamble sections = preamble.children parentId = null anchors.putAll(parseAnchors(preamble)) } sections.addAll(getPagesRecursive(dom, parentId, anchors, pageAnchors, 1, maxLevel)) } return [pages, anchors, pageAnchors] } if(config.confluence.inputHtmlFolder) { htmlFolder = \"${docDir}/${config.confluence.inputHtmlFolder}\" println \"Starting processing files in folder: \" + config.confluence.inputHtmlFolder def dir = new File(htmlFolder) dir.eachFileRecurse (FILES) { fileName -&gt; if (fileName.isFile()){ def map = [file: config.confluence.inputHtmlFolder+fileName.getName()] config.confluence.input.add(map) } } } config.confluence.input.each { input -&gt; // TODO check why this is necessary if(input.file) { input.file = confluenceService.checkAndBuildCanonicalFileName(input.file) // assignend, but never used in pushToConfluence(...) (fixed here) // #938-mksiva: assign spaceKey passed for each file in the input spaceKeyInput = input.spaceKey confluenceSpaceKey = input.spaceKey ?: config.confluence.spaceKey confluenceCreateSubpages = (input.createSubpages != null) ? input.createSubpages : config.confluence.createSubpages confluenceAllInOnePage = (input.allInOnePage != null) ? input.allInOnePage : config.confluence.allInOnePage if (!(confluenceCreateSubpages instanceof ConfigObject &amp;&amp; confluenceAllInOnePage instanceof ConfigObject)) { println \"ERROR:\" println \"Deprecated configuration, migrate as follows:\" println \"allInOnePage = true -&gt; subpagesForSections = 0\" println \"allInOnePage = false &amp;&amp; createSubpages = false -&gt; subpagesForSections = 1\" println \"allInOnePage = false &amp;&amp; createSubpages = true -&gt; subpagesForSections = 2\" throw new RuntimeException(\"config problem\") } confluenceSubpagesForSections = (input.subpagesForSections != null) ? input.subpagesForSections : config.confluence.subpagesForSections if (confluenceSubpagesForSections instanceof ConfigObject) { confluenceSubpagesForSections = 1 } // hard to read in case of using :sectnums: -&gt; so we add a suffix confluencePagePrefix = input.pagePrefix ?: config.confluence.pagePrefix // added confluencePageSuffix = input.pageSuffix ?: config.confluence.pageSuffix confluencePreambleTitle = input.preambleTitle ?: config.confluence.preambleTitle if (!(confluencePreambleTitle instanceof ConfigObject)) { println \"ERROR:\" println \"Deprecated configuration, use first level heading in document instead of preambleTitle configuration\" throw new RuntimeException(\"config problem\") } File htmlFile = new File(input.file) baseUrl = htmlFile Document dom = confluenceService.parseFile(htmlFile) // if ancestorName is defined try to find machingAncestorId in confluence def retrievedAncestorId if (input.ancestorName) { // Retrieve a page id by name retrievedAncestorId = retrievePageIdByName(input.ancestorName) println(\"Retrieved pageId for given ancestorName '${input.ancestorName}' is ${retrievedAncestorId}\") } // if input does not contain an ancestorName, check if there is ancestorId, otherwise check if there is a global one def parentId = retrievedAncestorId ?: input.ancestorId ?: config.confluence.ancestorId // if parentId is still not set, create a new parent page (parentId = null) parentId = parentId ?: null //println(\"ancestorName: '${input.ancestorName}', ancestorId: ${input.ancestorId} ---&gt; final parentId: ${parentId}\") // #342-dierk42: get the keywords from the meta tags def keywords = confluenceService.getKeywords(dom) def (pages, anchors, pageAnchors) = getPages(dom, parentId, confluenceSubpagesForSections) pushPages pages, anchors, pageAnchors, keywords if (parentId) { println \"published to ${config.confluence.api - \"rest/api/\"}/spaces/${confluenceSpaceKey}/pages/${parentId}\" } else { println \"published to ${config.confluence.api - \"rest/api/\"}/spaces/${confluenceSpaceKey}\" } } } \"\" .gravatar img { margin-left: 3px; border-radius: 4px; } 14. convertToDocx 1 minute to read 14.1. Before You Begin Before using this task: Install pandoc . Ensure that 'docbook' and 'docx' are added to the inputFiles formats in Config.groovy. As an optional step, specify a reference doc file with custom stylesheets (see task createReferenceDoc ). 14.2. Further Reading and Resources Read the Render AsciiDoc to docx (MS Word) blog post. 14.3. Source Show source code of scripts/pandoc.gradle or go directly to GitHub · docToolchain/scripts/pandoc.gradle . scripts/pandoc.gradle task convertToDocx ( group: 'docToolchain', description: 'converts file to .docx via pandoc. Needs pandoc installed.', type: Exec ) { // All files with option `docx` in config.groovy is converted to docbook and then to docx. def sourceFilesDocx = sourceFiles.findAll { 'docx' in it.formats } def explicitSourceFilesCount = sourceFilesDocx.size() if(explicitSourceFilesCount==0){ sourceFilesDocx = sourceFiles.findAll { 'docbook' in it.formats } } sourceFilesDocx.each { def sourceFile = it.file.replace('.adoc', '.xml') def targetFile = sourceFile.replace('.xml', '.docx') new File(\"$targetDir/docx/$targetFile\") .getParentFile() .getAbsoluteFile().mkdirs() workingDir \"$targetDir/docbook\" executable = \"pandoc\" def pandocOptions = config.pandocOptions ?: [] if(referenceDocFile?.trim()) { args = [\"-r\",\"docbook\", \"-t\",\"docx\", \"-o\",\"../docx/$targetFile\", *pandocOptions, \"--reference-doc=${docDir}/${referenceDocFile}\", sourceFile] } else { args = [\"-r\",\"docbook\", \"-t\",\"docx\", \"-o\",\"./../docx/$targetFile\", *pandocOptions, sourceFile] } } doFirst { if(sourceFilesDocx.size()==0){ throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'docx'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } if(explicitSourceFilesCount==0) { logger.warn('WARNING: No source files defined for type \"docx\". Converting with best effort') } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 15. createReferenceDoc 1 minute to read 15.1. Before You Begin Install pandoc . 15.2. About This Task This task creates a reference docx file used by pandoc during docbook-to-docx conversion. Use task convertToDocx to edit this file so it uses your preferred styles. The contents of the reference docx are ignored, but its stylesheets and document properties (including margins, page size, header and footer) are used in the new docx. For more information, see Pandoc User&#8217;s Guide: Options affecting specific writers (--reference-doc) And if you have problems with changing the default table style: see https://github.com/jgm/pandoc/issues/3275 . 15.3. Config.groovy Notes The 'referenceDocFile' property must be set to your custom reference file in Config.groovy: inputPath = '.' // use a style reference file in the input path for conversion from docbook to docx referenceDocFile = \"${inputPath}/my-ref-file.docx\" 15.4. Source Show source code of scripts/pandoc.gradle or go directly to GitHub · docToolchain/scripts/pandoc.gradle . scripts/pandoc.gradle task createReferenceDoc ( group: 'docToolchain helper', description: 'creates a docx file to be used as a format style reference in task convertToDocx. Needs pandoc installed.', type: Exec ) { workingDir \"$docDir\" executable = \"pandoc\" args = [\"-o\", \"${docDir}/${referenceDocFile}\", \"--print-default-data-file\", \"reference.docx\"] doFirst { if(!(referenceDocFile?.trim())) { throw new GradleException(\"Option `referenceDocFile` is not defined in config.groovy or has an empty value.\") } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 16. convertToEpub 1 minute to read 16.1. Dependency generateDocBook 16.2. About This Task This task uses pandoc to convert the DocBook output from AsciiDoctor to ePub. This publishes the output as an eBook which can be read using any eBook reader. The resulting file can be found in build/docs/epub . 16.3. Further Reading and Resources Turn your Document into an Audio-Book blog post. 16.4. Source Show source code of scripts/pandoc.gradle or go directly to GitHub · docToolchain/scripts/pandoc.gradle . scripts/pandoc.gradle task convertToEpub ( group: 'docToolchain', description: 'converts file to .epub via pandoc. Needs pandoc installed.', type: Exec ) { // All files with option `epub` in config.groovy is converted to docbook and then to epub. def sourceFilesEpub = sourceFiles.findAll { 'epub' in it.formats } def explicitSourceFilesCount = sourceFilesEpub.size() if(explicitSourceFilesCount==0){ sourceFilesEpub = sourceFiles.findAll { 'docbook' in it.formats } } sourceFilesEpub.each { def sourceFile = it.file.replace('.adoc', '.xml') def targetFile = sourceFile.replace('.xml', '.epub') new File(\"$targetDir/epub/$targetFile\") .getParentFile() .getAbsoluteFile().mkdirs() workingDir \"$targetDir/docbook\" executable = \"pandoc\" args = ['-r','docbook', '-t','epub', '-o',\"../epub/$targetFile\", sourceFile] } doFirst { if(sourceFilesEpub.size()==0){ throw new Exception (\"\"\" &gt;&gt; No source files defined for type 'epub'. &gt;&gt; Please specify at least one inputFile in your docToolchainConfig.groovy \"\"\") } if(explicitSourceFilesCount==0) { logger.warn('WARNING: No source files defined for type \"epub\". Converting with best effort') } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 17. exportEA 4 minutes to read 17.1. About This Task By default, no special configuration is necessary. However, several optional parameter configurations are available to support a project and packages to be used for export. These parameters can be used independently from one another. A sample of how to edit your projects' Config.groovy is provided in the 'Config.groovy' of the docToolchain project itself. 17.2. Important Currently this feature is WINDOWS-only. See this related issue . 17.3. The Optional Parameter Configurations 17.3.1. connection Either set the connection to a certain project, or comment it out to use all project files inside the src folder or its child folder. 17.3.2. packageFilter Add one or multiple packageGUIDs to be used for export. All packages are analysed, if no packageFilter is set. 17.3.3. exportPath Relative path to base 'docDir' to which the diagrams and notes are to be exported. Default: \"src/docs\". Example: docDir = 'D:\\work\\mydoc\\' ; exportPath = 'src/pdocs' ; Images will be exported to 'D:\\work\\mydoc\\src\\pdocs\\images\\ea', Notes will be exported to 'D:\\work\\mydoc\\src\\pdocs\\ea', 17.3.4. searchPath Relative path to base 'docDir', in which Enterprise Architect project files are searched Default: \"src/docs\". Example: docDir = 'D:\\work\\mydoc\\' ; exportPath = 'src/projects' ; Lookup for eap and eapx files starts in 'D:\\work\\mydoc\\src\\projects' and goes down the folder structure. Note : In case parameter 'connection' is already defined, the searchPath value is also used. exportEA starts opening the database parameter 'connection' first then looks for further project files either in the searchPath (if set) or in the docDir folder of the project. 17.3.5. glossaryAsciiDocFormat Whether the EA project glossary is exported depends on this parameter. If not set or an empty string, no glossary is exported. The glossaryAsciiDocFormat string is used to format each glossary entry in a certain AsciiDoc format. The following placeholders are defined for the format string: ID, TERM, MEANING, TYPE. One or more can be used by the output format. For example: A valid output format is to include the glossary as a flat list. The file can be included where needed in the documentation. glossaryAsciiDocFormat = \"TERM:: MEANING\" Other format strings can be used to include it as a table row. The glossary terms are sorted in alphabetical order. 17.3.6. glossaryTypes This parameter is used in case a glossaryAsciiDocFormat is defined, otherwise it is not evaluated. It&#8217;s used to filter for certain types. If the glossaryTypes list is empty, all entries will be used. For example: glossaryTypes = [\"Business\", \"Technical\"] 17.3.7. diagramAttributes If set, the string is used to create and store diagram attributes to be included in the document alongside a diagram. These placeholders are defined and populated with the diagram attributes, if used in the diagramAttributes string: %DIAGRAM_AUTHOR% , %DIAGRAM_CREATED% , %DIAGRAM_GUID% , %DIAGRAM_MODIFIED% , %DIAGRAM_NAME% , %DIAGRAM_NOTES% , %DIAGRAM_DIAGRAM_TYPE% , %DIAGRAM_VERSION% , %NEWLINE% Example: diagramAttributes = \"Last modification: %DIAGRAM_MODIFIED%%NEWLINE%Version: %DIAGRAM_VERSION%\" You can add the string %NEWLINE% where a line break will be added. The resulting text is stored next to the diagram image using the same path and file name, but a different file extension (.ad). This can be included in the document if required. If diagramAttributes is not set or an empty string, no file is written. 17.3.8. imageFormat If set, the set image format is used to export the diagrams. Default is set to \".png\". Please check your Enterprise Architect version which formats are supported. 17.3.9. additionalOptions This parameter is used to define the specific behavior of the export. Currently, these options are supported: KeepFirstDiagram If diagrams are not uniquely named, the last diagram will be saved. If you want to prevent diagrams from being overwritten, add this parameter to additionalOptions. 17.4. Glossary export By setting the glossaryAsciiDocFormat, the glossary terms stored in the EA project will be exported into a folder named 'glossary' below the configured exportPath. In case multiple EA projects are found for export, one glossary per project is exported - each named using the project&#8217;s GUID plus extension '.ad'. Each individual file will be filtered (see glossaryTypes) and sorted in alphabetical order. In addition, a global glossary is created by using all single glossary files. This global file is named 'glossary.ad' and is also placed in the glossary folder. The global glossary is also filtered and sorted. If there is only one EA project, only the global glossary is written. 17.5. Further Reading and Resources JIRA to Sparx EA blog post. Did you Ever Wish you Had Better Diagrams? blog post. 17.6. Source Show source code of scripts/exportEA.gradle or go directly to GitHub · docToolchain/scripts/exportEA.gradle . scripts/exportEA.gradle task exportEA( dependsOn: [streamingExecute], description: 'exports all diagrams and some texts from EA files', group: 'docToolchain' ) { doFirst { } doLast { logger.info(\"docToolchain &gt; exportEA: \" + docDir) logger.info(\"docToolchain &gt; exportEA: \" + mainConfigFile) def configFile = new File(docDir, mainConfigFile) def config = new ConfigSlurper().parse(configFile.text) def scriptParameterString = \"\" def exportPath = \"\" def searchPath = \"\" def glossaryPath = \"\" def imageFormat = \"\" def readme = \"\"\"This folder contains exported diagrams or notes from Enterprise Architect. Please note that these are generated files but reside in the `src`-folder in order to be versioned. This is to make sure that they can be used from environments other than windows. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradle exportEA` to re-export files \"\"\" if (!config.exportEA.connection.isEmpty()) { logger.info(\"docToolchain &gt; exportEA: found \" + config.exportEA.connection) scriptParameterString = scriptParameterString + \"-c \\\"${config.exportEA.connection}\\\"\" } if (!config.exportEA.packageFilter.isEmpty()) { def packageFilterToCreate = config.exportEA.packageFilter as List logger.info(\"docToolchain &gt; exportEA: package filter list size: \" + packageFilterToCreate.size()) packageFilterToCreate.each { packageFilter -&gt; scriptParameterString = scriptParameterString + \" -p \\\"${packageFilter}\\\"\" } } if (!config.exportEA.exportPath.isEmpty()) { exportPath = new File(docDir, config.exportEA.exportPath).getAbsolutePath() } else { exportPath = new File(docDir, 'src/docs').getAbsolutePath() } if (!config.exportEA.searchPath.isEmpty()) { searchPath = new File(docDir, config.exportEA.searchPath).getAbsolutePath() } else if (!config.exportEA.absoluteSearchPath.isEmpty()) { searchPath = new File(config.exportEA.absoluteSearchPath).getAbsolutePath() } else { searchPath = new File(docDir, 'src').getAbsolutePath() } if (config.exportEA.imageFormat.isEmpty()) { imageFormat = \".png\" } else if(!config.exportEA.imageFormat.startsWith(\".\")) { imageFormat = \".\" + config.exportEA.imageFormat } else { imageFormat = config.exportEA.imageFormat } scriptParameterString = scriptParameterString + \" -d \\\"$exportPath\\\"\" scriptParameterString = scriptParameterString + \" -s \\\"$searchPath\\\"\" scriptParameterString = scriptParameterString + \" -f \\\"$imageFormat\\\"\" logger.info(\"docToolchain &gt; exportEA: exportPath: \" + exportPath) //remove old glossary files/folder if exist new File(exportPath, 'glossary').deleteDir() //set the glossary file path in case an output format is configured, other no glossary is written if (!config.exportEA.glossaryAsciiDocFormat.isEmpty()) { //create folder to store glossaries new File(exportPath, 'glossary/.').mkdirs() glossaryPath = new File(exportPath, 'glossary').getAbsolutePath() scriptParameterString = scriptParameterString + \" -g \\\"$glossaryPath\\\"\" } //configure additional diagram attributes to be exported if (!config.exportEA.diagramAttributes.isEmpty()) { scriptParameterString = scriptParameterString + \" -da \\\"$config.exportEA.diagramAttributes\\\"\" } //configure additional diagram attributes to be exported if (!config.exportEA.additionalOptions.isEmpty()) { scriptParameterString = scriptParameterString + \" -ao \\\"$config.exportEA.additionalOptions\\\"\" } //make sure path for notes exists //and remove old notes new File(exportPath, 'ea').deleteDir() //also remove old diagrams new File(exportPath, 'images/ea').deleteDir() //create a readme to clarify things new File(exportPath, 'images/ea/.').mkdirs() new File(exportPath, 'images/ea/readme.ad').write(readme) new File(exportPath, 'ea/.').mkdirs() new File(exportPath, 'ea/readme.ad').write(readme) //execute through cscript in order to make sure that we get WScript.echo right logger.info(\"docToolchain &gt; exportEA: parameters: \" + scriptParameterString) \"%SystemRoot%\\\\System32\\\\cscript.exe //nologo ${projectDir}/scripts/exportEAP.vbs ${scriptParameterString}\".executeCmd() //the VB Script is only capable of writing iso-8859-1-Files. //we now have to convert them to UTF-8 new File(exportPath, 'ea/.').eachFileRecurse { file -&gt; if (file.isFile()) { println \"exported notes \" + file.canonicalPath file.write(file.getText('iso-8859-1'), 'utf-8') } } //sort, filter and reformat a glossary if an output format is configured if (!config.exportEA.glossaryAsciiDocFormat.isEmpty()) { def glossaryTypes if (!config.exportEA.glossaryTypes.isEmpty()) { glossaryTypes = config.exportEA.glossaryTypes as List } new GlossaryHandler().execute(glossaryPath, config.exportEA.glossaryAsciiDocFormat, glossaryTypes); } } } Show source code of scripts/exportEAP.vbs or go directly to GitHub · docToolchain/scripts/exportEAP.vbs . scripts/exportEAP.vbs ' based on the \"Project Interface Example\" which comes with EA ' http://stackoverflow.com/questions/1441479/automated-method-to-export-enterprise-architect-diagrams Dim EAapp 'As EA.App Dim Repository 'As EA.Repository Dim FS 'As Scripting.FileSystemObject Dim projectInterface 'As EA.Project Const ForAppending = 8 Const ForWriting = 2 ' Helper ' http://windowsitpro.com/windows/jsi-tip-10441-how-can-vbscript-create-multiple-folders-path-mkdir-command Function MakeDir (strPath) Dim strParentPath, objFSO Set objFSO = CreateObject(\"Scripting.FileSystemObject\") On Error Resume Next strParentPath = objFSO.GetParentFolderName(strPath) If Not objFSO.FolderExists(strParentPath) Then MakeDir strParentPath If Not objFSO.FolderExists(strPath) Then objFSO.CreateFolder strPath On Error Goto 0 MakeDir = objFSO.FolderExists(strPath) End Function ' Replaces certain characters with '_' to avoid unwanted file or folder names causing errors or structure failures. ' Regular expression can easily be extended with further characters to be replaced. Function NormalizeName(theName) dim re : Set re = new regexp re.Pattern = \"[\\\\/\\[\\]\\s:]\" re.Global = True NormalizeName = re.Replace(theName, \"_\") End Function Sub WriteNote(currentModel, currentElement, notes, prefix) If (Left(notes, 6) = \"{adoc:\") Then strFileName = Trim(Mid(notes,7,InStr(notes,\"}\")-7)) strNotes = Right(notes,Len(notes)-InStr(notes,\"}\")) set objFSO = CreateObject(\"Scripting.FileSystemObject\") If (currentModel.Name=\"Model\") Then ' When we work with the default model, we don't need a sub directory path = objFSO.BuildPath(exportDestination,\"ea/\") Else path = objFSO.BuildPath(exportDestination,\"ea/\"&amp;NormalizeName(currentModel.Name)&amp;\"/\") End If MakeDir(path) post = \"\" If (prefix&lt;&gt;\"\") Then post = \"_\" End If MakeDir(path&amp;prefix&amp;post) set objFile = objFSO.OpenTextFile(path&amp;prefix&amp;post&amp;\"/\"&amp;strFileName&amp;\".ad\",ForAppending, True) name = currentElement.Name name = Replace(name,vbCr,\"\") name = Replace(name,vbLf,\"\") strCombinedNotes = \"_all_notes.ad\" set objCombinedNotesFile = objFSO.OpenTextFile(path&amp;prefix&amp;post&amp;\"/\"&amp;strCombinedNotes,ForAppending, True) if (Left(strNotes, 3) = vbCRLF&amp;\"|\") Then ' content should be rendered as table - so don't interfere with it objFile.WriteLine(vbCRLF) objCombinedNotesFile.WriteLine(vbCRLF) else 'let's add the name of the object objFile.WriteLine(vbCRLF&amp;vbCRLF&amp;\".\"&amp;name) objCombinedNotesFile.WriteLine(vbCRLF&amp;vbCRLF&amp;\".\"&amp;name) End If objFile.WriteLine(vbCRLF&amp;strNotes) objFile.Close objCombinedNotesFile.WriteLine(vbCRLF&amp;strNotes) objCombinedNotesFile.Close if (prefix&lt;&gt;\"\") Then ' write the same to a second file set objFile = objFSO.OpenTextFile(path&amp;prefix&amp;\".ad\",ForAppending, True) objFile.WriteLine(vbCRLF&amp;vbCRLF&amp;\".\"&amp;name&amp;vbCRLF&amp;strNotes) objFile.Close End If End If End Sub Sub SyncJira(currentModel, currentDiagram) notes = currentDiagram.notes set currentPackage = Repository.GetPackageByID(currentDiagram.PackageID) updated = 0 created = 0 If (Left(notes, 6) = \"{jira:\") Then WScript.echo \" &gt;&gt;&gt;&gt; Diagram jira tag found\" strSearch = Mid(notes,7,InStr(notes,\"}\")-7) Set objShell = CreateObject(\"WScript.Shell\") 'objShell.CurrentDirectory = fso.GetFolder(\"./scripts\") Set objExecObject = objShell.Exec (\"cmd /K groovy ./scripts/exportEAPJiraPrintHelper.groovy \"\"\" &amp; strSearch &amp;\"\"\" &amp; exit\") strReturn = \"\" x = 0 y = 0 Do While Not objExecObject.StdOut.AtEndOfStream output = objExecObject.StdOut.ReadLine() ' WScript.echo output jiraElement = Split(output,\"|\") name = jiraElement(0)&amp;\":\"&amp;vbCR&amp;vbLF&amp;jiraElement(4) On Error Resume Next Set requirement = currentPackage.Elements.GetByName(name) On Error Goto 0 if (IsObject(requirement)) then ' element already exists requirement.notes = \"\" requirement.notes = requirement.notes&amp;\"&lt;a href='\"&amp;jiraElement(5)&amp;\"'&gt;\"&amp;jiraElement(0)&amp;\"&lt;/a&gt;\"&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Priority: \"&amp;jiraElement(1)&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Created: \"&amp;jiraElement(2)&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Assignee: \"&amp;jiraElement(3)&amp;vbCR&amp;vbLF requirement.Update() updated = updated + 1 else Set requirement = currentPackage.Elements.AddNew(name,\"Requirement\") requirement.notes = \"\" requirement.notes = requirement.notes&amp;\"&lt;a href='\"&amp;jiraElement(5)&amp;\"'&gt;\"&amp;jiraElement(0)&amp;\"&lt;/a&gt;\"&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Priority: \"&amp;jiraElement(1)&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Created: \"&amp;jiraElement(2)&amp;vbCR&amp;vbLF requirement.notes = requirement.notes&amp;\"Assignee: \"&amp;jiraElement(3)&amp;vbCR&amp;vbLF requirement.Update() currentPackage.Elements.Refresh() Set dia_obj = currentDiagram.DiagramObjects.AddNew(\"l=\"&amp;(10+x*200)&amp;\";t=\"&amp;(10+y*50)&amp;\";b=\"&amp;(10+y*50+44)&amp;\";r=\"&amp;(10+x*200+180),\"\") x = x + 1 if (x&gt;3) then x = 0 y = y + 1 end if dia_obj.ElementID = requirement.ElementID dia_obj.Update() created = created + 1 end if Loop Set objShell = Nothing WScript.echo \"created \"&amp;created&amp;\" requirements\" WScript.echo \"updated \"&amp;updated&amp;\" requirements\" End If End Sub ' This sub routine checks if the format string defined in diagramAttributes ' does contain any characters. It replaces the known placeholders: ' %DIAGRAM_AUTHOR%, %DIAGRAM_CREATED%, %DIAGRAM_GUID%, %DIAGRAM_MODIFIED%, ' %DIAGRAM_NAME%, %DIAGRAM_NOTES%, %DIAGRAM_DIAGRAM_TYPE%, %DIAGRAM_VERSION% ' with the attribute values read from the EA diagram object. ' None, one or multiple number of placeholders can be used to create a diagram attribute ' to be added to the document. The attribute string is stored as a file with the same ' path and name as the diagram image, but with suffix .ad. So, it can ' easily be included in an asciidoc file. Sub SaveDiagramAttribute(currentDiagram, path, diagramName) If Len(diagramAttributes) &gt; 0 Then filledDiagAttr = diagramAttributes set objFSO = CreateObject(\"Scripting.FileSystemObject\") filename = objFSO.BuildPath(path, diagramName &amp; \".ad\") set objFile = objFSO.OpenTextFile(filename, ForWriting, True) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_AUTHOR%\", currentDiagram.Author) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_CREATED%\", currentDiagram.CreatedDate) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_GUID%\", currentDiagram.DiagramGUID) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_MODIFIED%\", currentDiagram.ModifiedDate) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_NAME%\", currentDiagram.Name) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_NOTES%\", currentDiagram.Notes) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_DIAGRAM_TYPE%\", currentDiagram.Type) filledDiagAttr = Replace(filledDiagAttr, \"%DIAGRAM_VERSION%\", currentDiagram.Version) filledDiagAttr = Replace(filledDiagAttr, \"%NEWLINE%\", vbCrLf) objFile.WriteLine(filledDiagAttr) objFile.Close End If End Sub Sub SaveDiagram(currentModel, currentDiagram) Dim exportDiagram ' As Boolean ' Open the diagram Repository.OpenDiagram(currentDiagram.DiagramID) ' Save and close the diagram set objFSO = CreateObject(\"Scripting.FileSystemObject\") If (currentModel.Name=\"Model\") Then ' When we work with the default model, we don't need a sub directory path = objFSO.BuildPath(exportDestination,\"/images/ea/\") Else path = objFSO.BuildPath(exportDestination,\"/images/ea/\" &amp; NormalizeName(currentModel.Name) &amp; \"/\") End If path = objFSO.GetAbsolutePathName(path) MakeDir(path) diagramName = currentDiagram.Name diagramName = Replace(diagramName,vbCr,\"\") diagramName = Replace(diagramName,vbLf,\"\") diagramName = NormalizeName(diagramName) filename = objFSO.BuildPath(path, diagramName &amp; imageFormat) exportDiagram = True If objFSO.FileExists(filename) Then WScript.echo \" --- \" &amp; filename &amp; \" already exists.\" If Len(additionalOptions) &gt; 0 Then If InStr(additionalOptions, \"KeepFirstDiagram\") &gt; 0 Then WScript.echo \" --- Skipping export -- parameter 'KeepFirstDiagram' set.\" Else WScript.echo \" --- Overwriting -- parameter 'KeepFirstDiagram' not set.\" exportDiagram = False End If Else WScript.echo \" --- Overwriting -- parameter 'KeepFirstDiagram' not set.\" End If End If If exportDiagram Then projectInterface.SaveDiagramImageToFile(filename) WScript.echo \" extracted image to \" &amp; filename If Not IsEmpty(diagramAttributes) Then SaveDiagramAttribute currentDiagram, path, diagramName End If End If Repository.CloseDiagram(currentDiagram.DiagramID) ' Write the note of the diagram WriteNote currentModel, currentDiagram, currentDiagram.Notes, diagramName&amp;\"_notes\" For Each diagramElement In currentDiagram.DiagramObjects Set currentElement = Repository.GetElementByID(diagramElement.ElementID) WriteNote currentModel, currentElement, currentElement.Notes, diagramName&amp;\"_notes\" Next For Each diagramLink In currentDiagram.DiagramLinks set currentConnector = Repository.GetConnectorByID(diagramLink.ConnectorID) WriteNote currentModel, currentConnector, currentConnector.Notes, diagramName&amp;\"_links\" Next End Sub ' ' Recursively saves all diagrams under the provided package and its children ' Sub DumpDiagrams(thePackage,currentModel) Set currentPackage = thePackage ' export element notes For Each currentElement In currentPackage.Elements WriteNote currentModel, currentElement, currentElement.Notes, \"\" ' export connector notes For Each currentConnector In currentElement.Connectors ' WScript.echo currentConnector.ConnectorGUID if (currentConnector.ClientID=currentElement.ElementID) Then WriteNote currentModel, currentConnector, currentConnector.Notes, \"\" End If Next if (Not currentElement.CompositeDiagram Is Nothing) Then SyncJira currentModel, currentElement.CompositeDiagram SaveDiagram currentModel, currentElement.CompositeDiagram End If if (Not currentElement.Elements Is Nothing) Then DumpDiagrams currentElement,currentModel End If Next ' Iterate through all diagrams in the current package For Each currentDiagram In currentPackage.Diagrams SyncJira currentModel, currentDiagram SaveDiagram currentModel, currentDiagram Next ' Process child packages Dim childPackage 'as EA.Package ' otPackage = 5 if (currentPackage.ObjectType = 5) Then For Each childPackage In currentPackage.Packages call DumpDiagrams(childPackage, currentModel) Next End If End Sub Function SearchEAProjects(path) For Each folder In path.SubFolders SearchEAProjects folder Next For Each file In path.Files If fso.GetExtensionName (file.Path) = \"eap\" OR fso.GetExtensionName (file.Path) = \"eapx\" OR fso.GetExtensionName (file.Path) = \"qea\" OR fso.GetExtensionName (file.Path) = \"qeax\" Then WScript.echo \"found \"&amp;file.path If (Left(file.name, 1) = \"_\") Then WScript.echo \"skipping, because it start with `_` (replication)\" Else OpenProject(file.Path) End If End If Next End Function 'Gets the package object as referenced by its GUID from the Enterprise Architect project. 'Looks for the model node, the package is a child of as it is required for the diagram export. 'Calls the Sub routine DumpDiagrams for the model and package found. 'An error is printed to console only if the packageGUID is not found in the project. Function DumpPackageDiagrams(EAapp, packageGUID) WScript.echo \"DumpPackageDiagrams\" WScript.echo packageGUID Dim package Set package = EAapp.Repository.GetPackageByGuid(packageGUID) If (package Is Nothing) Then WScript.echo \"invalid package - as package is not part of the project\" Else Dim currentModel Set currentModel = package while currentModel.IsModel = false Set currentModel = EAapp.Repository.GetPackageByID(currentModel.parentID) wend ' Iterate through all child packages and save out their diagrams ' save all diagrams of package itself call DumpDiagrams(package, currentModel) End If End Function Function FormatStringToJSONString(inputString) outputString = Replace(inputString, \"\\\", \"\\\\\") outputString = Replace(outputString, \"\"\"\", \"\\\"\"\") outputString = Replace(outputString, vbCrLf, \"\\n\") outputString = Replace(outputString, vbLf, \"\\n\") outputString = Replace(outputString, vbCr, \"\\n\") FormatStringToJSONString = outputString End Function 'If a valid file path is set, the glossary terms are read from EA repository, 'formatted in a JSON compatible format and written into file. 'The file is read and reformatted by the exportEA gradle task afterwards. Function ExportGlossaryTermsAsJSONFile(EArepo) If (Len(glossaryFilePath) &gt; 0) Then set objFSO = CreateObject(\"Scripting.FileSystemObject\") GUID = Replace(EArepo.ProjectGUID,\"{\",\"\") GUID = Replace(GUID,\"}\",\"\") currentGlossaryFile = objFSO.BuildPath(glossaryFilePath,\"/\"&amp;GUID&amp;\".ad\") set objFile = objFSO.OpenTextFile(currentGlossaryFile,ForAppending, True) Set glossary = EArepo.Terms() objFile.WriteLine(\"[\") dim counter counter = 0 For Each term In glossary if (counter &gt; 0) Then objFile.Write(\",\") end if objFile.Write(\"{ \"\"term\"\" : \"\"\"&amp;FormatStringToJSONString(term.term)&amp;\"\"\", \"\"meaning\"\" : \"\"\"&amp;FormatStringToJSONString(term.Meaning)&amp;\"\"\",\") objFile.WriteLine(\" \"\"termID\"\" : \"\"\"&amp;FormatStringToJSONString(term.termID)&amp;\"\"\", \"\"type\"\" : \"\"\"&amp;FormatStringToJSONString(term.type)&amp;\"\"\" }\") counter = counter + 1 Next objFile.WriteLine(\"]\") objFile.Close End If End Function Sub OpenProject(file) ' open Enterprise Architect Set EAapp = CreateObject(\"EA.App\") WScript.echo \"opening Enterprise Architect. This might take a moment...\" ' load project EAapp.Repository.OpenFile(file) ' make Enterprise Architect to not appear on screen EAapp.Visible = False ' get repository object Set Repository = EAapp.Repository ' Show the script output window ' Repository.EnsureOutputVisible(\"Script\") call ExportGlossaryTermsAsJSONFile(Repository) Set projectInterface = Repository.GetProjectInterface() Dim childPackage 'As EA.Package ' Iterate through all model nodes Dim currentModel 'As EA.Package If (InStrRev(file,\"{\") &gt; 0) Then ' the filename references a GUID ' like {04C44F80-8DA1-4a6f-ECB8-982349872349} WScript.echo file GUID = Mid(file, InStrRev(file,\"{\")+0,38) WScript.echo GUID ' Iterate through all child packages and save out their diagrams call DumpPackageDiagrams(EAapp, GUID) Else If packageFilter.Count = 0 Then WScript.echo \"done\" ' Iterate through all model nodes For Each currentModel In Repository.Models ' Iterate through all child packages and save out their diagrams For Each childPackage In currentModel.Packages call DumpDiagrams(childPackage,currentModel) Next Next Else ' Iterate through all packages found in the package filter given by script parameter. For Each packageGUID In packageFilter call DumpPackageDiagrams(EAapp, packageGUID) Next End If End If EAapp.Repository.CloseFile() ' Since EA 15.2 the Enterprise Architect background process hangs without calling Exit explicitly On Error Resume Next EAapp.Repository.CloseFile() EAapp.Repository.Exit() EAapp.Repository = null ' end fix EA End Sub Private connectionString Private packageFilter Private exportDestination Private searchPath Private glossaryFilePath Private imageFormat Private diagramAttributes Private additionalOptions exportDestination = \"./src/docs\" searchPath = \"./src\" Set packageFilter = CreateObject(\"System.Collections.ArrayList\") Set objArguments = WScript.Arguments Dim argCount argCount = 0 While objArguments.Count &gt; argCount+1 Select Case objArguments(argCount) Case \"-c\" connectionString = objArguments(argCount+1) Case \"-p\" packageFilter.Add objArguments(argCount+1) Case \"-d\" exportDestination = objArguments(argCount+1) Case \"-s\" searchPath = objArguments(argCount+1) Case \"-g\" glossaryFilePath = objArguments(argCount+1) Case \"-f\" imageFormat = objArguments(argCount+1) Case \"-da\" diagramAttributes = objArguments(argCount+1) Case \"-ao\" additionalOptions = objArguments(argCount+1) Case Else WScript.echo \"unknown argument: \" &amp; objArguments(argCount) End Select argCount = argCount + 2 WEnd set fso = CreateObject(\"Scripting.fileSystemObject\") WScript.echo \"Image extractor\" ' Check both types in parallel - 1st check Enterprise Architect database connection, 2nd look for local project files If Not IsEmpty(connectionString) Then WScript.echo \"opening database connection now\" OpenProject(connectionString) End If WScript.echo \"looking for .eap(x) and .qea(x) files in \" &amp; fso.GetAbsolutePathName(searchPath) ' Dim f As Scripting.Files SearchEAProjects fso.GetFolder(searchPath) WScript.echo \"finished exporting images\" .gravatar img { margin-left: 3px; border-radius: 4px; } 18. exportVisio 1 minute to read 18.1. About This Task This task searches for Visio files in the /src/docs folder then exports all diagrams and element notes to /src/docs/images/visio and /src/docs/visio . Images are stored as /images/visio/[filename]-[pagename].png . Notes are stored as /visio/[filename]-[pagename].adoc You can specify a filename to export notes to by starting any comment with {adoc:[filename].adoc} . It will then be written to /visio/[filename].adoc . 18.2. Important Information About This Task Currently, only Visio files stored directly in /src/docs are supported. All others will export to the wrong location. Before running this task, close any open Visio instance. 18.3. Further Reading and Resources Issue #112 . 18.4. Source Show source code of scripts/exportVisio.gradle or go directly to GitHub · docToolchain/scripts/exportVisio.gradle . scripts/exportVisio.gradle task exportVisio( dependsOn: [streamingExecute], description: 'exports all diagrams and notes from visio files', group: 'docToolchain' ) { doLast { //make sure path for notes exists //and remove old notes new File(docDir, 'src/docs/visio').deleteDir() //also remove old diagrams new File(docDir, 'src/docs/images/visio').deleteDir() //create a readme to clarify things def readme = \"\"\"This folder contains exported diagrams and notes from visio files. Please note that these are generated files but reside in the `src`-folder in order to be versioned. This is to make sure that they can be used from environments other than windows. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradle exportVisio` to re-export files \"\"\" new File(docDir, 'src/docs/images/visio/.').mkdirs() new File(docDir, 'src/docs/images/visio/readme.ad').write(readme) new File(docDir, 'src/docs/visio/.').mkdirs() new File(docDir, 'src/docs/visio/readme.ad').write(readme) def sourcePath = new File(docDir, 'src/docs/.').canonicalPath def scriptPath = new File(projectDir, 'scripts/VisioPageToPngConverter.ps1').canonicalPath \"powershell ${scriptPath} -SourcePath ${sourcePath}\".executeCmd() } } Show source code of scripts/VisioPageToPngConverter.ps1 or go directly to GitHub · docToolchain/scripts/VisioPageToPngConverter.ps1 . scripts/VisioPageToPngConverter.ps1 # Convert all pages in all visio files in the given directory to png files. # A Visio windows might flash shortly. # The converted png files are stored in the same directory # The name of the png file is concatenated from the Visio file name and the page name. # In addtion all the comments are stored in adoc files. # If the Viso file is named \"MyVisio.vsdx\" and the page is called \"FirstPage\" # the name of the png file will be \"MyVisio-FirstPage.png\" and the comment will # be stored in \"MyVisio-FirstPage.adoc\". # But for the name of the adoc files there is an alternative. It can be given in the first # line of the comment. If it is given in the comment it has to be given in curly brackes # with the prefix \"adoc:\", e.g. {adoc:MyCommentFile.adoc} # Prerequisites: Viso and PowerShell has to be installed on the computer. # Parameter: SourcePath where visio files can be found # Example powershell VisoPageToPngConverter.ps1 -SourcePath c:\\convertertest\\ Param ( [Parameter(Mandatory=$true,ValueFromPipeline=$true,Position=0)] [Alias('p')][String]$SourcePath ) Write-Output \"starting to export visio\" If (!(Test-Path -Path $SourcePath)) { Write-Warning \"The path \"\"$SourcePath\"\" does not exist or is not accessible, please input the correct path.\" Exit } # Extend the source path to get only Visio files of the given directory and not in subdircetories If ($SourcePath.EndsWith(\"\\\")) { $SourcePath = \"$SourcePath\" } Else { $SourcePath = \"$SourcePath\\\" } $VisioFiles = Get-ChildItem -Path \"$SourcePath*\" -Recurse -Include *.vsdx,*.vssx,*.vstx,*.vxdm,*.vssm,*.vstm,*.vsd,*.vdw,*.vss,*.vst If(!($VisioFiles)) { Write-Warning \"There are no Visio files in the path \"\"$SourcePath\"\".\" Exit } $VisioApp = New-Object -ComObject Visio.Application $VisioApp.Visible = $false # Extract the png from all the files in the folder Foreach($File in $VisioFiles) { $FilePath = $File.FullName Write-Output \"found \"\"$FilePath\"\" .\" $FileDirectory = $File.DirectoryName # Get the folder containing the Visio file. Will be used to store the png and adoc files $FileBaseName = $File.BaseName -replace '[ :/\\\\*?|&lt;&gt;]','-' # Get the filename to be used as part of the name of the png and adoc files Try { $Document = $VisioApp.Documents.Open($FilePath) $Pages = $VisioApp.ActiveDocument.Pages Foreach($Page in $Pages) { # Create valid filenames for the png and adoc files $PngFileName = $Page.Name -replace '[ :/\\\\*?|&lt;&gt;]','-' $PngFileName = \"$FileBaseName-$PngFileName.png\" $AdocFileName = $PngFileName.Replace(\".png\", \".adoc\") #TODO: this needs better logic Write-Output(\"$SourcePath\\images\\visio\\$PngFileName\") $Page.Export(\"$SourcePath\\images\\visio\\$PngFileName\") $AllPageComments = \"\" ForEach($PageComment in $Page.Comments) { # Extract adoc filename from comment text if the syntax is valid # Remove the filename from the text and save the comment in a file with a valid name $EofStringIndex = $PageComment.Text.IndexOf(\".adoc}\") if ($PageComment.Text.StartsWith(\"{adoc\") -And ($EofStringIndex -gt 6)) { $AdocFileName = $PageComment.Text.Substring(6, $EofStringIndex -1) $AllPageComments += $PageComment.Text.Substring($EofStringIndex + 6) } else { $AllPageComments += $PageComment.Text+\"`n\" } } If ($AllPageComments) { $AdocFileName = $AdocFileName -replace '[:/\\\\*?|&lt;&gt;]','-' #TODO: this needs better logic $stream = [System.IO.StreamWriter] \"$SourcePath\\visio\\$AdocFileName\" $stream.WriteLine($AllPageComments) $stream.close() } } $Document.Close() } Catch { if ($Document) { $Document.Close() } Write-Warning \"One or more visio page(s) in file \"\"$FilePath\"\" have been lost in this converting.\" Write-Warning \"Error was: $_\" } } $VisioApp.Quit() .gravatar img { margin-left: 3px; border-radius: 4px; } 19. exportDrawIo 2 minutes to read 19.1. About This Task There is no exportDrawIo task available in docToolchain because such a task is not required. You can continue to use diagrams.net (formerly known as draw.io) to edit your diagrams simply by making a change to your diagram-authoring workflow. 19.2. About diagrams.net diagrams.net offers free and open source desktop editors for all major operating system platforms. Visit https://www.diagrams.net/integrations to find a desktop editor application compatible with your operating system. When you use the desktop version, just create your diagram with the .png (or even better, .dio.png ) extension and diagrams.net will always save your diagram as a PNG with the source as metadata. They have also launched a free plugin for VS Code and IntelliJ, so you can edit your diagrams offline! 19.3. How to Change Your Workflow to Use diagrams.net Export your diagrams.net/draw.io diagrams as a PNG with the source embedded in the file metadata. This allows you to embed your diagrams into AsciiDoc source as you normally would (using the image:: macro) with the added advantage of storing the diagram source with the image itself. 19.4. How to Convert a Confluence Page to AsciiDoc If you are converting a Confluence page with embedded draw.io diagrams to AsciiDoc, use this export workflow to continue using diagrams.net: Export an editable PNG diagram from Confluence. Load the diagram you want to export from Confluence. Click File &#160; Export as &#160; PNG&#8230;&#8203; . In the Image modal, make sure that Include a copy of my diagram is selected. Click Export to save the PNG file with the pattern [file].dio.png . Commit the exported PNG file to source control. Your diagram can now be managed in source control, added to your documentation source and edited using a diagrams.net desktop version. Specifying .dio (short for \" d raw io \") in the name will help you identify PNG files containing an embedded XML diagram source. // Please, replace #yourelement with a real element id on your webpage MarketplaceWidget.setupMarketplaceWidget('card', 15635, \"#myelement\"); .gravatar img { margin-left: 3px; border-radius: 4px; } 20. exportChangeLog 2 minutes to read 20.1. About This Task As the name suggests, this task exports the changelog to be referenced from within your documentation, if needed. The changelog is written to build/docs/changelog.adoc . This task can be configured to use a different source control system or a different directory. To configure this task, copy template_config/scripts/ChangelogConfig.groovy to your directory and modify to suit your needs. Then use -PchangelogConfigFile=&lt;your config file&gt; to add the path to your configuration file to the task. See the description inside the template for more details. By default, the source is the Git changelog for the path src/docs and only contains the commit messages for changes made to the documentation. All changes to the build or other sources in the repository will not show up. By default, the changelog contains changes made to date , author and commit message already formatted as AsciiDoc table content: | 09.04.2017 | Ralf D. Mueller | fix #24 template updated to V7.0 | 08.04.2017 | Ralf D. Mueller | fixed typo You simply include it like this: .Changes [options=\"header\",cols=\"1,2,6\"] |==== | Date | Author | Comment include::../../build/docs/changelog.adoc[] |==== By excluding the table definition, you can easily translate the table headings through different text snippets. In a future docToolchain release, you will have the ability to include only certain commit messages from the changelog and exclude others (starting with # or // ?). This feature is not available just yet. 20.2. Further Reading and Resources The only constant in life is change blog post. 20.3. Source Show source code of scripts/exportChangelog.gradle or go directly to GitHub · docToolchain/scripts/exportChangelog.gradle . scripts/exportChangelog.gradle task exportChangeLog( description: 'exports the change log from a git subpath', group: 'docToolchain' ) { doFirst { new File(targetDir).mkdirs() } doLast { logger.info(\"docToolchain&gt; docDir: \"+docDir) logger.info(\"docToolchain&gt; mainConfigFile: \"+mainConfigFile) def config = new ConfigSlurper().parse(new File(docDir, mainConfigFile).text) def cmd = \"${config.changelog.cmd} .\" def changes = cmd.execute(null, new File(docDir, config.changelog.dir)).text def changelog = new File(targetDir, 'changelog.adoc') logger.info \"&gt; changelog exported ${changelog.canonicalPath}\" changelog.write(changes) } } .gravatar img { margin-left: 3px; border-radius: 4px; } 21. exportContributors 3 minutes to read 21.1. About This Task This task crawls through all Asciidoctor source files and extracts a list of contributors, which is then rendered as AsciiDoc images of each contributor&#8217;s gravatar picture. The extracted list is stored in /home/runner/work/docToolchain/docToolchain/build/contributors/015_tasks/03_task_exportContributors.adoc so it can be easily included in your documents. 21.2. How to Use This Task The best way to use this task is to create a feedback.adoc file similar to this: feedback.adoc ifndef::backend-pdf[] (1) image::https://img.shields.io/badge/improve-this%20doc-orange.svg[link={manualdir}{filename}, float=right] (2) image::https://img.shields.io/badge/create-an%20issue-blue.svg[link=\"https://github.com/docToolchain/documentation/issues/new?title=&amp;body=%0A%0A%5BEnter%20feedback%20here%5D%0A%0A%0A---%0A%23page:{filename}\", float=right] (3) endif::[] include::{targetDir}/contributors/{filename}[] (4) Key: 1 Do not show this section when docs are rendered as PDF. 2 Create an Improve This Doc button which links to your GitHub sources. 3 Create a Create an Issue button which links to your issue tracker. 4 Include the list of contributors created by this task. (The task automatically adds the estimated reading time to the list of contributors.) 21.3. About the Avatar-Icons It seems not to be possible to extract a link to the github avatar icons from the log. So, the solution is to use Gravatar icons. For this to work, the contributors email address is hashed and an icon link is generated from that hash. http://www.gravatar.com/avatar/cc5f3bf8b3cb91c985ed4fd046aa451d?d=identicon This result at least in an icon which has a distinct color. Contributors can set up their own image through Gravatar.com . For this to work, the git commits need to use an email address which can be verified by Gravatar.com. Unfortunately, this is not the case if a contributor decided to make his email address private in the email sections of her github account. 21.4. File Attributes This task also exports some GitHub file attributes. The extracted attributes are stored in /home/runner/work/docToolchain/docToolchain/build/fileattribs/015_tasks/03_task_exportContributors.adoc . :lastUpdated: 16.05.2019 06:22 :lastAuthorName: Ralf D. Müller :lastAuthorEmail: ralf.d.mueller@gmail.com :lastAuthorAvatar: http://www.gravatar.com/avatar/cc5f3bf8b3cb91c985ed4fd046aa451d?d=identicon[32,32,role='gravatar',alt='Ralf D. Müller',title='Ralf D. Müller'] :lastMessage: #310 started to document config options You can import and use these attributes in the same way as you import the contributors list. please make sure that you do not accidentally publish the email address if your contributors do not want it. For example: feedback.adoc include::{targetDir}/fileattribs/{filename}[] Last updated {lastUpdated} by {lastAuthorName} .gravatar img { margin-left: 3px; border-radius: 4px; } 22. exportJiraIssues 3 minutes to read 22.1. About This Task This task exports all issues for a given query or queries from Jira as either an AsciiDoc table, an Excel file or both. The configuration for this task can be found within Config.gradle ( gradle.properties can be used as a fallback). Username/password is deprecated, so you need to use username/API-token instead. An API-token can be created through https://id.atlassian.com/manage/api-tokens . We recommend that you keep username and API-token out of your GitHub repository, and instead pass them as environment variables to docToolchain. 22.2. Migrate configuration to version &gt;= 3.2.0 Since version 3.2.0, the configuration requests is deprecated. Please migrate to and use exports instead. The old configuration will be removed in the near future. To migrate your configuration, replace the JiraRequest class with a Map. The following example shows how to migrate a configuration with a single JiraRequest to the new configuration: Prior to 3.2.0 jira.requests = [ new JiraRequest( filename: 'jiraIssues', jql: 'project = %jiraProject% AND labels = %jiraLabel%', customfields: [ 'customfield_10026': 'StoryPoints' ] ) ] will be migrated to: From 3.2.0 onwards jira.exports = [ [ filename: 'jiraIssues', jql: 'project = %jiraProject% AND labels = %jiraLabel%', customfields: [ 'customfield_10026': 'StoryPoints' ] ] ] 22.3. Configuration Jira configuration support list requests to Jira where results of each request will be saved in a file with specifies filename. Flags saveAsciidoc &amp; saveExcel allow you to easily configure the format in which results should be saved. 22.3.1. Deprecation Notice The old configuration was based on the single Jira query is deprecated (single 'jql' parameter). Support for it will be removed in the near future. Please migrate to the new configuration which allows multiple Jira queries. Since version 3.2.0, the configuration requests is deprecated. Please migrate to and use exports instead. The old configuration will be removed in the near future. 22.3.2. Configuration Options exports (since 3.2.0), List of Maps that contains the following keys: filename : The filename of the exported file. The file extension will be added automatically. jql : The Jira query to be executed. Can have placeholders that are interpolated. Allowed placeholders are: %jiraProject% (interpolated with jira.project ), %jiraLabel% (interpolated with jira.label ) customfields : A Map of custom fields to be included in the export. Key is the technical name of the custom field in Jira, value is the name of the column in the export. rateLimit (since 3.2.0), The rate limit for Jira requests. Default is 10 requests per second. requests ( deprecated since 3.2.0, please use exports instead), List of JiraRequest that has the following properties: class JiraRequest { String filename //filename (without extension) of the file in which JQL results will be saved. Extension will be determined automatically for Asciidoc or Excel file String jql // Jira Query Language syntax Map&lt;String,String&gt; customfields // map of customFieldId:displayName values for Jira fields which don't have default names, i.e. customfield_10026:StoryPoints } Full configuration options: Config.groovy // Configuration for Jira related tasks jira = [:] jira.with { // endpoint of the JiraAPI (REST) to be used api = 'https://your-jira-instance' // requests per second for Jira API calls rateLimit = 10 /* WARNING: It is strongly recommended to store credentials securely instead of commiting plain text values to your git repository!!! Tool expects credentials that belong to an account which has the right permissions to read the JIRA issues for a given project. Credentials can be used in a form of: - passed parameters when calling script (-PjiraUser=myUsername -PjiraPass=myPassword) which can be fetched as a secrets on CI/CD or - gradle variables set through gradle properties (uses the 'jiraUser' and 'jiraPass' keys) Often, Jira &amp; Confluence credentials are the same, in which case it is recommended to pass CLI parameters for both entities as -Pusername=myUser -Ppassword=myPassword */ // the key of the Jira project project = 'PROJECTKEY' // the format of the received date time values to parse dateTimeFormatParse = \"yyyy-MM-dd'T'H:m:s.SSSz\" // i.e. 2020-07-24'T'9:12:40.999 CEST // the format in which the date time should be saved to output dateTimeFormatOutput = \"dd.MM.yyyy HH:mm:ss z\" // i.e. 24.07.2020 09:02:40 CEST // the label to restrict search to label = 'label1' // Legacy settings for Jira query. This setting is deprecated &amp; support for it will soon be completely removed. Please use JiraRequests settings jql = \"project='%jiraProject%' AND labels='%jiraLabel%' ORDER BY priority DESC, duedate ASC\" // Base filename in which Jira query results should be stored resultsFilename = 'JiraTicketsContent' saveAsciidoc = true // if true, asciidoc file will be created with *.adoc extension saveExcel = true // if true, Excel file will be created with *.xlsx extension // Output folder for this task inside main outputPath resultsFolder = 'JiraRequests' /* List of requests to Jira API: These are basically JQL expressions bundled with a filename in which results will be saved. User can configure custom fields IDs and name those for column header, i.e. customfield_10026:'Story Points' for Jira instance that has custom field with that name and will be saved in a coloumn named \"Story Points\" */ exports = [ [ filename:\"File1_Done_issues\", jql:\"project='%jiraProject%' AND status='Done' ORDER BY duedate ASC\", customfields: [customfield_10026:'Story Points'] ], [ filename:'CurrentSprint', jql:\"project='%jiraProject%' AND Sprint in openSprints() ORDER BY priority DESC, duedate ASC\", customfields: [customfield_10026:'Story Points'] ] ] } 22.4. Source Show source code of scripts/exportJiraIssues.gradle or go directly to GitHub · docToolchain/scripts/exportJiraIssues.gradle . scripts/exportJiraIssues.gradle task exportJiraIssues( description: 'exports all jira issues from a given search', group: 'docToolchain' ) { doLast { config.targetDir = targetDir new ExportJiraIssuesTask(config).execute() } } .gravatar img { margin-left: 3px; border-radius: 4px; } 23. exportJiraSprintChangelogIssues 1 minute to read 23.1. About This Task This task exports a simplified (key and summary) list of Jira issues for a specific sprint defined in the task configuration. Only a few additional fields (such as assignee) can be switched using configuration flags. Once you define the sprint, the relevant AsciiDoc and Excel files will be generated. If a sprint is not defined in the configuration, changelogs for all sprints that match the configuration will be saved in separate AsciiDoc files and in different tabs within an Excel file. The task configuration can be found within Config.gradle . In addition to the configuration snippet below, it is important to configure the Jira API and credentials in the Jira section of the configuration inside the same file. 23.2. Configuration Config.groovy // Sprint changelog configuration generate changelog lists based on tickets in sprints of an Jira instance. // This feature requires at least Jira API &amp; credentials to be properly set in Jira section of this configuration sprintChangelog = [:] sprintChangelog.with { sprintState = 'closed' // it is possible to define multiple states, i.e. 'closed, active, future' ticketStatus = \"Done, Closed\" // it is possible to define multiple ticket statuses, i.e. \"Done, Closed, 'in Progress'\" showAssignee = false showTicketStatus = false showTicketType = true sprintBoardId = 12345 // Jira instance probably have multiple boards; here it can be defined which board should be used // Output folder for this task inside main outputPath resultsFolder = 'Sprints' // if sprintName is not defined or sprint with that name isn't found, release notes will be created on for all sprints that match sprint state configuration sprintName = 'PRJ Sprint 1' // if sprint with a given sprintName is found, release notes will be created just for that sprint allSprintsFilename = 'Sprints_Changelogs' // Extension will be automatically added. } 23.3. Source Show source code of scripts/exportJiraSprintChangelog.gradle or go directly to GitHub · docToolchain/scripts/exportJiraSprintChangelog.gradle . scripts/exportJiraSprintChangelog.gradle task exportJiraSprintChangelog( description: 'exports all jira issues from Sprint for release notes', group: 'docToolchain' ) { doLast { config.targetDir = targetDir new ExportJiraSprintChangelogTask(config).execute() } } .gravatar img { margin-left: 3px; border-radius: 4px; } 24. exportPPT 1 minute to read 24.1. About This Task This task lets you export a series of PowerPoint slides to be used within your AsciiDoc documentation. It is currently a Windows-only task. It exports the slides as .jpg files and the speaker notes as one .adoc file. The tag {slide} within the speaker notes will be replaced with the corresponding image reference. This will help you to get a stable result, even when you insert or delete slides. Use the tagged regions ( //tag::[ ) feature of asciidoctor] to include only certain slides or parts of your speaker notes. 24.2. Further Reading and Resources Read the Do More with Slides blog post. Find more information about the Windows-only aspect of this task in this issue . Check out asciidoctorj-office-extension for another way to use PPT slides in your docs. 24.3. Source Show source code of scripts/exportPPT.gradle or go directly to GitHub · docToolchain/scripts/exportPPT.gradle . scripts/exportPPT.gradle task exportPPT( dependsOn: [streamingExecute], description: 'exports all slides and some texts from PPT files', group: 'docToolchain' ) { doLast { File sourceDir = file(srcDir) logger.info(\"sourceDir: ${sourceDir}\") //make sure path for notes exists //and remove old notes new File(sourceDir, 'ppt').deleteDir() //also remove old diagrams new File(sourceDir, 'images/ppt').deleteDir() //create a readme to clarify things def readme = \"\"\"This folder contains exported slides or notes from .ppt presentations. Please note that these are generated files but reside in the `src`-folder in order to be versioned. This is to make sure that they can be used from environments other than windows. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradle exportPPT` to re-export files \"\"\" new File(sourceDir, 'images/ppt/.').mkdirs() new File(sourceDir, 'images/ppt/readme.ad').write(readme) new File(sourceDir, 'ppt/.').mkdirs() new File(sourceDir, 'ppt/readme.ad').write(readme) def searchPath = new File(sourceDir, 'ppt') //execute through cscript in order to make sure that we get WScript.echo right \"%SystemRoot%\\\\System32\\\\cscript.exe //nologo ${projectDir}/scripts/exportPPT.vbs -s ${sourceDir.absolutePath}\".executeCmd() } } Show source code of scripts/exportPPT.vbs or go directly to GitHub · docToolchain/scripts/exportPPT.vbs . scripts/exportPPT.vbs Const ForAppending = 8 Const ppPlaceholderBody = 2 ' Helper ' http://windowsitpro.com/windows/jsi-tip-10441-how-can-vbscript-create-multiple-folders-path-mkdir-command Function MakeDir (strPath) Dim strParentPath, objFSO Set objFSO = CreateObject(\"Scripting.FileSystemObject\") On Error Resume Next strParentPath = objFSO.GetParentFolderName(strPath) If Not objFSO.FolderExists(strParentPath) Then MakeDir strParentPath If Not objFSO.FolderExists(strPath) Then objFSO.CreateFolder strPath On Error Goto 0 MakeDir = objFSO.FolderExists(strPath) End Function Function SearchPresentations(path) For Each folder In path.SubFolders SearchPresentations folder Next For Each file In path.Files If (Left(fso.GetExtensionName (file.Path), 3) = \"ppt\") OR (Left(fso.GetExtensionName (file.Path), 3) = \"pps\") Then WScript.echo \"found \"&amp;file.path ExportSlides(file.Path) End If Next End Function Sub ExportSlides(sFile) Set objRegEx = CreateObject(\"VBScript.RegExp\") objRegEx.Global = True objRegEx.IgnoreCase = True objRegEx.MultiLine = True ' \".\" doesn't work for multiline in vbs, \"[\\s,\\S]\" does... objRegEx.Pattern = \"[\\s,\\S]*{adoc}\" ' http://www.pptfaq.com/FAQ00481_Export_the_notes_text_of_a_presentation.htm strFileName = fso.GetFIle(sFile).Name Err.Clear Set oPPT = CreateObject(\"PowerPoint.Application\") Set oPres = oPPT.Presentations.Open(sFile, True, False, False) ' Read Only, No Title, No Window On Error resume next Set oSlides = oPres.Slides WScript.echo \"number slides: \"&amp;oSlides.Count strNotesText = \"\" strImagePath = \"/images/ppt/\" &amp; strFileName &amp; \"/\" MakeDir(searchPath &amp; strImagePath) strNotesPath = \"/ppt/\" MakeDir(searchPath &amp; strNotesPath) For Each oSl In oSlides strSlideName = oSl.Name 'WScript.echo fso.GetAbsolutePathName(searchPath) &amp; strImagePath &amp; strSlideName &amp; \".jpg\" oSl.Export fso.GetAbsolutePathName(searchPath) &amp; strImagePath &amp; strSlideName &amp; \".jpg\", \".jpg\" For Each oSh In oSl.NotesPage.Shapes If oSh.PlaceholderFormat.Type = ppPlaceholderBody Then If oSh.HasTextFrame Then If oSh.TextFrame.HasText Then strCurrentNotes = oSh.TextFrame.TextRange.Text strCurrentNotes = Replace(strCurrentNotes,vbVerticalTab, vbCrLf) strCurrentNotes = Replace(strCurrentNotes,\"{slide}\",\"image::ppt/\"&amp;strFileName&amp;\"/\"&amp;strSlideName&amp;\".jpg[]\") ' remove speaker notes before marker \"{adoc}\" strCurrentNotes = objRegEx.Replace(strCurrentNotes,\"\") strNotesText = strNotesText &amp; vbCrLf &amp; strCurrentNotes &amp; vbCrLf &amp; vbCrLf End If End If End If Next Next ' WScript.echo fso.GetAbsolutePathName(\".\") &amp; strNotesPath&amp;\"\"&amp;strFileName&amp;\".ad\" ' http://stackoverflow.com/questions/2524703/save-text-file-utf-8-encoded-with-vba Set fsT = CreateObject(\"ADODB.Stream\") fsT.Type = 2 'Specify stream type - we want To save text/string data. fsT.Charset = \"utf-8\" 'Specify charset For the source text data. fsT.Open 'Open the stream And write binary data To the object fsT.WriteText \"ifndef::imagesdir[:imagesdir: ../../images]\"&amp;vbCrLf&amp;CStr(strNotesText) fsT.SaveToFile fso.GetAbsolutePathName(searchPath) &amp; strNotesPath&amp;\"\"&amp;strFileName&amp;\".ad\", 2 'Save binary data To disk oPres.Close() oPPT.Quit() If Err.Number &lt;&gt; 0 Then WScript.Echo \"Error: \" &amp; Err.Number WScript.Echo \"Error (Hex): \" &amp; Hex(Err.Number) WScript.Echo \"Source: \" &amp; Err.Source WScript.Echo \"Description: \" &amp; Err.Description Err.Clear ' Clear the Error End If End Sub set fso = CreateObject(\"Scripting.fileSystemObject\") WScript.echo \"Slide extractor\" Set objArguments = WScript.Arguments Dim argCount argCount = 0 While objArguments.Count &gt; argCount+1 Select Case objArguments(argCount) Case \"-s\" searchPath = objArguments(argCount+1) End Select argCount = argCount + 2 WEnd WScript.echo \"looking for .ppt files in \" &amp; fso.GetAbsolutePathName(searchPath) SearchPresentations fso.GetFolder(searchPath) WScript.echo \"finished exporting slides\" .gravatar img { margin-left: 3px; border-radius: 4px; } 25. exportExcel 2 minutes to read 25.1. About This Task Sometimes you need to include tabular data in your documentation. Most likely, this data will be stored as a MS Excel spreadsheet, or you may like to use Excel to create and edit it. Either way, this task lets you export an Excel spreadsheet and include it directly in your docs. It searches for .xlsx files and exports each contained worksheet as .csv and as .adoc . Note that formulas contained in your spreadsheet are evaluated and exported statically. The generated files are written to src/excel/[filename]/[worksheet].(adoc|cvs) . The src folder is used instead of the build folder because a better history of worksheet changes is captured. The files can be included either as AsciiDoc: include::excel/Sample.xlsx/Numerical.adoc[] &#8230;&#8203;or as a CSV file: [options=\"header\",format=\"csv\"] |=== include::excel/Sample.xlsx/Numerical.csv[] |=== The AsciiDoc version gives you a bit more control because the following are preserved: Horizontal and vertical alignment. col-span and row-span. Line breaks. Column width relative to other columns. Background colors. 25.2. Further Reading and Resources See asciidoctorj-office-extension to learn another way to use Excel spreadsheets in your docs. 25.3. Source Show source code of scripts/exportExcel.gradle or go directly to GitHub · docToolchain/scripts/exportExcel.gradle . scripts/exportExcel.gradle task exportExcel( description: 'exports all excelsheets to csv and AsciiDoc', group: 'docToolchain' ) { doFirst { File sourceDir = file(srcDir) def tree = fileTree(srcDir).include('**/*.xlsx').exclude('**/~*') def exportFileDir = new File(sourceDir, 'excel') //make sure path for notes exists exportFileDir.deleteDir() //create a readme to clarify things def readme = \"\"\"This folder contains exported workbooks from Excel. Please note that these are generated files but reside in the `src`-folder in order to be versioned. This is to make sure that they can be used from environments other than windows. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradle exportExcel` to re-export files \"\"\" exportFileDir.mkdirs() new File(exportFileDir, '/readme.ad').write(readme) } doLast { File sourceDir = file(srcDir) def exportFileDir = new File(sourceDir, 'excel') def tree = fileTree(srcDir).include('**/*.xlsx').exclude('**/~*') def nl = System.getProperty(\"line.separator\") def export = { sheet, evaluator, targetFileName -&gt; def targetFileCSV = new File(targetFileName + '.csv') def targetFileAD = new File(targetFileName + '.adoc') def df = new org.apache.poi.ss.usermodel.DataFormatter(); def regions = [] sheet.numMergedRegions.times { regions &lt;&lt; sheet.getMergedRegion(it) } logger.debug \"sheet contains ${regions.size()} regions\" def color = '' def resetColor = false def numCols = 0 def headerCreated = false def emptyRows = 0 for (int rowNum=0; rowNum&lt;=sheet.lastRowNum; rowNum++) { def row = sheet.getRow(rowNum) if (row &amp;&amp; !headerCreated) { headerCreated = true // create AsciiDoc table header def width = [] numCols = row.lastCellNum numCols.times { columnIndex -&gt; width &lt;&lt; sheet.getColumnWidth((int) columnIndex) } //lets make those numbers nicer: width = width.collect { Math.round(100 * it / width.sum()) } targetFileAD.append('[options=\"header\",cols=\"' + width.join(',') + '\"]' + nl) targetFileAD.append('|===' + nl) } def data = [] def style = [] def colors = [] // For each row, iterate through each columns if (row &amp;&amp; (row?.lastCellNum!=-1)) { numCols.times { columnIndex -&gt; def cell = row.getCell(columnIndex) if (cell) { def cellValue = df.formatCellValue(cell, evaluator) if (cellValue.startsWith('*') &amp;&amp; cellValue.endsWith('\\u20AC')) { // Remove special characters at currency cellValue = cellValue.substring(1).trim(); } def cellStyle = '' def region = regions.find { it.isInRange(cell.rowIndex, cell.columnIndex) } def skipCell = false if (region) { //check if we are in the upper left corner of the region if (region.firstRow == cell.rowIndex &amp;&amp; region.firstColumn == cell.columnIndex) { def colspan = 1 + region.lastRow - region.firstRow def rowspan = 1 + region.lastColumn - region.firstColumn if (rowspan &gt; 1) { cellStyle += \"${rowspan}\" } if (colspan &gt; 1) { cellStyle += \".${colspan}\" } cellStyle += \"+\" } else { skipCell = true } } if (!skipCell) { switch (cell.cellStyle.getCellAlignment().getHorizontal().toString()) { case 'RIGHT': cellStyle += '&gt;' break case 'CENTER': cellStyle += '^' break } switch (cell.cellStyle.getCellAlignment().getVertical().toString()) { case 'BOTTOM': cellStyle += '.&gt;' break case 'CENTER': cellStyle += '.^' break } color = cell.cellStyle.fillForegroundXSSFColor?.RGB?.encodeHex() color = color != null ? nl + \"{set:cellbgcolor:#${color}}\" : '' data &lt;&lt; cellValue if (color == '' &amp;&amp; resetColor) { colors &lt;&lt; nl + \"{set:cellbgcolor!}\" resetColor = false } else { colors &lt;&lt; color } if (color != '') { resetColor = true } style &lt;&lt; cellStyle } else { data &lt;&lt; \"\" colors &lt;&lt; \"\" style &lt;&lt; \"skip\" } } else { data &lt;&lt; \"\" colors &lt;&lt; \"\" style &lt;&lt; \"\" } } emptyRows = 0 } else { if (emptyRows&lt;3) { //insert empty row numCols.times { data &lt;&lt; \"\" colors &lt;&lt; \"\" style &lt;&lt; \"\" } emptyRows++ } else { break } } targetFileCSV.append(data .collect { \"\\\"${it.replaceAll('\"', '\"\"')}\\\"\" } .join(',') + nl, 'UTF-8') // fix #1192 https://github.com/docToolchain/docToolchain/issues/1192 // remove unnecessary spans which break Asciidoctor rendering def prev = '' def removed = [] def useRemoved = true style.eachWithIndex { s, i -&gt; if (s!=\"skip\") { if (s.contains('+')) { def span = s.split('[+]')[0].split('[.]') def current = \"\" if (span.size()&gt;1) { current = span[1] } if (span[0] != '') { removed &lt;&lt; span[0] + '+' + s.split('[+]')[1] } else { removed &lt;&lt; s.split('[+]')[1] } if (i &gt; 0) { if (current != prev) { useRemoved = false } } prev = current } else { removed &lt;&lt; s useRemoved = false } } else { removed &lt;&lt; \"skip\" } } if (useRemoved) { style = removed } // fix #1192 https://github.com/docToolchain/docToolchain/issues/1192 targetFileAD.append(data .withIndex() .collect { value, index -&gt; if (style[index] == \"skip\") { \"\" } else { style[index] + \"| ${value.replaceAll('[|]', '{vbar}').replaceAll(\"\\n\", ' +$0') + colors[index]}\" } } .join(nl) + nl * 2, 'UTF-8') } targetFileAD.append('|===' + nl) // rewrite file to remove consecutive nl targetFileAD.write(targetFileAD.text.replaceAll(\"(?m)(\\\\r?\\\\n){2,}\", nl+nl)) } tree.each { File excel -&gt; println \"file: \" + excel def excelDir = new File(exportFileDir, excel.getName()) excelDir.mkdirs() InputStream inp inp = new FileInputStream(excel) def wb = org.apache.poi.ss.usermodel.WorkbookFactory.create(inp); def evaluator = wb.getCreationHelper().createFormulaEvaluator(); for (int wbi = 0; wbi &lt; wb.getNumberOfSheets(); wbi++) { def sheetName = wb.getSheetAt(wbi).getSheetName() println \" -- sheet: \" + sheetName def targetFile = new File(excelDir, sheetName) export(wb.getSheetAt(wbi), evaluator, targetFile.getAbsolutePath()) } inp.close(); } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 26. exportMarkdown 1 minute to read 26.1. About This Task The exportMarkdown task can be used to include markdown files into the documentation. It scans the /src/docs directory for markdown ( *.md ) files and converts them into Asciidoc files. The converted files can then be referenced from within the /build -folder. 26.2. Source Show source code of scripts/exportMarkdown.gradle or go directly to GitHub · docToolchain/scripts/exportMarkdown.gradle . scripts/exportMarkdown.gradle task exportMarkdown( description: 'exports all markdown files to AsciiDoc', group: 'docToolchain', type: Copy ) { from srcDir include(\"**/*.md\") //include only markdown files includeEmptyDirs = false rename(/(.+).md/, '$1.adoc') //rename all files from *.md to *.adoc filter(Markdown2AdocFilter) // convert the content of the files into targetDir } class Markdown2AdocFilter extends FilterReader { Markdown2AdocFilter(Reader input) { super(new StringReader(nl.jworks.markdown_to_asciidoc.Converter.convertMarkdownToAsciiDoc(input.text))) } } .gravatar img { margin-left: 3px; border-radius: 4px; } 27. exportOpenAPI 1 minute to read 27.1. About This Task This task exports an OpenAPI Specification definition yaml file to a AsciiDoc document. Currently, this task depends on OpenAPI Generator (v4.3.1) and its gradle plugin . 27.2. Configuration Config.groovy // Configuration for OpenAPI related task openApi = [:] // 'specFile' is the name of OpenAPI specification yaml file. Tool expects this file inside working dir (as a filename or relative path with filename) // 'infoUrl' and 'infoEmail' are specification metadata about further info related to the API. By default this values would be filled by openapi-generator plugin placeholders // openApi.with { specFile = 'src/docs/petstore-v2.0.yaml' // i.e. 'petstore.yaml', 'src/doc/petstore.yaml' infoUrl = 'https://my-api.company.com' infoEmail = 'info@company.com' } 27.3. Source Show source code of scripts/exportOpenApi.gradle or go directly to GitHub · docToolchain/scripts/exportOpenApi.gradle . scripts/exportOpenApi.gradle task exportOpenApi ( type: org.openapitools.generator.gradle.plugin.tasks.GenerateTask, group: 'docToolchain', description: 'exports OpenAPI specification to the asciidoc file') { if (!specFile) { logger.info(\"\\n---&gt; OpenAPI specification file not found in Config.groovy (https://doctoolchain.github.io/docToolchain/#_exportopenapi)\") return } else { logger.info(\"Found OpenAPI specification in Config.groovy\") } outputs.upToDateWhen { false } outputs.cacheIf { false } generatorName = 'asciidoc' outputDir = \"${targetDir}/OpenAPI\".toString() inputSpec = \"${docDir}/${specFile}\" // plugin is not able to find file if inputPath is defined as '.' logger.debug(\"\\n=====================\\nProject Config:\\n=====================\") logger.debug(\"Docdir: ${docDir}\") logger.debug(\"Target: ${targetDir}\") logger.info(\"\\n=====================\\nOpenAPI Config:\\n=====================\") logger.info(\"Specification file: ${specFile}\") logger.info(\"inputSpec: ${inputSpec}\") logger.info(\"outputDir: ${outputDir}\\n\") additionalProperties = [ infoEmail:\"${config.openApi.infoEmail}\", infoUrl:\"${config.openApi.infoUrl}\" ] } .gravatar img { margin-left: 3px; border-radius: 4px; } 28. exportStructurizr 3 minutes to read 28.1. About This Task Structurizr builds upon \"diagrams as code\", allowing you to create multiple diagrams from a single model, using a number of tools and programming languages. Structurizr is specifically designed to support the C4 model for visualising software architecture . This task exports PlantUML (respective C4-PlantUML ) diagrams from a software architecture model described with the Structurizr DSL . The generated diagrams can be integrated into the AsciiDoc documentation. The software architecture model is integral part of the software architecture documentation. As such we strongly suggest to put the Structurizr workspace file under revision control integrating it in the src/docs directory. The user would edit the software architecture model by this file. This Structurizr DSL example below creates two diagrams, based upon a single set of elements and relationships. workspace { model { user = person \"User\" softwareSystem = softwareSystem \"Software System\" { webapp = container \"Web Application\" { user -&gt; this \"Uses\" } container \"Database\" { webapp -&gt; this \"Reads from and writes to\" } } } views { systemContext softwareSystem { include * autolayout lr } container softwareSystem { include * autolayout lr } theme default } } And here the diagrams defined by the views in the example above rendered by the Structurizr web renderer. 28.2. Configuration Config.groovy // Configuration for Structurizr related tasks structurizr = [:] structurizr.with { // Configure where `exportStructurizr` looks for the Structurizr model. workspace = { // The directory in which the Structurizr workspace file is located. // path = 'src/docs/structurizr' // By default `exportStructurizr` looks for a file '${structurizr.workspace.path}/workspace.dsl' // You can customize this behavior with 'filename'. Note that the workspace filename is provided without '.dsl' extension. // filename = 'workspace' } export = { // Directory for the exported diagrams. // // WARNING: Do not put manually created/changed files into this directory. // If a valid Structurizr workspace file is found the directory is deleted before the diagram files are generated. // outputPath = 'src/docs/structurizr/diagrams' // Format of the exported diagrams. Defaults to 'plantuml' if the parameter is not provided. // // Following formats are supported: // - 'plantuml': the same as 'plantuml/structurizr' // - 'plantuml/structurizr': exports views to PlantUML // - 'plantuml/c4plantuml': exports views to PlantUML with https://github.com/plantuml-stdlib/C4-PlantUML // format = 'plantuml' } } 28.3. Example Configuration The example below shows a possible directory layout with a src/docs/structurizr directory containing the workspace.dsl file. . ├── docToolchainConfig.groovy ├── dtcw └── src └── docs ├── example │   └── example.adoc ├── images │   ├── some-pics-1.png │   └── some-pics-2.png └── structurizr └── workspace.dsl The minimal configuration for the exportStructurizr task in your docToolchainConfig.groovy would look like structurizr = [:] structurizr.with { workspace = { path = 'src/docs/structurizr' } export = { outputPath = \"src/docs/structurizr/diagrams\" // The format is optional. // format = 'plantuml' } } You probably want to put the directory configured with structurizr.export.outputPath into your .gitignore file. Do not put manually created/changed files into the directory provided with structurizr.export.outputPath . If a valid Structurizr workspace file is provided the directory is deleted before the diagram files are generated. Calling ./dtcw exportStructurizr generates the diagrams in the structurizr.export.outputPath directory. Directory layout after exporting the diagrams ├── docToolchainConfig.groovy ├── dtcw └── src └── docs ├── example │   └── example.adoc ├── images │   ├── some-pics-1.png │   └── some-pics-2.png └── structurizr ├── diagrams | ├── Container-001-key.puml | ├── Container-001.puml | ├── SystemContext-001-key.puml | └── SystemContext-001.puml └── workspace.dsl Following our example the exported diagrams may be included in the Asciidoc document example.adoc with plantuml::../structurizr/diagrams/SystemContext-001.puml[\"structurizr-SystemContext\",format=svg] plantuml::../structurizr/diagrams/Container-001.puml[\"structurizr-Container\",format=svg] 28.4. Source Show source code of scripts/exportStructurizr.gradle or go directly to GitHub · docToolchain/scripts/exportStructurizr.gradle . scripts/exportStructurizr.gradle task exportStructurizr ( group: 'docToolchain', description: 'exports the views of a Structurizr DSL file to diagramms' ) { doLast { logger.debug(\"\\n=====================\\nStructurizr Config - before property replacement:\\n=====================\") logger.debug(\"structurizr.workspace.path: ${config.structurizr.workspace.path}\") logger.debug(\"structurizr.workspace.filename: ${config.structurizr.workspace.filename}\") logger.debug(\"structurizr.export.outputPath: ${config.structurizr.export.outputPath}\") logger.debug(\"structurizr.export.format: ${config.structurizr.export.format}\") // First we check the parameters def workspacePath = findProperty(\"structurizr.workspace.path\")?:config.structurizr.workspace.path if (!workspacePath) { throw new GradleException(\"Missing configuration parameter 'structurizr.workspace.path': please provide the path where the Structurizr workspace file is located.\") } // If 'workspace.filename' is not provided, default to 'workspace' (without extension). def filename = (findProperty(\"structurizr.workspace.filename\")?:config.structurizr.workspace.filename)?:'workspace' def outputPath = findProperty(\"structurizr.export.outputPath\")?:config.structurizr.export.outputPath if (!outputPath) { throw new GradleException(\"Missing configuration parameter 'structurizr.export.outputPath': please provide the directory where the diagrams should be exported.\") } // If 'format' parameter is not provided, default to 'plantuml'. def format = (findProperty(\"structurizr.export.format\")?:config.structurizr.export.format)?:'plantuml' // Assure valid 'format' configuration parameter. DiagramExporter exporter switch(format) { case 'plantuml': case 'plantuml/structurizr': exporter = new StructurizrPlantUMLExporter() break case 'plantuml/c4plantuml': exporter = new C4PlantUMLExporter() break default: throw new GradleException(\"unknown structurizr.format '${format}': supported formats are 'plantuml' and 'plantuml/c4plantuml'.\") } logger.info(\"\\n=====================\\nStructurizr Config:\\n=====================\") logger.info(\"structurizr.workspace.path: ${workspacePath}\") logger.info(\"structurizr.workspace.filename: ${filename}\") logger.info(\"structurizr.export.outputPath: ${outputPath}\") logger.info(\"structurizr.export.format: ${format}\") def workspaceFile = new File(docDir, workspacePath+'/'+filename+'.dsl') logger.info(\"Parsing Structurizr workspace file '${workspaceFile}'\") StructurizrDslParser parser = new StructurizrDslParser() // TODO: provide better error output in case parsing fails parser.parse(workspaceFile) Workspace workspace = parser.getWorkspace() ThemeUtils.loadThemes(workspace) // Cleanup existing diagrams and then make sure the directory exists where the diagrams are exported new File(docDir, outputPath).deleteDir() // Create a readme to clarify things def readme = \"\"\"This folder contains exported diagrams from a model described with Structurizr DSL. Please note that these are generated files but reside in the `src`-folder in order to be versioned. # Warning! **The contents of this folder will be overwritten with each re-export!** use `gradlew exportStructurizr` to re-export the diagrams \"\"\" new File(docDir, outputPath).mkdirs() new File(docDir, outputPath+'/README.adoc').write(readme) Collection&lt;Diagram&gt; diagrams = exporter.export(workspace); diagrams.each { diagram -&gt; def file = new File(docDir, outputPath+\"/\"+diagram.key+'.'+diagram.getFileExtension()) file.write(diagram.definition) if (diagram.legend) { def legend = new File(docDir, outputPath+\"/\"+diagram.key+\"-key.\"+diagram.getFileExtension()) legend.write(diagram.legend.definition) } } } } .gravatar img { margin-left: 3px; border-radius: 4px; } 29. htmlSanityCheck 1 minute to read 29.1. About This Task This task invokes the htmlSanityCheck gradle plugin. It is a standalone (batch- and command-line) HTML sanity checker whose role is to detect missing images, dead links and duplicated bookmarks. In docToolchain, the htmlSanityCheck task ensures that generated HTML contains no missing links or other problems. It is the last default task, and creates a report in build/reports/htmlchecks/index.html (see example below). Figure 4. sample report 29.2. Further Reading and Resources Read the Automated Quality-Checks blog post. Visit https://github.com/aim42/htmlSanityCheck for more information about this task. 29.3. Source Show source code of scripts/htmlSanityCheck.gradle or go directly to GitHub · docToolchain/scripts/htmlSanityCheck.gradle . scripts/htmlSanityCheck.gradle htmlSanityCheck { sourceDir = new File(config.htmlSanityCheck.sourceDir?targetDir+\"/\"+config.htmlSanityCheck.sourceDir:\"$targetDir/html5\") // files to check - in Set-notation //sourceDocuments = [ \"one-file.html\", \"another-file.html\", \"index.html\"] // where to put results of sanityChecks... checkingResultsDir = new File(config.htmlSanityCheck.checkingResultsDir?:checkingResultsPath) // directory where the results written to in JUnit XML format junitResultsDir = new File(config.htmlSanityCheck.junitResultsDir?:\"$targetDir/test-results/htmlchecks\") // which statuscodes shall be interpreted as warning, error or success defaults to standard httpSuccessCodes = config.htmlSanityCheck.httpSuccessCodes?:[] httpWarningCodes = config.htmlSanityCheck.httpWarningCodes?:[] httpErrorCodes = config.htmlSanityCheck.httpErrorCodes?:[] // fail build on errors? failOnErrors = config.htmlSanityCheck.failOnErrors?:false logger.info \"docToolchain&gt; HSC sourceDir: ${sourceDir}\" logger.info \"docToolchain&gt; HSC checkingResultsDir: ${checkingResultsDir}\" } .gravatar img { margin-left: 3px; border-radius: 4px; } 30. dependencyUpdates 1 minute to read 30.1. About This Task This task uses the Gradle versions plugin created by Ben Manes to check for outdated build dependencies. Use this task to keep all dependencies up to date. If you discover newer version, it doesn&#8217;t mean that versions and dependencies will play nicely together. To ensure that everything works, we recommend the versions selected by docToolchain contributors. 30.2. Further Reading and Resources Read the Handle Dependency Updates the Easy Way blog post. 30.3. Development 1 minute to read INFO: this chapter is still work in progress 30.4. Setting Up a Dev Environment 4 minutes to read 30.4.1. Before You Begin When you install docToolchain, all the code is hidden. The information on this page explains how to get access to the code, so you can customise the setup in your dev environment. 30.4.2. Do a Local Install for Docker and SDKMAN! You need a local installation of docToolchain for development. Docker and SDKMAN! are derived from it. Docker simply contains a local install, and SDKMAN! installs docToolchain locally, but the location is controlled by SDKMAN! not docToolchain. The docToolchain-Wrapper installs docToolchain locally to $HOME/.doctoolchain/docToolchain-$v2.6.7/ . All task invocations through the docToolchain-Wrapper dtcw are redirected to $HOME/.doctoolchain/docToolchain-$v2.6.7/bin/doctoolchain . This shell script calls the Gradle-Wrapper for most tasks. What you need to do is: Create a local install which is connected to your GitHub fork of docToolchain. Create a folder called $HOME/.doctoolchain/docToolchain-2.0.0-dev/ . Check out the ng-branch of your fork to this folder. To use this version in your test project, edit the version at the start of your dtcw script to 2.0.0-dev . You now have the full repo locally cloned. To save memory, some parts of the repo are zipped. If you have problems, check out the prepareDist-Task . 30.4.3. Create Gradle-Independent Tasks All tasks currently use Gradle to run. You can bypass Gradle for tasks where it doesn’t add any value (and make docToolchain run faster as a result!). To do this, use the bin/doctoolchain scripts and create a switch. 30.4.4. Create or Change a Theme It’s not just the docToolchain code that is hidden. The themes for the static site generator jBake are also hidden. Follow these procedures to customise themes. How to Overwrite a Project Theme When docToolchain builds a static website, it first copies an internal theme to a temp folder, then copies an external theme (if defined) over it. Finally, it copies the project theme over the top. This gives you the opportunity to overwrite some parts of the theme on a per-project basis. To do this: Run the copyThemes task to copy the internal and external themes to the microsite.siteFolder . Check the files (take a look at jbake.org to get a better understanding). Modify the relevant files and delete all the other files. How to Modify an Existing Theme or Create a Theme from Scratch As we have already mentioned, an external theme is simply a zipped copy of the 'microsite.siteFolder'. All themes are downloaded when referenced from a dtcw configuration, and are stored in $HOME/.doctoolchain/themes/[hash of url] . To modify an existing theme, go to its folder and check out the theme’s project instead of the downloaded copy. This will create a connection back to the GitHub repo so that you can modify the theme directly in $HOME/.doctoolchain/themes/[hash of url] . To create a new theme from scratch, use a simple md5 hash. For example, if you configure your new theme as \"myTheme\" then \"myTheme\".md5() will be the hash. 30.4.5. Special Functionality for Themes (Config Fragments) It’s likely that you will need a new config item for your self-generated theme. And you can also prompt users to set a value for this new config item when they install the theme for the first time. To do this, create a file called configFragment.groovy in the site folder of your theme. For example: // the title of the microsite, displayed in the upper-left corner // Example: my new site title = '##site-title##' The first line is the message that will be shown to the user (can be over several lines). The second line (starting with Example :) is the default value for the prompt. The third line is the config item itself. If the value is surrounded by ## , the user will be prompted for this value and it will be replaced with the user’s input. Otherwise, the config item will be added without a prompt to the user’s current docToochainConfig.groovy . :jbake-status: published :jbake-order: 20 :jbake-type: page_toc :jbake-menu: development :jbake-title: Running Tests 30.5. Running Tests 2 minutes to read docToolchain uses Spock as Test-Framework. See http://spockframework.org/ for details. 30.5.1. Execute Tests rm -r build &amp;&amp; ./gradlew test --info The rm command ensures that you have a clean test running. This is vital because if artifacts of an older test run still exist, Gradle will skip steps (‘Up-to-date’) and you might get false positives. 30.5.2. Execute a specific test rm -r build &amp;&amp; ./gradlew test --info --tests=ExportStructurizrSpec 30.5.3. Workaround to Ensure Correct Proxy Settings for Tests The docToolchain setup is based on the Gradle-Test-Kit and makes use of the Spock test execution framework . The Gradle test runner is started in its own test environment and its own JVM instance. As a result, the global proxy settings are ignored. To execute the test with the correct proxy settings, you must use a workaround. Copy the proxy settings from the gradle.properties file located in the user directory to the gradle.properties file located in the docToolchain folder itself. Note: The files downloaded by the Gradle test runner are placed in a different folder than the default Gradle cache. You will find them in the Tmp folder C:\\Users\\YOUR_USER_NAME\\AppData\\Local\\Temp\\.gradle-test-kit-YOUR_USER_NAME\\caches. :jbake-status: published :jbake-order: 30 :jbake-type: page_toc :jbake-menu: development :jbake-title: Creating a New Release 30.6. Creating a New Release 2 minutes to read 30.6.1. Before You Begin We use semantic versioning and we also keep a changelog . All of this is done on a best-efforts basis. A release consists of five parts, each explained below. 30.6.2. GitHub run docker run -it -e BATS_LIB_PATH=/usr/lib/bats -v \"${PWD}/dtcw:/code/dtcw\" -v \"${PWD}/test:/code/test\" maxh/bats:latest test to test dtcw Update the version in gradle.properties . Update the version in dtcw and dtcw.ps1 . dtcw.bat will be generated Update the changelog. Create a section for the version. Copy to the new section all unreleased features which will be in the release. Commit and push the new version. Draft a new release . Copy the contents of the changelog for this version to the description then submit. Set the version as v X.Y.Z. Run ./gradlew createDist to zip the source in build (the distribution file). Add the zipped file and submit the new release. 30.6.3. Docker Hub Standard Image Update the GitHub workflows to reflect the new version. run github action to build and deploy the image do the same for the other images 30.6.4. Blog Post Create a blog post to announce the new release. The SDKMAN! announcement will reference it. 30.6.5. docToolchain-Wrapper (dtcw) Everything went well? Great! Now let’s update the wrapper. Navigate to https://github.com/docToolchain/doctoolchain.github.io/actions/workflows/update-dtcw.yml and trigger the action. 30.6.6. SDKMAN! A GitHub action sdkman deploy has been created to deploy to SDKMAN! Set the version to the same as for the other releases, but without the prepended v: X.Y.Z. Use as a download link the link to the docToolchain-dist.zip from the GitHub release. Tip: the link looks like https://github.com/docToolchain/docToolchain/releases/download/v1.3.1/docToolchain-dist.zip . :jbake-status: published :jbake-order: 40 :jbake-type: page_toc :jbake-menu: development :jbake-title: Debugging 30.7. Debugging 2 minutes to read Things not working as you expected? Here are some tips that might help you. 30.7.1. Environment To get the best out of docToolchain, we recommend that you set up a development environment. This way you get to see the inner workings and you also get to add extra debug output to the tasks that you want to inspect. 30.7.2. Gradle You get more hints about what is going on with Gradle when you add the --info flag to your ./dtcw generateSite command: ./dtcw generateSite --info This outputs all config settings as seen by docToolchain along with many other internal settings. 30.7.3. jBake Templates If something goes wrong with a template, you typically don’t receive much information about the problem. Take a look at menu.gsp to see how you can use try/catch blocks to get an error message. But to find out where the problem is occurring, you’ll need to use the poor man’s debugger and add some System.out.println statements. Make sure that you use the full System.out.println statement and not only println otherwise you won’t see any output. 30.7.4. Theming, Menu and Images How the system creates the menu entries might seem like magic, but sometimes you cannot work out why an image is not shown. Remember, there is a way that you can check the generated files. Check the build/microsite/tmp folder to see the folder that is fed into jBake. In this folder, all files will have additional jbake attributes which are used to build the menu. They are generated from the original attributes of the file and folder/filename information. Now check the build/microsite/output folder to see the generated result. This often helps you find out where an image actually is located. 30.7.5. Script Execution Debugging The execution of the ../../../bin/doctoolchain bash script may be traced by setting the environment variable DTC_BASH_OPTS to, e.g., -vx . 30.8. Solutions to Common Problems 9 minutes to read This section tries to answer the most common and frequently asked questions about how to work with docToolchain. It will also contain questions relevant to the tools used to build docToolchain, but the main focus is docToolchain itself. If you are stuck, make sure that you also check other sources like Stack Overflow . There is also a great FAQ for all your arc42 questions: https://faq.arc42.org/home/ If you have a question or problem for which you can&#8217;t find a solution, you can for this repo, add your question and create a pull request raise the issue through the GitHub issue tracker ask your question on Stack Overflow discuss the problem on Slack 30.8.1. References Q: How can I reference source code from my documentation? Answer As long, as you stay within your documents folder (default src/docs ), you can simply reference other files with a relative include::filename.adoc[] -statement. If you need to reference files outside of the documents folder, you need to reference them with an absolute path. include::/home/runner/work/docToolchain/docToolchainfilename.adoc[] The /home/runner/work/docToolchain/docToolchain will point to the folder where your dtcw file resides. In order make this also work in your editor preview, specify a line like the following in your documents: ifndef::projectRootDir[:projectRootDir: ../../../] 30.8.2. Images Asciidoctor User Manual on images Asciidoctor Quick Reference on images AsciiDoctor Writer Guide on images Q: Why are images not shown in the preview of my editor? Answer This is most likely because your editor doesn&#8217;t know where they are stored. If you follow the default settings, you probably store your images in a subfolder images . The build script knows about it, because the attribute imagesdir has been set to ./images , but your editor doesn&#8217;t care about the build script - it only checks the currently opened AsciiDoc file. The solution is to add a line to each file which checks if the imagesdir is set and if not, sets it to a valid value: ifndef::imagesdir[:imagesdir: ../images] Q: Which image format should I use? Answer AsciiDoc and AsciiDoctor support several formats like GIF, PNG, JPG and SVG. However, if you want to use most features, some formats are better to use than others: GIF is not supported by the PDF renderer. Use JPG or PNG instead. JPG is great for photos but not for diagrams (you might get compression artifacts). So, if you want to use photos from your flipcharts - JPG might work for you. SVG great for high resolution diagrams, but not good supported by DOCX as output format. OpenOffice Writer might display the image a bit stretched, MS Word didn&#8217;t display it at all in some experiments. PDF output might display a warning that newer SVG versions are not supported (happens especially with diagrams.net images). PNG this is the preferred format for images used with docToolchain. All output formats support it and if diagrams are rendered with a resolution high enough to display all details, it will also be scaled well with all output formats. Q: Why are my images rotated in the output? Answer This most likely happens when you&#8217;ve taken photos with a mobile device and include them in you docs. A mobile device does not rotate the image itself, it only stores the orientation of the device in the metadata of the photo. Your operating system will show you the image as expected, but the rendered AsciiDoc will not. This can be „fixed“ with Imagemagick, by using convert -auto-orient or mogrify -auto-orient (thanx to @rotnroll666 for this tip). You can also try to just open the image in your favourite editor and re-save it. === exportVisio Q: I get an error message saying that a library is not registered when I try to run the exportVisio -task. Ausnahme beim Festlegen von \"Visible\": \"Das COM-Objekt des Typs \"Microsoft.Office.Interop.Visio.ApplicationClass\" kann nicht in den Schnittstellentyp \"Microsoft.Office.Interop.Visio.IVApplication\" umgewandelt werden. Dieser Vorgang konnte nicht durchgeführt werden, da der QueryInterface-Aufruf an die COM-Komponente für die Schnittstelle mit der IID \"{000D0700-0000-0000-C000-000000000046}\" aufgrund des folgenden Fehlers nicht durchgeführt werden konnte: Bibliothek nicht registriert. (Ausnahme von HRESULT: 0x8002801D (TYPE_E_LIBNOTREGISTERED)).\" In ...\\scripts\\VisioPageToPngConverter.ps1:48 Zeichen:1 + $VisioApp.Visible = $false + ~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : NotSpecified: (:) [], SetValueInvocationException + FullyQualifiedErrorId : ExceptionWhenSetting Answer When Visio is installed, it registers itself as a com library. It seems that this registration can break. You can fix this by visiting the windows system settings &#8594; install or uninstall a program, select visio , select change and then repair . 30.8.3. Sparx Enterprise Architect Q: Sparx Enterprise Architect is a Windows tool, isn&#8217;t it? Answer Yes, it is, but it is written to support CrossOver in order to run on Linux based systems. Wine, the open source branch of CrossOver, seems to work as well. Take a look at this page to see how to install it on a linux based system: https://www.sparxsystems.com/support/faq/ea_on_linux.html I (Ralf) once gave it a try and even managed to get remote control over EA via VBS and COM up and running (which is the pre-requisite for docToolchain). 30.8.4. Known error Messages Q: I get the error for ':generateDeck' saying 'No such file or directory' when cloning reveal.js. ./dtcw generateDeck dtcw - docToolchain wrapper V0.38 docToolchain Vlatest docToolchain as CLI available docker available home folder exists cloning reveal.js ./dtcw: line 133: cd: $HOME/.doctoolchain/docToolchain-latest/resources: No such file or directory Answer You&#8217;re using dtcw v0.38 or an older version. This is because with the release of docToolchain 3.x, the ':generateDeck' tasks no longer rely on helper scripts. To resolve this issue, simply upgrade dtcw to the latest version. The good news is that dtcw is backwards compatible with docToolchain, meaning you can use the latest version of dtcw while still referring to older versions of docToolchain. To switch to other version of docToolchain refer to the installation docs . Q: I get the error saying 'Failed to create MD5 hash for file content'. * What went wrong: Failed to capture snapshot of input files for task ':generateHTML' property 'sourceDir' during up-to-date check. &gt; Failed to create MD5 hash for file content.` Answer There are two known reasons for this error. One of the .adoc files is opened in an editor, so that windows can&#8217;t get the lock for that file. &#8594; Close all .adoc files. You use the Bash script doctoolchain on a windows system. &#8594; Use doctoolchain.bat instead. It works even in a Bash Shell. Q: I get the error saying 'Unsupported major.minor version 52.0' Answer This is a sign that you use an outdated version of Java. Please upgrade to Java 8 at least and 14 max. The docToolchain-wrapper (dtcw) in v2.0 will check the java version for you so that you will not see this error message in the future. Q: I get an error message saying 'Error occurred during initialization of VM' Starting a Gradle Daemon, 1 incompatible Daemon could not be reused, use --status for details FAILURE: Build failed with an exception. * What went wrong: Unable to start the daemon process. … Error occurred during initialization of VM Could not reserve enough space for 2097152KB object heap Answer Somehow docToolchain can&#8217;t allocate the memory which is configured out of the box. Try to free up some memory or comment out the line org.gradle.jvmargs=-Xmx2048m in gradle.properties Q: I get the error saying Could not initialize class java.awt.GraphicsEnvironment$LocaleGE Answer This seems to be a problem with WSL on Windows. Some sources mention to run Java in headless mode, but in this case, it doesn&#8217;t solve the problem. The root cause seems to be plantUML trying to get some font information. Only real solution seems to be to shutdown WSL from a powershell window with wsl --shutdown and retry. this will kill all your WSL terminals without warning. Another solution seems to be to install a fresh version of your java runtime (I thought it is immutable, but it really helps). Best Solution is to switch to powershell. Another solution is to avoid PlantUML and generate Diagrams through a kroki.io server. Another variant of this is Can&#8217;t connect to X11 window server using '192.168.189.153:0' as the value of the DISPLAY variable. . In this case, it might help to install an X-Server (x410 for example) and configure the DISPLAY variable correctly. An easy way to test your configuration is to run xeyes in WSL. Make sure that your WSL is up-to-date by running wsl --update . This is not part of your regular Windows update! Q: I get a Failed to create parent directory /project/.gradle error &gt; Gradle could not start your build. &gt; Could not create service of type CrossBuildFileHashCache using BuildSessionServices.createCrossBuildFileHashCache(). &gt; Failed to create parent directory '/project/.gradle' when creating directory '/project/.gradle/6.7.1/fileHashes' Answer This issue can occur in CI environments (such as Bamboo) that have restricted permissions in the working folder where files or directories created outside the container might not be accessible inside the container. Before starting the container, give the working directory maximum permissions for allowing access to the user inside the Docker container. chmod -R o+rwx ${bamboo.working.directory} ./dtcw generateSite Another solution could be that you work on the same project with WSL and Powershell. In such an environment, the WSL environment creates temporary files which can not be modified via powershell. In such a case, just delete the .gradle folder. Q: I get an error stating that Gradle dependencies cannot be downloaded because a proxy is restricting internet access Answer Remember that dtcw is a wrapper around Gradle. So instead of calling this: ./dtcw generateSite You could call this instead (remember to replace the values used in our example): ./dtcw generateSite -Dhttp.proxyHost=127.0.0.1 -Dhttp.proxyPort=3128 \"-http.nonProxyHosts=*.nonproxyrepos.com|localhost\" (IP, port, etc. just an example) For more information about Gradle proxy configuration, read this article . 30.9. Useful Resources 2 minutes to read 30.9.1. Introduction Everything you need to know about docToolchain, from the underlying technology to useful resources. 30.9.2. Underlying Technologies Learn more about the technologies that support docToolchain, as well as some useful resources. Markup AsciiDoc This is our preferred markup language for technical docs. Asciidoctor User-Manual AsciiDoc Syntax Quick Reference \"Asciidoctor Deep Dive Video\" by Alexander Schwartz Markdown Since we use JBake as a static site generator, you can write your docs in Markdown too. flexmark-java is the Markdown parser and flavor jBake uses. markdown-to-asciidoc library can be used if you prefer to use the exportMarkdown -Task. Templates arc42 The perfect template for your software solution architecture documentation. arc42 arc42 Tips &amp; Tricks arc42 FAQ Docs as Code Docs as Code Treat your docs as if they were code. Docs-as-Code write the docs: docs-as-code Static Site Generator Static Site Generator The underlying static site generator for the generateSite -Task is jBake Our standard theme is docsy Our CSS framework is Twitter Bootstrap 30.9.3. Books These are Amazon affiliate links. Title Author Language Docs Like Code Anne Gentle English Modern Technical Writing: An Introduction to Software Documentation Andrew Etter English arc42 by Example Gernot Starke, Stefan Zörner, Michael Simons, Ralf D. Müller English Communicating Software Architectures with arc42 Gernot Starke und Peter Hruschka English Software Architecture for Developers, Volume 2 Simon Brown English arc42 in Aktion: Praktische Tipps zur Architekturdokumentation von Gernot Starke and Peter Hruschka40:00 German Softwarearchitekturen dokumentieren und kommunizieren: Entwürfe, Entscheidungen und Lösungen nachvollziehbar und wirkungsvoll festhalten von Stefan Zörner German 30.10. Configuration 2 minutes to read This appendix covers all configuration introduced by docToolchain. AsciiDoc, AsciiDoctor, Gradle and other tools and libraries used know of more configuration settings and you can read about those in the corresponding documentation. 30.10.1. mainConfigFile and docDir docToolchain should be easy to use. That&#8217;s why the goal is to have one config file with all settings for each project. But first of all, docToolchain has to know where your documentation project is located. If docDir is defined, the default for mainConfigFile is Config.groovy in the root folder of your docDir . You have several options to specify the location of your documentation project ( docDir ) and the location of your config file ( mainConfigFile ). Commandline Specify the property on the commandline ./dtcw generateHTML -PmainConfigFile=Config.groovy you can verify the location of your Config.groovy by executing docToolchain with the --info parameter which sets the loglevel to info . It will print the location on the command line (among other settings) dynamic configuration properties Sometimes you need a more dynamic configuration. Since the configuration file is an executable .groovy file, you can not only configure static values but also fetch dynamic once. For example, example = System.properties.myProperty You can then specify the property with the -D parameter like this ./dtcw docker generateHTML -DmyProperty=myValue In the same way, you can use environment variables example = System.getenv(\"myEnvVariable\") But in this case, you have to ensure that the environment variable can be accessed. It will not work for docker based execution of dtcw Content of the mainConfigFile outputPath = 'build/docs' // If you want to use the Antora integration, set this to true. // This requires your project to be setup as Antora module. // You can use `downloadTemplate` task to bootstrap your project. //useAntoraIntegration = false // Path where the docToolchain will search for the input files. // This path is appended to the docDir property specified in gradle.properties // or in the command line, and therefore must be relative to it. inputPath = 'src/docs'; inputFiles = [ [file: 'manual_test_script.adoc', formats: ['html','pdf']], /** inputFiles **/ ] //folders in which asciidoc will find images. //these will be copied as resources to ./images //folders are relative to inputPath imageDirs = [ /** imageDirs **/ ] // whether the build should fail when detecting broken image references // if this config is set to true all images will be embedded // failOnMissingImages = false taskInputsDirs = [\"${inputPath}/images\"] taskInputsFiles = [] //****************************************************************************************** //customization of the Jbake gradle plugin used by the generateSite task jbake.with { // possibility to configure additional asciidoctorj plugins used by jbake plugins = [ ] // possibiltiy to configure additional asciidoctor attributes passed to the jbake task asciidoctorAttributes = [ ] } //Configuration for exportChangelog exportChangelog = [:] changelog.with { // Directory of which the exportChangelog task will export the changelog. // It should be relative to the docDir directory provided in the // gradle.properties file. dir = 'src/docs' // Command used to fetch the list of changes. // It should be a single command taking a directory as a parameter. // You cannot use multiple commands with pipe between. // This command will be executed in the directory specified by changelogDir // it the environment inherited from the parent process. // This command should produce asciidoc text directly. The exportChangelog // task does not do any post-processing // of the output of that command. // // See also https://git-scm.com/docs/pretty-formats cmd = 'git log --pretty=format:%x7c%x20%ad%x20%n%x7c%x20%an%x20%n%x7c%x20%s%x20%n --date=short' } //***************************************************************************************** //Configureation for publishToConfluence confluence = [:] // 'input' is an array of files to upload to Confluence with the ability // to configure a different parent page for each file. // // Attributes // - 'file': absolute or relative path to the asciidoc generated html file to be exported // - 'url': absolute URL to an asciidoc generated html file to be exported // - 'ancestorName' (optional): the name of the parent page in Confluence as string; // this attribute has priority over ancestorId, but if page with given name doesn't exist, // ancestorId will be used as a fallback // - 'ancestorId' (optional): the id of the parent page in Confluence as string; leave this empty // if a new parent shall be created in the space // Set it for every file so the page scanning is done only for the given ancestor page trees. // // The following four keys can also be used in the global section below // - 'spaceKey' (optional): page specific variable for the key of the confluence space to write to // - 'subpagesForSections' (optional): The number of nested sub-pages to create. Default is '1'. // '0' means creating all on one page. // The following migration for removed configuration can be used. // 'allInOnePage = true' is the same as 'subpagesForSections = 0' // 'allInOnePage = false &amp;&amp; createSubpages = false' is the same as 'subpagesForSections = 1' // 'allInOnePage = false &amp;&amp; createSubpages = true' is the same as 'subpagesForSections = 2' // - 'pagePrefix' (optional): page specific variable, the pagePrefix will be a prefix for the page title and it's sub-pages // use this if you only have access to one confluence space but need to store several // pages with the same title - a different pagePrefix will make them unique // - 'pageSuffix' (optional): same usage as prefix but appended to the title and it's subpages // only 'file' or 'url' is allowed. If both are given, 'url' is ignored confluence.with { input = [ [ file: \"build/docs/html5/arc42-template-de.html\" ], ] // endpoint of the confluenceAPI (REST) to be used // https://[yourServer] api = 'https://[yourServer]' // requests per second for confluence API calls rateLimit = 10 // Additionally, spaceKey, subpagesForSections, pagePrefix and pageSuffix can be globally defined here. The assignment in the input array has precedence // the key of the confluence space to write to spaceKey = 'asciidoc' // if true, all pages will be created using the new editor v2 // enforceNewEditor = false // variable to determine how many layers of sub pages should be created subpagesForSections = 1 // the pagePrefix will be a prefix for each page title // use this if you only have access to one confluence space but need to store several // pages with the same title - a different pagePrefix will make them unique pagePrefix = '' pageSuffix = '' /* WARNING: It is strongly recommended to store credentials securely instead of commiting plain text values to your git repository!!! Tool expects credentials that belong to an account which has the right permissions to to create and edit confluence pages in the given space. Credentials can be used in a form of: - passed parameters when calling script (-PconfluenceUser=myUsername -PconfluencePass=myPassword) which can be fetched as a secrets on CI/CD or - gradle variables set through gradle properties (uses the 'confluenceUser' and 'confluencePass' keys) Often, same credentials are used for Jira &amp; Confluence, in which case it is recommended to pass CLI parameters for both entities as -Pusername=myUser -Ppassword=myPassword */ //optional API-token to be added in case the credentials are needed for user and password exchange. //apikey = \"[API-token]\" // HTML Content that will be included with every page published // directly after the TOC. If left empty no additional content will be // added // extraPageContent = '&lt;ac:structured-macro ac:name=\"warning\"&gt;&lt;ac:parameter ac:name=\"title\" /&gt;&lt;ac:rich-text-body&gt;This is a generated page, do not edit!&lt;/ac:rich-text-body&gt;&lt;/ac:structured-macro&gt; extraPageContent = '' // enable or disable attachment uploads for local file references enableAttachments = false // default attachmentPrefix = attachment - All files to attach will require to be linked inside the document. // attachmentPrefix = \"attachment\" // Optional proxy configuration, only used to access Confluence // schema supports http and https // proxy = [host: 'my.proxy.com', port: 1234, schema: 'http'] // Optional: specify which Confluence OpenAPI Macro should be used to render OpenAPI definitions // possible values: [\"confluence-open-api\", \"open-api\", \"swagger-open-api\", true]. true is the same as \"confluence-open-api\" for backward compatibility // useOpenapiMacro = \"confluence-open-api\" } //***************************************************************************************** //Configuration for the export script 'exportEA.vbs'. // The following parameters can be used to change the default behaviour of 'exportEA'. // All parameter are optionally. // - connection: Parameter allows to select a certain database connection by // using the ConnectionString as used for directly connecting to the project // database instead of looking for EAP/EAPX files inside and below the 'src' folder. // - 'packageFilter' is an array of package GUID's to be used for export. All // images inside and in all packages below the package represented by its GUID // are exported. A packageGUID, that is not found in the currently opened // project, is silently skipped. PackageGUID of multiple project files can // be mixed in case multiple projects have to be opened. // - exportPath: relative path to base 'docDir' to which the diagrams and notes are to be exported // - searchPath: relative path to base 'docDir', in which Enterprise Architect project files are searched // - absoluteSearchPath: absolute path in which Enterprise Architect project files are searched // - glossaryAsciiDocFormat: if set, the EA glossary is exported into exportPath as 'glossary.ad' // - glossaryTypes: if set and glossary is exported, used to filter for certain types. // Not set or empty list will cause no filtered glossary. // - diagramAttributes: if set, the diagram attributes are exported and formatted as specified // - imageFormat: if set, the image format is used for the export of diagrams. Default is '.png'. exportEA.with { // OPTIONAL: Set the connection to a certain project or comment it out to use all project files inside the src folder or its child folder. // connection = \"DBType=1;Connect=Provider=SQLOLEDB.1;Integrated Security=SSPI;Persist Security Info=False;Initial Catalog=[THE_DB_NAME_OF_THE_PROJECT];Data Source=[server_hosting_database.com];LazyLoad=1;\" // OPTIONAL: Add one or multiple packageGUIDs to be used for export. All packages are analysed, if no packageFilter is set. // packageFilter = [ // \"{A237ECDE-5419-4d47-AECC-B836999E7AE0}\", // \"{B73FA2FB-267D-4bcd-3D37-5014AD8806D6}\" // ] // OPTIONAL: export diagrams, notes, etc. below folder src/docs // exportPath = \"src/docs/\" // OPTIONAL: EA project files are expected to be located in folder src/projects // searchPath = \"src/projects/\" // OPTIONAL: terms will be exported as asciidoc 'Description, single-line' // glossaryAsciiDocFormat = \"TERM:: MEANING\" // OPTIONAL: only terms of type Business and Technical will be exported. // glossaryTypes = [\"Business\", \"Technical\"] // OPTIONAL: Additional files will be exported containing diagram attributes in the given asciidoc format // diagramAttributes = \"Modified: %DIAGRAM_AUTHOR%, %DIAGRAM_MODIFIED%, %DIAGRAM_NAME%, // %DIAGRAM_GUID%, %DIAGRAM_CREATED%, %DIAGRAM_NOTES%, %DIAGRAM_DIAGRAM_TYPE%, %DIAGRAM_VERSION%\" // OPTIONAL: format of the exported diagrams. Defaults to '.png' if the parameter is not provided. // imageFormat = \".svg\" } htmlSanityCheck.with { //sourceDir = \"build/html5/site\" // where to put results of sanityChecks... //checkingResultsDir = // OPTIONAL: directory where the results written to in JUnit XML format //junitResultsDir = // OPTIONAL: which statuscodes shall be interpreted as warning, error or success defaults to standard //httpSuccessCodes = [] //httpWarningCodes = [] //httpErrorCodes = [] // fail build on errors? failOnErrors = false } // Configuration for Jira related tasks jira = [:] jira.with { // endpoint of the JiraAPI (REST) to be used api = 'https://your-jira-instance' // requests per second for Jira API calls rateLimit = 10 /* WARNING: It is strongly recommended to store credentials securely instead of commiting plain text values to your git repository!!! Tool expects credentials that belong to an account which has the right permissions to read the JIRA issues for a given project. Credentials can be used in a form of: - passed parameters when calling script (-PjiraUser=myUsername -PjiraPass=myPassword) which can be fetched as a secrets on CI/CD or - gradle variables set through gradle properties (uses the 'jiraUser' and 'jiraPass' keys) Often, Jira &amp; Confluence credentials are the same, in which case it is recommended to pass CLI parameters for both entities as -Pusername=myUser -Ppassword=myPassword */ // the key of the Jira project project = 'PROJECTKEY' // the format of the received date time values to parse dateTimeFormatParse = \"yyyy-MM-dd'T'H:m:s.SSSz\" // i.e. 2020-07-24'T'9:12:40.999 CEST // the format in which the date time should be saved to output dateTimeFormatOutput = \"dd.MM.yyyy HH:mm:ss z\" // i.e. 24.07.2020 09:02:40 CEST // the label to restrict search to label = 'label1' // Legacy settings for Jira query. This setting is deprecated &amp; support for it will soon be completely removed. Please use JiraRequests settings jql = \"project='%jiraProject%' AND labels='%jiraLabel%' ORDER BY priority DESC, duedate ASC\" // Base filename in which Jira query results should be stored resultsFilename = 'JiraTicketsContent' saveAsciidoc = true // if true, asciidoc file will be created with *.adoc extension saveExcel = true // if true, Excel file will be created with *.xlsx extension // Output folder for this task inside main outputPath resultsFolder = 'JiraRequests' /* List of requests to Jira API: These are basically JQL expressions bundled with a filename in which results will be saved. User can configure custom fields IDs and name those for column header, i.e. customfield_10026:'Story Points' for Jira instance that has custom field with that name and will be saved in a coloumn named \"Story Points\" */ exports = [ [ filename:\"File1_Done_issues\", jql:\"project='%jiraProject%' AND status='Done' ORDER BY duedate ASC\", customfields: [customfield_10026:'Story Points'] ], [ filename:'CurrentSprint', jql:\"project='%jiraProject%' AND Sprint in openSprints() ORDER BY priority DESC, duedate ASC\", customfields: [customfield_10026:'Story Points'] ] ] } // Configuration for OpenAPI related task openApi = [:] // 'specFile' is the name of OpenAPI specification yaml file. Tool expects this file inside working dir (as a filename or relative path with filename) // 'infoUrl' and 'infoEmail' are specification metadata about further info related to the API. By default this values would be filled by openapi-generator plugin placeholders // openApi.with { specFile = 'src/docs/petstore-v2.0.yaml' // i.e. 'petstore.yaml', 'src/doc/petstore.yaml' infoUrl = 'https://my-api.company.com' infoEmail = 'info@company.com' } // Sprint changelog configuration generate changelog lists based on tickets in sprints of an Jira instance. // This feature requires at least Jira API &amp; credentials to be properly set in Jira section of this configuration sprintChangelog = [:] sprintChangelog.with { sprintState = 'closed' // it is possible to define multiple states, i.e. 'closed, active, future' ticketStatus = \"Done, Closed\" // it is possible to define multiple ticket statuses, i.e. \"Done, Closed, 'in Progress'\" showAssignee = false showTicketStatus = false showTicketType = true sprintBoardId = 12345 // Jira instance probably have multiple boards; here it can be defined which board should be used // Output folder for this task inside main outputPath resultsFolder = 'Sprints' // if sprintName is not defined or sprint with that name isn't found, release notes will be created on for all sprints that match sprint state configuration sprintName = 'PRJ Sprint 1' // if sprint with a given sprintName is found, release notes will be created just for that sprint allSprintsFilename = 'Sprints_Changelogs' // Extension will be automatically added. } collectIncludes = [:] collectIncludes.with { // fileFilter = \"adoc\" // define which files are considered. default: \"ad|adoc|asciidoc\" // minPrefixLength = \"3\" // define what minimum length the prefix. default: \"3\" // maxPrefixLength = \"3\" // define what maximum length the prefix. default: \"\" // separatorChar = \"_\" // define the allowed separators after prefix. default: \"-_\" // cleanOutputFolder = true // should the output folder be emptied before generation? default: false // excludeDirectories = [] // define additional directories that should not be traversed. } // Configuration for Structurizr related tasks structurizr = [:] structurizr.with { // Configure where `exportStructurizr` looks for the Structurizr model. workspace = { // The directory in which the Structurizr workspace file is located. // path = 'src/docs/structurizr' // By default `exportStructurizr` looks for a file '${structurizr.workspace.path}/workspace.dsl' // You can customize this behavior with 'filename'. Note that the workspace filename is provided without '.dsl' extension. // filename = 'workspace' } export = { // Directory for the exported diagrams. // // WARNING: Do not put manually created/changed files into this directory. // If a valid Structurizr workspace file is found the directory is deleted before the diagram files are generated. // outputPath = 'src/docs/structurizr/diagrams' // Format of the exported diagrams. Defaults to 'plantuml' if the parameter is not provided. // // Following formats are supported: // - 'plantuml': the same as 'plantuml/structurizr' // - 'plantuml/structurizr': exports views to PlantUML // - 'plantuml/c4plantuml': exports views to PlantUML with https://github.com/plantuml-stdlib/C4-PlantUML // format = 'plantuml' } } // Configuration for openAI related tasks openAI = [:] openAI.with { // This task requires a person access token for openAI. // Ensure to pass this token as parameters when calling the task // using -PopenAI.token=xx-xxxxxxxxxxxxxx //model = \"text-davinci-003\" //maxToken = '500' //temperature = '0.3' } // Configuration for pandoc options pandocOptions = [ '--toc' ] 30.10.2. AsciiDoc config 30.10.3. Command Line Parameters "
},

{
    "id": 108,
    "uri": "search.html",
    "menu": "-",
    "title": "search",
    "text": " Search Results "
},

{
    "id": 109,
    "uri": "lunrjsindex.html",
    "menu": "-",
    "title": "null",
    "text": " will be replaced by the index "
},

];
